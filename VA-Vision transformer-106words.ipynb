{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0687db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce3812a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n"
     ]
    }
   ],
   "source": [
    "load_path='E:/VA/onehandtwohand/128/106words_DSLR_FH/'\n",
    "CATEGORIES=np.load(load_path+'cat_106.npy', allow_pickle=True)\n",
    "IMG_SIZE=128\n",
    "cat_len=len(CATEGORIES)\n",
    "print(cat_len)\n",
    "X=np.load(load_path+'X_dslr.npy', allow_pickle=True)\n",
    "Y=np.load(load_path+'Y_dslr.npy', allow_pickle=True)\n",
    "# X = X.astype('float32')\n",
    "# X /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3e4fcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43469,)\n"
     ]
    }
   ],
   "source": [
    "Y_new=[]\n",
    "for i in range(len(X)):\n",
    "    index = (Y[i].tolist()).index(1)\n",
    "    Y_new.append(index)\n",
    "len(Y_new)\n",
    "\n",
    "Y=np.array(Y_new)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41df9c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting\n",
      "pass\n"
     ]
    }
   ],
   "source": [
    "print('Splitting') \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = cat_len)\n",
    "X_train, X_new, y_train, y_new = train_test_split(X_train, y_train, test_size = 0.2, random_state = cat_len)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "X_new = np.array(X_new)\n",
    "y_new = np.array(y_new)\n",
    "\n",
    "print(\"pass\")\n",
    "del X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe3ad89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = cat_len\n",
    "input_shape = (IMG_SIZE, IMG_SIZE, 3)\n",
    "learning_rate = 0.0001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 100\n",
    "num_epochs = 75\n",
    "image_size = 72  # We'll resize input images to this size\n",
    "patch_size = 6  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bb20c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Image Data Augmentation')\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# val_generator = ImageDataGenerator(rotation_range=0, zoom_range=0.2, width_shift_range=0.2,\n",
    "#     height_shift_range=0.2, shear_range=0.2, resize=(image_size, image_size,3))\n",
    "# #                                     , horizontal_flip=True, brightness_range=[0.6,1.3])\n",
    "# val_generator.fit(X_train)\n",
    "# val_generator.fit(X_new)\n",
    "# val_generator.fit(X_test)\n",
    "\n",
    "# print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3493d496",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.Resizing(image_size, image_size),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "        layers.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "data_augmentation.layers[0].adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d603701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7038972",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b59c93de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 72 X 72\n",
      "Patch size: 6 X 6\n",
      "Patches per image: 144\n",
      "Elements per patch: 108\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x400 with 144 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "image = X_train[np.random.choice(range(X_train.shape[0]))]\n",
    "plt.imshow((image).astype(\"uint8\"))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "resized_image = tf.image.resize(\n",
    "    tf.convert_to_tensor([image]), size=(image_size, image_size)\n",
    ")\n",
    "patches = Patches(patch_size)(resized_image)\n",
    "print(f\"Image size: {image_size} X {image_size}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
    "print(f\"Patches per image: {patches.shape[1]}\")\n",
    "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
    "\n",
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
    "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de1a07b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1456f10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier():\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Augment data.\n",
    "    augmented = data_augmentation(inputs)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    logits = layers.Dense(num_classes)(features)\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8fe12da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "Epoch 1/75\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "220/220 [==============================] - 329s 1s/step - loss: 4.8029 - accuracy: 0.0179 - top-5-accuracy: 0.0775 - val_loss: 4.3547 - val_accuracy: 0.0706 - val_top-5-accuracy: 0.2698\n",
      "Epoch 2/75\n",
      "220/220 [==============================] - 312s 1s/step - loss: 4.0725 - accuracy: 0.0704 - top-5-accuracy: 0.2377 - val_loss: 3.1990 - val_accuracy: 0.2637 - val_top-5-accuracy: 0.5405\n",
      "Epoch 3/75\n",
      "220/220 [==============================] - 311s 1s/step - loss: 3.3358 - accuracy: 0.1699 - top-5-accuracy: 0.4334 - val_loss: 2.4719 - val_accuracy: 0.4131 - val_top-5-accuracy: 0.7183\n",
      "Epoch 4/75\n",
      "220/220 [==============================] - 314s 1s/step - loss: 2.8910 - accuracy: 0.2434 - top-5-accuracy: 0.5476 - val_loss: 2.1228 - val_accuracy: 0.4460 - val_top-5-accuracy: 0.7766\n",
      "Epoch 5/75\n",
      "220/220 [==============================] - 313s 1s/step - loss: 2.5767 - accuracy: 0.3030 - top-5-accuracy: 0.6348 - val_loss: 1.7911 - val_accuracy: 0.5515 - val_top-5-accuracy: 0.8497\n",
      "Epoch 6/75\n",
      "220/220 [==============================] - 311s 1s/step - loss: 2.3338 - accuracy: 0.3530 - top-5-accuracy: 0.6917 - val_loss: 1.5409 - val_accuracy: 0.5897 - val_top-5-accuracy: 0.8825\n",
      "Epoch 7/75\n",
      "220/220 [==============================] - 311s 1s/step - loss: 2.1396 - accuracy: 0.3907 - top-5-accuracy: 0.7411 - val_loss: 1.4351 - val_accuracy: 0.6062 - val_top-5-accuracy: 0.8891\n",
      "Epoch 8/75\n",
      "220/220 [==============================] - 311s 1s/step - loss: 1.9526 - accuracy: 0.4348 - top-5-accuracy: 0.7787 - val_loss: 1.3271 - val_accuracy: 0.6513 - val_top-5-accuracy: 0.9064\n",
      "Epoch 9/75\n",
      "220/220 [==============================] - 310s 1s/step - loss: 1.8031 - accuracy: 0.4737 - top-5-accuracy: 0.8149 - val_loss: 1.2072 - val_accuracy: 0.6616 - val_top-5-accuracy: 0.9138\n",
      "Epoch 10/75\n",
      "220/220 [==============================] - 311s 1s/step - loss: 1.6755 - accuracy: 0.5058 - top-5-accuracy: 0.8368 - val_loss: 1.0657 - val_accuracy: 0.7092 - val_top-5-accuracy: 0.9343\n",
      "Epoch 11/75\n",
      "220/220 [==============================] - 310s 1s/step - loss: 1.5300 - accuracy: 0.5446 - top-5-accuracy: 0.8660 - val_loss: 0.9939 - val_accuracy: 0.7142 - val_top-5-accuracy: 0.9409\n",
      "Epoch 12/75\n",
      "220/220 [==============================] - 311s 1s/step - loss: 1.4015 - accuracy: 0.5775 - top-5-accuracy: 0.8896 - val_loss: 0.9305 - val_accuracy: 0.7236 - val_top-5-accuracy: 0.9524\n",
      "Epoch 13/75\n",
      "220/220 [==============================] - 305s 1s/step - loss: 1.2956 - accuracy: 0.6057 - top-5-accuracy: 0.9046 - val_loss: 0.9201 - val_accuracy: 0.7109 - val_top-5-accuracy: 0.9483\n",
      "Epoch 14/75\n",
      "220/220 [==============================] - 311s 1s/step - loss: 1.1989 - accuracy: 0.6336 - top-5-accuracy: 0.9181 - val_loss: 0.7961 - val_accuracy: 0.7585 - val_top-5-accuracy: 0.9626\n",
      "Epoch 15/75\n",
      "220/220 [==============================] - 320s 1s/step - loss: 1.0878 - accuracy: 0.6679 - top-5-accuracy: 0.9357 - val_loss: 0.7298 - val_accuracy: 0.7799 - val_top-5-accuracy: 0.9741\n",
      "Epoch 16/75\n",
      "220/220 [==============================] - 312s 1s/step - loss: 1.0309 - accuracy: 0.6799 - top-5-accuracy: 0.9417 - val_loss: 0.6782 - val_accuracy: 0.7943 - val_top-5-accuracy: 0.9721\n",
      "Epoch 17/75\n",
      "220/220 [==============================] - 307s 1s/step - loss: 0.9467 - accuracy: 0.7081 - top-5-accuracy: 0.9498 - val_loss: 0.6639 - val_accuracy: 0.7922 - val_top-5-accuracy: 0.9745\n",
      "Epoch 18/75\n",
      "220/220 [==============================] - 311s 1s/step - loss: 0.8883 - accuracy: 0.7201 - top-5-accuracy: 0.9562 - val_loss: 0.6119 - val_accuracy: 0.8041 - val_top-5-accuracy: 0.9823\n",
      "Epoch 19/75\n",
      "220/220 [==============================] - 312s 1s/step - loss: 0.8192 - accuracy: 0.7467 - top-5-accuracy: 0.9631 - val_loss: 0.5858 - val_accuracy: 0.8177 - val_top-5-accuracy: 0.9811\n",
      "Epoch 20/75\n",
      "220/220 [==============================] - 308s 1s/step - loss: 0.7447 - accuracy: 0.7685 - top-5-accuracy: 0.9708 - val_loss: 0.4879 - val_accuracy: 0.8472 - val_top-5-accuracy: 0.9881\n",
      "Epoch 21/75\n",
      "220/220 [==============================] - 303s 1s/step - loss: 0.7000 - accuracy: 0.7794 - top-5-accuracy: 0.9731 - val_loss: 0.6068 - val_accuracy: 0.8025 - val_top-5-accuracy: 0.9811\n",
      "Epoch 22/75\n",
      "220/220 [==============================] - 310s 1s/step - loss: 0.6407 - accuracy: 0.8029 - top-5-accuracy: 0.9763 - val_loss: 0.4523 - val_accuracy: 0.8600 - val_top-5-accuracy: 0.9828\n",
      "Epoch 23/75\n",
      "220/220 [==============================] - 311s 1s/step - loss: 0.5808 - accuracy: 0.8203 - top-5-accuracy: 0.9820 - val_loss: 0.4414 - val_accuracy: 0.8554 - val_top-5-accuracy: 0.9856\n",
      "Epoch 24/75\n",
      "220/220 [==============================] - 310s 1s/step - loss: 0.5400 - accuracy: 0.8300 - top-5-accuracy: 0.9826 - val_loss: 0.4299 - val_accuracy: 0.8674 - val_top-5-accuracy: 0.9877\n",
      "Epoch 25/75\n",
      "220/220 [==============================] - 315s 1s/step - loss: 0.4987 - accuracy: 0.8431 - top-5-accuracy: 0.9854 - val_loss: 0.4167 - val_accuracy: 0.8669 - val_top-5-accuracy: 0.9906\n",
      "Epoch 26/75\n",
      "220/220 [==============================] - 311s 1s/step - loss: 0.4581 - accuracy: 0.8570 - top-5-accuracy: 0.9897 - val_loss: 0.4476 - val_accuracy: 0.8534 - val_top-5-accuracy: 0.9893\n",
      "Epoch 27/75\n",
      "220/220 [==============================] - 309s 1s/step - loss: 0.4436 - accuracy: 0.8631 - top-5-accuracy: 0.9891 - val_loss: 0.4043 - val_accuracy: 0.8723 - val_top-5-accuracy: 0.9918\n",
      "Epoch 28/75\n",
      "220/220 [==============================] - 310s 1s/step - loss: 0.4123 - accuracy: 0.8752 - top-5-accuracy: 0.9889 - val_loss: 0.3388 - val_accuracy: 0.8903 - val_top-5-accuracy: 0.9918\n",
      "Epoch 29/75\n",
      "220/220 [==============================] - 310s 1s/step - loss: 0.3706 - accuracy: 0.8867 - top-5-accuracy: 0.9916 - val_loss: 0.3230 - val_accuracy: 0.9014 - val_top-5-accuracy: 0.9955\n",
      "Epoch 30/75\n",
      "220/220 [==============================] - 307s 1s/step - loss: 0.3572 - accuracy: 0.8911 - top-5-accuracy: 0.9923 - val_loss: 0.3567 - val_accuracy: 0.8780 - val_top-5-accuracy: 0.9943\n",
      "Epoch 31/75\n",
      "220/220 [==============================] - 306s 1s/step - loss: 0.3287 - accuracy: 0.8977 - top-5-accuracy: 0.9934 - val_loss: 0.3047 - val_accuracy: 0.8977 - val_top-5-accuracy: 0.9955\n",
      "Epoch 32/75\n",
      "220/220 [==============================] - 309s 1s/step - loss: 0.3159 - accuracy: 0.9026 - top-5-accuracy: 0.9952 - val_loss: 0.2414 - val_accuracy: 0.9224 - val_top-5-accuracy: 0.9984\n",
      "Epoch 33/75\n",
      "220/220 [==============================] - 307s 1s/step - loss: 0.2908 - accuracy: 0.9105 - top-5-accuracy: 0.9958 - val_loss: 0.3400 - val_accuracy: 0.8891 - val_top-5-accuracy: 0.9914\n",
      "Epoch 34/75\n",
      "220/220 [==============================] - 305s 1s/step - loss: 0.2762 - accuracy: 0.9172 - top-5-accuracy: 0.9953 - val_loss: 0.2982 - val_accuracy: 0.9150 - val_top-5-accuracy: 0.9955\n",
      "Epoch 35/75\n",
      "220/220 [==============================] - 305s 1s/step - loss: 0.2758 - accuracy: 0.9130 - top-5-accuracy: 0.9960 - val_loss: 0.2611 - val_accuracy: 0.9092 - val_top-5-accuracy: 0.9975\n",
      "Epoch 36/75\n",
      "220/220 [==============================] - 306s 1s/step - loss: 0.2469 - accuracy: 0.9261 - top-5-accuracy: 0.9969 - val_loss: 0.3495 - val_accuracy: 0.8891 - val_top-5-accuracy: 0.9926\n",
      "Epoch 37/75\n",
      "220/220 [==============================] - 316s 1s/step - loss: 0.2389 - accuracy: 0.9281 - top-5-accuracy: 0.9964 - val_loss: 0.2206 - val_accuracy: 0.9298 - val_top-5-accuracy: 0.9984\n",
      "Epoch 38/75\n",
      "220/220 [==============================] - 306s 1s/step - loss: 0.2148 - accuracy: 0.9349 - top-5-accuracy: 0.9976 - val_loss: 0.2752 - val_accuracy: 0.9084 - val_top-5-accuracy: 0.9967\n",
      "Epoch 39/75\n",
      "220/220 [==============================] - 310s 1s/step - loss: 0.2155 - accuracy: 0.9331 - top-5-accuracy: 0.9973 - val_loss: 0.1660 - val_accuracy: 0.9540 - val_top-5-accuracy: 0.9979\n",
      "Epoch 40/75\n",
      "220/220 [==============================] - 306s 1s/step - loss: 0.1985 - accuracy: 0.9407 - top-5-accuracy: 0.9980 - val_loss: 0.2375 - val_accuracy: 0.9183 - val_top-5-accuracy: 0.9988\n",
      "Epoch 41/75\n",
      "220/220 [==============================] - 306s 1s/step - loss: 0.1940 - accuracy: 0.9410 - top-5-accuracy: 0.9980 - val_loss: 0.2784 - val_accuracy: 0.9175 - val_top-5-accuracy: 0.9951\n",
      "Epoch 42/75\n",
      "220/220 [==============================] - 309s 1s/step - loss: 0.1982 - accuracy: 0.9392 - top-5-accuracy: 0.9972 - val_loss: 0.1812 - val_accuracy: 0.9405 - val_top-5-accuracy: 0.9992\n",
      "Epoch 43/75\n",
      "220/220 [==============================] - 310s 1s/step - loss: 0.1715 - accuracy: 0.9492 - top-5-accuracy: 0.9981 - val_loss: 0.1970 - val_accuracy: 0.9405 - val_top-5-accuracy: 0.9963\n",
      "Epoch 44/75\n",
      "220/220 [==============================] - 309s 1s/step - loss: 0.1647 - accuracy: 0.9504 - top-5-accuracy: 0.9988 - val_loss: 0.2160 - val_accuracy: 0.9306 - val_top-5-accuracy: 0.9984\n",
      "Epoch 45/75\n",
      "220/220 [==============================] - 308s 1s/step - loss: 0.1646 - accuracy: 0.9499 - top-5-accuracy: 0.9983 - val_loss: 0.1764 - val_accuracy: 0.9437 - val_top-5-accuracy: 0.9992\n",
      "Epoch 46/75\n",
      "220/220 [==============================] - 311s 1s/step - loss: 0.1530 - accuracy: 0.9545 - top-5-accuracy: 0.9994 - val_loss: 0.1905 - val_accuracy: 0.9351 - val_top-5-accuracy: 0.9984\n",
      "Epoch 47/75\n",
      "220/220 [==============================] - 305s 1s/step - loss: 0.1486 - accuracy: 0.9569 - top-5-accuracy: 0.9986 - val_loss: 0.1720 - val_accuracy: 0.9495 - val_top-5-accuracy: 0.9984\n",
      "Epoch 48/75\n",
      "220/220 [==============================] - 321s 1s/step - loss: 0.1461 - accuracy: 0.9565 - top-5-accuracy: 0.9988 - val_loss: 0.1294 - val_accuracy: 0.9589 - val_top-5-accuracy: 0.9988\n",
      "Epoch 49/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 307s 1s/step - loss: 0.1360 - accuracy: 0.9593 - top-5-accuracy: 0.9991 - val_loss: 0.1724 - val_accuracy: 0.9511 - val_top-5-accuracy: 0.9988\n",
      "Epoch 50/75\n",
      "220/220 [==============================] - 308s 1s/step - loss: 0.1365 - accuracy: 0.9599 - top-5-accuracy: 0.9988 - val_loss: 0.1892 - val_accuracy: 0.9335 - val_top-5-accuracy: 0.9984\n",
      "Epoch 51/75\n",
      "220/220 [==============================] - 307s 1s/step - loss: 0.1397 - accuracy: 0.9589 - top-5-accuracy: 0.9990 - val_loss: 0.1618 - val_accuracy: 0.9499 - val_top-5-accuracy: 0.9992\n",
      "Epoch 52/75\n",
      "220/220 [==============================] - 310s 1s/step - loss: 0.1359 - accuracy: 0.9592 - top-5-accuracy: 0.9989 - val_loss: 0.1545 - val_accuracy: 0.9536 - val_top-5-accuracy: 0.9984\n",
      "Epoch 53/75\n",
      "220/220 [==============================] - 309s 1s/step - loss: 0.1216 - accuracy: 0.9645 - top-5-accuracy: 0.9992 - val_loss: 0.1618 - val_accuracy: 0.9499 - val_top-5-accuracy: 0.9988\n",
      "Epoch 54/75\n",
      "220/220 [==============================] - 305s 1s/step - loss: 0.1247 - accuracy: 0.9633 - top-5-accuracy: 0.9994 - val_loss: 0.1698 - val_accuracy: 0.9454 - val_top-5-accuracy: 0.9975\n",
      "Epoch 55/75\n",
      "220/220 [==============================] - 306s 1s/step - loss: 0.1189 - accuracy: 0.9650 - top-5-accuracy: 0.9990 - val_loss: 0.1782 - val_accuracy: 0.9429 - val_top-5-accuracy: 0.9988\n",
      "Epoch 56/75\n",
      "220/220 [==============================] - 321s 1s/step - loss: 0.1249 - accuracy: 0.9625 - top-5-accuracy: 0.9992 - val_loss: 0.1118 - val_accuracy: 0.9696 - val_top-5-accuracy: 1.0000\n",
      "Epoch 57/75\n",
      "220/220 [==============================] - 313s 1s/step - loss: 0.1080 - accuracy: 0.9684 - top-5-accuracy: 0.9996 - val_loss: 0.1213 - val_accuracy: 0.9643 - val_top-5-accuracy: 1.0000\n",
      "Epoch 58/75\n",
      "220/220 [==============================] - 309s 1s/step - loss: 0.1171 - accuracy: 0.9660 - top-5-accuracy: 0.9995 - val_loss: 0.1490 - val_accuracy: 0.9515 - val_top-5-accuracy: 0.9988\n",
      "Epoch 59/75\n",
      "220/220 [==============================] - 306s 1s/step - loss: 0.1130 - accuracy: 0.9651 - top-5-accuracy: 0.9991 - val_loss: 0.2125 - val_accuracy: 0.9376 - val_top-5-accuracy: 0.9984\n",
      "Epoch 60/75\n",
      "220/220 [==============================] - 305s 1s/step - loss: 0.1020 - accuracy: 0.9707 - top-5-accuracy: 0.9997 - val_loss: 0.1742 - val_accuracy: 0.9466 - val_top-5-accuracy: 0.9971\n",
      "Epoch 61/75\n",
      "220/220 [==============================] - 307s 1s/step - loss: 0.1217 - accuracy: 0.9647 - top-5-accuracy: 0.9988 - val_loss: 0.1326 - val_accuracy: 0.9573 - val_top-5-accuracy: 0.9992\n",
      "Epoch 62/75\n",
      "220/220 [==============================] - 305s 1s/step - loss: 0.1016 - accuracy: 0.9708 - top-5-accuracy: 0.9995 - val_loss: 0.1625 - val_accuracy: 0.9491 - val_top-5-accuracy: 0.9984\n",
      "Epoch 63/75\n",
      "220/220 [==============================] - 305s 1s/step - loss: 0.1026 - accuracy: 0.9701 - top-5-accuracy: 0.9992 - val_loss: 0.1197 - val_accuracy: 0.9626 - val_top-5-accuracy: 0.9992\n",
      "Epoch 64/75\n",
      "220/220 [==============================] - 306s 1s/step - loss: 0.1121 - accuracy: 0.9687 - top-5-accuracy: 0.9994 - val_loss: 0.1299 - val_accuracy: 0.9585 - val_top-5-accuracy: 0.9992\n",
      "Epoch 65/75\n",
      "220/220 [==============================] - 306s 1s/step - loss: 0.0934 - accuracy: 0.9738 - top-5-accuracy: 0.9995 - val_loss: 0.1185 - val_accuracy: 0.9626 - val_top-5-accuracy: 0.9996\n",
      "Epoch 66/75\n",
      "220/220 [==============================] - 316s 1s/step - loss: 0.0994 - accuracy: 0.9709 - top-5-accuracy: 0.9996 - val_loss: 0.0961 - val_accuracy: 0.9717 - val_top-5-accuracy: 0.9988\n",
      "Epoch 67/75\n",
      "220/220 [==============================] - 306s 1s/step - loss: 0.0966 - accuracy: 0.9725 - top-5-accuracy: 0.9995 - val_loss: 0.1612 - val_accuracy: 0.9507 - val_top-5-accuracy: 0.9996\n",
      "Epoch 68/75\n",
      "220/220 [==============================] - 307s 1s/step - loss: 0.0977 - accuracy: 0.9728 - top-5-accuracy: 0.9996 - val_loss: 0.2717 - val_accuracy: 0.9097 - val_top-5-accuracy: 0.9951\n",
      "Epoch 69/75\n",
      "220/220 [==============================] - 304s 1s/step - loss: 0.1104 - accuracy: 0.9675 - top-5-accuracy: 0.9994 - val_loss: 0.1207 - val_accuracy: 0.9684 - val_top-5-accuracy: 0.9996\n",
      "Epoch 70/75\n",
      "220/220 [==============================] - 304s 1s/step - loss: 0.0925 - accuracy: 0.9731 - top-5-accuracy: 0.9997 - val_loss: 0.1221 - val_accuracy: 0.9655 - val_top-5-accuracy: 0.9996\n",
      "Epoch 71/75\n",
      "220/220 [==============================] - 304s 1s/step - loss: 0.0945 - accuracy: 0.9720 - top-5-accuracy: 0.9995 - val_loss: 0.1523 - val_accuracy: 0.9515 - val_top-5-accuracy: 0.9979\n",
      "Epoch 72/75\n",
      "220/220 [==============================] - 304s 1s/step - loss: 0.0902 - accuracy: 0.9743 - top-5-accuracy: 0.9993 - val_loss: 0.1306 - val_accuracy: 0.9585 - val_top-5-accuracy: 0.9984\n",
      "Epoch 73/75\n",
      "220/220 [==============================] - 315s 1s/step - loss: 0.0880 - accuracy: 0.9750 - top-5-accuracy: 0.9995 - val_loss: 0.0816 - val_accuracy: 0.9791 - val_top-5-accuracy: 0.9996\n",
      "Epoch 74/75\n",
      "220/220 [==============================] - 306s 1s/step - loss: 0.0933 - accuracy: 0.9739 - top-5-accuracy: 0.9995 - val_loss: 0.1634 - val_accuracy: 0.9417 - val_top-5-accuracy: 0.9996\n",
      "Epoch 75/75\n",
      "220/220 [==============================] - 317s 1s/step - loss: 0.0946 - accuracy: 0.9712 - top-5-accuracy: 0.9997 - val_loss: 0.2570 - val_accuracy: 0.9203 - val_top-5-accuracy: 0.9955\n",
      "408/408 [==============================] - 7s 17ms/step - loss: 0.0907 - accuracy: 0.9745 - top-5-accuracy: 0.9989\n",
      "Test accuracy: 97.45%\n",
      "Test top 5 accuracy: 99.89%\n"
     ]
    }
   ],
   "source": [
    "def run_experiment(model):\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = load_path+\"tmp\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    _, accuracy, top_5_accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "    return model, history\n",
    "\n",
    "\n",
    "vit_classifier = create_vit_classifier()\n",
    "model, history = run_experiment(vit_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e4d35f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, query_layer_call_fn while saving (showing 5 of 100). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/VA/onehandtwohand/128/106words_DSLR_FH/VAViT_model.sav\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/VA/onehandtwohand/128/106words_DSLR_FH/VAViT_model.sav\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved\n"
     ]
    }
   ],
   "source": [
    "print('Saving')\n",
    "model_name1 = 'VAViT'\n",
    "np.save(load_path+model_name1+'_history.npy',history.history)\n",
    "model.save(load_path+model_name1+'_model.sav') \n",
    "print(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d57e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load saved history\n",
    "model_name1 = 'VAViT'\n",
    "history_const=np.load(load_path+model_name1+'_history.npy',allow_pickle='TRUE').item()\n",
    "\n",
    "# #load saved model\n",
    "model1=load_model(load_path+model_name1+'_model.sav')\n",
    "\n",
    "print(\"loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a5edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = model1.predict(X_new)\n",
    "\n",
    "Y_pred=[]\n",
    "for i in range(len(X_new)):\n",
    "#     index = (y_pred[i].tolist()).index(argmax())\n",
    "    index = y_pred[i].argmax()\n",
    "    Y_pred.append(index)\n",
    "Y_pred=np.array(Y_pred)\n",
    "\n",
    "accuracy_score(y_new, Y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
