{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d962aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dropout, BatchNormalization, Dense, Flatten, LayerNormalization\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.applications as appl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from keras import callbacks  \n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13774f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path='E:/VA/onehandtwohand/128/106words_DSLR_FH/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edaddf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES=np.load(load_path+'cat_106.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "659cb729",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12d7e2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n"
     ]
    }
   ],
   "source": [
    "cat_len=len(CATEGORIES)\n",
    "print(cat_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc104aa6",
   "metadata": {},
   "source": [
    "# Save combined data npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4dd8029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "# model_name1 = 'InceptionResNetV2'\n",
    "# model_name1 = '4layer'\n",
    "model_name1 = 'Xception_lr0.00001_106words_dslr128-99.69'\n",
    "#model_name2 = 'VGG16'\n",
    "# model_name1 = 'DenseNet121'\n",
    "# model_name1 = 'InceptionV3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa37bec1",
   "metadata": {},
   "source": [
    "Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0def0f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load(load_path+'X_dslr.npy', allow_pickle=True)\n",
    "Y=np.load(load_path+'Y_dslr.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bac9e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype('float32')\n",
    "X /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89586ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting\n",
      "pass\n"
     ]
    }
   ],
   "source": [
    "print('Splitting') \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = cat_len)\n",
    "X_train, X_new, y_train, y_new = train_test_split(X_train, y_train, test_size = 0.2, random_state = cat_len)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "X_new = np.array(X_new)\n",
    "y_new = np.array(y_new)\n",
    "\n",
    "print(\"pass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f26320e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f75aadef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Data Augmentation\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('Image Data Augmentation')\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "val_generator = ImageDataGenerator(rotation_range=0, zoom_range=0.2, width_shift_range=0.2,\n",
    "    height_shift_range=0.2, shear_range=0.2)\n",
    "#                                     , horizontal_flip=True, brightness_range=[0.6,1.3])\n",
    "val_generator.fit(X_train)\n",
    "val_generator.fit(X_new)\n",
    "val_generator.fit(X_test)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0efad93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"xception\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 63, 63, 32)   864         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " block1_conv1_bn (BatchNormaliz  (None, 63, 63, 32)  128         ['block1_conv1[0][0]']           \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " block1_conv1_act (Activation)  (None, 63, 63, 32)   0           ['block1_conv1_bn[0][0]']        \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 61, 61, 64)   18432       ['block1_conv1_act[0][0]']       \n",
      "                                                                                                  \n",
      " block1_conv2_bn (BatchNormaliz  (None, 61, 61, 64)  256         ['block1_conv2[0][0]']           \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " block1_conv2_act (Activation)  (None, 61, 61, 64)   0           ['block1_conv2_bn[0][0]']        \n",
      "                                                                                                  \n",
      " block2_sepconv1 (SeparableConv  (None, 61, 61, 128)  8768       ['block1_conv2_act[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block2_sepconv1_bn (BatchNorma  (None, 61, 61, 128)  512        ['block2_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2_sepconv2_act (Activatio  (None, 61, 61, 128)  0          ['block2_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block2_sepconv2 (SeparableConv  (None, 61, 61, 128)  17536      ['block2_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block2_sepconv2_bn (BatchNorma  (None, 61, 61, 128)  512        ['block2_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 31, 31, 128)  8192        ['block1_conv2_act[0][0]']       \n",
      "                                                                                                  \n",
      " block2_pool (MaxPooling2D)     (None, 31, 31, 128)  0           ['block2_sepconv2_bn[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 31, 31, 128)  512        ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 31, 31, 128)  0           ['block2_pool[0][0]',            \n",
      "                                                                  'batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " block3_sepconv1_act (Activatio  (None, 31, 31, 128)  0          ['add[0][0]']                    \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block3_sepconv1 (SeparableConv  (None, 31, 31, 256)  33920      ['block3_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block3_sepconv1_bn (BatchNorma  (None, 31, 31, 256)  1024       ['block3_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3_sepconv2_act (Activatio  (None, 31, 31, 256)  0          ['block3_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block3_sepconv2 (SeparableConv  (None, 31, 31, 256)  67840      ['block3_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block3_sepconv2_bn (BatchNorma  (None, 31, 31, 256)  1024       ['block3_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 16, 16, 256)  32768       ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " block3_pool (MaxPooling2D)     (None, 16, 16, 256)  0           ['block3_sepconv2_bn[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 16, 16, 256)  0           ['block3_pool[0][0]',            \n",
      "                                                                  'batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " block4_sepconv1_act (Activatio  (None, 16, 16, 256)  0          ['add_1[0][0]']                  \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block4_sepconv1 (SeparableConv  (None, 16, 16, 728)  188672     ['block4_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block4_sepconv1_bn (BatchNorma  (None, 16, 16, 728)  2912       ['block4_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4_sepconv2_act (Activatio  (None, 16, 16, 728)  0          ['block4_sepconv1_bn[0][0]']     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block4_sepconv2 (SeparableConv  (None, 16, 16, 728)  536536     ['block4_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block4_sepconv2_bn (BatchNorma  (None, 16, 16, 728)  2912       ['block4_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 8, 8, 728)    186368      ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " block4_pool (MaxPooling2D)     (None, 8, 8, 728)    0           ['block4_sepconv2_bn[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 8, 8, 728)   2912        ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 8, 8, 728)    0           ['block4_pool[0][0]',            \n",
      "                                                                  'batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " block5_sepconv1_act (Activatio  (None, 8, 8, 728)   0           ['add_2[0][0]']                  \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block5_sepconv1 (SeparableConv  (None, 8, 8, 728)   536536      ['block5_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5_sepconv1_bn (BatchNorma  (None, 8, 8, 728)   2912        ['block5_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5_sepconv2_act (Activatio  (None, 8, 8, 728)   0           ['block5_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block5_sepconv2 (SeparableConv  (None, 8, 8, 728)   536536      ['block5_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5_sepconv2_bn (BatchNorma  (None, 8, 8, 728)   2912        ['block5_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5_sepconv3_act (Activatio  (None, 8, 8, 728)   0           ['block5_sepconv2_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block5_sepconv3 (SeparableConv  (None, 8, 8, 728)   536536      ['block5_sepconv3_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5_sepconv3_bn (BatchNorma  (None, 8, 8, 728)   2912        ['block5_sepconv3[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 8, 8, 728)    0           ['block5_sepconv3_bn[0][0]',     \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " block6_sepconv1_act (Activatio  (None, 8, 8, 728)   0           ['add_3[0][0]']                  \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block6_sepconv1 (SeparableConv  (None, 8, 8, 728)   536536      ['block6_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6_sepconv1_bn (BatchNorma  (None, 8, 8, 728)   2912        ['block6_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6_sepconv2_act (Activatio  (None, 8, 8, 728)   0           ['block6_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block6_sepconv2 (SeparableConv  (None, 8, 8, 728)   536536      ['block6_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6_sepconv2_bn (BatchNorma  (None, 8, 8, 728)   2912        ['block6_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6_sepconv3_act (Activatio  (None, 8, 8, 728)   0           ['block6_sepconv2_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block6_sepconv3 (SeparableConv  (None, 8, 8, 728)   536536      ['block6_sepconv3_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6_sepconv3_bn (BatchNorma  (None, 8, 8, 728)   2912        ['block6_sepconv3[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 8, 8, 728)    0           ['block6_sepconv3_bn[0][0]',     \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " block7_sepconv1_act (Activatio  (None, 8, 8, 728)   0           ['add_4[0][0]']                  \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block7_sepconv1 (SeparableConv  (None, 8, 8, 728)   536536      ['block7_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " block7_sepconv1_bn (BatchNorma  (None, 8, 8, 728)   2912        ['block7_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block7_sepconv2_act (Activatio  (None, 8, 8, 728)   0           ['block7_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block7_sepconv2 (SeparableConv  (None, 8, 8, 728)   536536      ['block7_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block7_sepconv2_bn (BatchNorma  (None, 8, 8, 728)   2912        ['block7_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block7_sepconv3_act (Activatio  (None, 8, 8, 728)   0           ['block7_sepconv2_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block7_sepconv3 (SeparableConv  (None, 8, 8, 728)   536536      ['block7_sepconv3_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block7_sepconv3_bn (BatchNorma  (None, 8, 8, 728)   2912        ['block7_sepconv3[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 8, 8, 728)    0           ['block7_sepconv3_bn[0][0]',     \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " block8_sepconv1_act (Activatio  (None, 8, 8, 728)   0           ['add_5[0][0]']                  \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block8_sepconv1 (SeparableConv  (None, 8, 8, 728)   536536      ['block8_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block8_sepconv1_bn (BatchNorma  (None, 8, 8, 728)   2912        ['block8_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block8_sepconv2_act (Activatio  (None, 8, 8, 728)   0           ['block8_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block8_sepconv2 (SeparableConv  (None, 8, 8, 728)   536536      ['block8_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block8_sepconv2_bn (BatchNorma  (None, 8, 8, 728)   2912        ['block8_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block8_sepconv3_act (Activatio  (None, 8, 8, 728)   0           ['block8_sepconv2_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block8_sepconv3 (SeparableConv  (None, 8, 8, 728)   536536      ['block8_sepconv3_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block8_sepconv3_bn (BatchNorma  (None, 8, 8, 728)   2912        ['block8_sepconv3[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 8, 8, 728)    0           ['block8_sepconv3_bn[0][0]',     \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " block9_sepconv1_act (Activatio  (None, 8, 8, 728)   0           ['add_6[0][0]']                  \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block9_sepconv1 (SeparableConv  (None, 8, 8, 728)   536536      ['block9_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block9_sepconv1_bn (BatchNorma  (None, 8, 8, 728)   2912        ['block9_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block9_sepconv2_act (Activatio  (None, 8, 8, 728)   0           ['block9_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block9_sepconv2 (SeparableConv  (None, 8, 8, 728)   536536      ['block9_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block9_sepconv2_bn (BatchNorma  (None, 8, 8, 728)   2912        ['block9_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block9_sepconv3_act (Activatio  (None, 8, 8, 728)   0           ['block9_sepconv2_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block9_sepconv3 (SeparableConv  (None, 8, 8, 728)   536536      ['block9_sepconv3_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block9_sepconv3_bn (BatchNorma  (None, 8, 8, 728)   2912        ['block9_sepconv3[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 8, 8, 728)    0           ['block9_sepconv3_bn[0][0]',     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " block10_sepconv1_act (Activati  (None, 8, 8, 728)   0           ['add_7[0][0]']                  \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block10_sepconv1 (SeparableCon  (None, 8, 8, 728)   536536      ['block10_sepconv1_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block10_sepconv1_bn (BatchNorm  (None, 8, 8, 728)   2912        ['block10_sepconv1[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block10_sepconv2_act (Activati  (None, 8, 8, 728)   0           ['block10_sepconv1_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block10_sepconv2 (SeparableCon  (None, 8, 8, 728)   536536      ['block10_sepconv2_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block10_sepconv2_bn (BatchNorm  (None, 8, 8, 728)   2912        ['block10_sepconv2[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block10_sepconv3_act (Activati  (None, 8, 8, 728)   0           ['block10_sepconv2_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block10_sepconv3 (SeparableCon  (None, 8, 8, 728)   536536      ['block10_sepconv3_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block10_sepconv3_bn (BatchNorm  (None, 8, 8, 728)   2912        ['block10_sepconv3[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 8, 8, 728)    0           ['block10_sepconv3_bn[0][0]',    \n",
      "                                                                  'add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " block11_sepconv1_act (Activati  (None, 8, 8, 728)   0           ['add_8[0][0]']                  \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block11_sepconv1 (SeparableCon  (None, 8, 8, 728)   536536      ['block11_sepconv1_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block11_sepconv1_bn (BatchNorm  (None, 8, 8, 728)   2912        ['block11_sepconv1[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block11_sepconv2_act (Activati  (None, 8, 8, 728)   0           ['block11_sepconv1_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block11_sepconv2 (SeparableCon  (None, 8, 8, 728)   536536      ['block11_sepconv2_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block11_sepconv2_bn (BatchNorm  (None, 8, 8, 728)   2912        ['block11_sepconv2[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block11_sepconv3_act (Activati  (None, 8, 8, 728)   0           ['block11_sepconv2_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block11_sepconv3 (SeparableCon  (None, 8, 8, 728)   536536      ['block11_sepconv3_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block11_sepconv3_bn (BatchNorm  (None, 8, 8, 728)   2912        ['block11_sepconv3[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 8, 8, 728)    0           ['block11_sepconv3_bn[0][0]',    \n",
      "                                                                  'add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " block12_sepconv1_act (Activati  (None, 8, 8, 728)   0           ['add_9[0][0]']                  \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block12_sepconv1 (SeparableCon  (None, 8, 8, 728)   536536      ['block12_sepconv1_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block12_sepconv1_bn (BatchNorm  (None, 8, 8, 728)   2912        ['block12_sepconv1[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block12_sepconv2_act (Activati  (None, 8, 8, 728)   0           ['block12_sepconv1_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block12_sepconv2 (SeparableCon  (None, 8, 8, 728)   536536      ['block12_sepconv2_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block12_sepconv2_bn (BatchNorm  (None, 8, 8, 728)   2912        ['block12_sepconv2[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block12_sepconv3_act (Activati  (None, 8, 8, 728)   0           ['block12_sepconv2_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block12_sepconv3 (SeparableCon  (None, 8, 8, 728)   536536      ['block12_sepconv3_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block12_sepconv3_bn (BatchNorm  (None, 8, 8, 728)   2912        ['block12_sepconv3[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 8, 8, 728)    0           ['block12_sepconv3_bn[0][0]',    \n",
      "                                                                  'add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " block13_sepconv1_act (Activati  (None, 8, 8, 728)   0           ['add_10[0][0]']                 \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block13_sepconv1 (SeparableCon  (None, 8, 8, 728)   536536      ['block13_sepconv1_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block13_sepconv1_bn (BatchNorm  (None, 8, 8, 728)   2912        ['block13_sepconv1[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block13_sepconv2_act (Activati  (None, 8, 8, 728)   0           ['block13_sepconv1_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block13_sepconv2 (SeparableCon  (None, 8, 8, 1024)  752024      ['block13_sepconv2_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block13_sepconv2_bn (BatchNorm  (None, 8, 8, 1024)  4096        ['block13_sepconv2[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 4, 4, 1024)   745472      ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " block13_pool (MaxPooling2D)    (None, 4, 4, 1024)   0           ['block13_sepconv2_bn[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 4, 4, 1024)  4096        ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 4, 4, 1024)   0           ['block13_pool[0][0]',           \n",
      "                                                                  'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " block14_sepconv1 (SeparableCon  (None, 4, 4, 1536)  1582080     ['add_11[0][0]']                 \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block14_sepconv1_bn (BatchNorm  (None, 4, 4, 1536)  6144        ['block14_sepconv1[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block14_sepconv1_act (Activati  (None, 4, 4, 1536)  0           ['block14_sepconv1_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block14_sepconv2 (SeparableCon  (None, 4, 4, 2048)  3159552     ['block14_sepconv1_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block14_sepconv2_bn (BatchNorm  (None, 4, 4, 2048)  8192        ['block14_sepconv2[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block14_sepconv2_act (Activati  (None, 4, 4, 2048)  0           ['block14_sepconv2_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['block14_sepconv2_act[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 106)          217194      ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,078,674\n",
      "Trainable params: 21,024,146\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# case 1: pretrained without weight ............... retraining architechture\n",
    "\n",
    "model_name = 'Xception'\n",
    "\n",
    "\n",
    "exec('from tensorflow.keras.applications import '+ model_name)\n",
    "\n",
    "\n",
    "## case 1:\n",
    "exec('MODEL = '+model_name+'(input_shape=(IMG_SIZE, IMG_SIZE, 3), include_top=True, weights=None, classes = cat_len)')\n",
    "for layers in MODEL.layers: \n",
    "    layers.trainable=True\n",
    "    \n",
    "model1=MODEL\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a88ad52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1\n",
      "Epoch 1/1000\n",
      "487/487 [==============================] - 63s 109ms/step - loss: 3.7314 - accuracy: 0.2713 - val_loss: 4.6753 - val_accuracy: 0.0141\n",
      "Epoch 2/1000\n",
      "487/487 [==============================] - 52s 106ms/step - loss: 1.7711 - accuracy: 0.6485 - val_loss: 1.3053 - val_accuracy: 0.7323\n",
      "Epoch 3/1000\n",
      "487/487 [==============================] - 51s 105ms/step - loss: 0.6426 - accuracy: 0.9030 - val_loss: 0.3689 - val_accuracy: 0.9472\n",
      "Epoch 4/1000\n",
      "487/487 [==============================] - 51s 105ms/step - loss: 0.2184 - accuracy: 0.9793 - val_loss: 0.1646 - val_accuracy: 0.9762\n",
      "Epoch 5/1000\n",
      "487/487 [==============================] - 51s 105ms/step - loss: 0.0854 - accuracy: 0.9959 - val_loss: 0.1011 - val_accuracy: 0.9857\n",
      "Epoch 6/1000\n",
      "487/487 [==============================] - 51s 104ms/step - loss: 0.0389 - accuracy: 0.9996 - val_loss: 0.0638 - val_accuracy: 0.9920\n",
      "Epoch 7/1000\n",
      "487/487 [==============================] - 51s 105ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9926\n",
      "Epoch 8/1000\n",
      "487/487 [==============================] - 51s 104ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 0.9936\n",
      "Epoch 9/1000\n",
      "487/487 [==============================] - 51s 105ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0332 - val_accuracy: 0.9937\n",
      "Epoch 10/1000\n",
      "487/487 [==============================] - 51s 105ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.9942\n",
      "Epoch 11/1000\n",
      "487/487 [==============================] - 51s 105ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9945\n",
      "Epoch 12/1000\n",
      "487/487 [==============================] - 51s 106ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9946\n",
      "Epoch 13/1000\n",
      "487/487 [==============================] - 51s 105ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 0.9951\n",
      "Epoch 14/1000\n",
      "487/487 [==============================] - 51s 106ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9952\n",
      "Epoch 15/1000\n",
      "487/487 [==============================] - 51s 105ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 0.9954\n",
      "Epoch 16/1000\n",
      "487/487 [==============================] - 51s 105ms/step - loss: 8.6793e-04 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9952\n",
      "Epoch 17/1000\n",
      "487/487 [==============================] - 51s 105ms/step - loss: 6.5281e-04 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9962\n",
      "Epoch 18/1000\n",
      "487/487 [==============================] - 52s 106ms/step - loss: 4.9686e-04 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9959\n",
      "Epoch 19/1000\n",
      "487/487 [==============================] - 51s 106ms/step - loss: 3.8381e-04 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9958\n",
      "Epoch 20/1000\n",
      "487/487 [==============================] - 52s 106ms/step - loss: 2.9159e-04 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9957\n",
      "Epoch 21/1000\n",
      "487/487 [==============================] - 51s 106ms/step - loss: 2.2638e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9959\n",
      "Epoch 22/1000\n",
      "487/487 [==============================] - 52s 106ms/step - loss: 1.7326e-04 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 0.9958\n",
      "Epoch 23/1000\n",
      "487/487 [==============================] - 51s 106ms/step - loss: 1.3234e-04 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9959\n",
      "Epoch 24/1000\n",
      "487/487 [==============================] - 51s 106ms/step - loss: 1.0433e-04 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9964\n",
      "Epoch 25/1000\n",
      "487/487 [==============================] - 51s 105ms/step - loss: 7.8413e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9961\n",
      "Epoch 26/1000\n",
      "487/487 [==============================] - 51s 106ms/step - loss: 6.2142e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9965\n",
      "Epoch 27/1000\n",
      "487/487 [==============================] - 51s 106ms/step - loss: 4.9370e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9963\n",
      "Epoch 28/1000\n",
      "487/487 [==============================] - 51s 106ms/step - loss: 3.9167e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9964\n",
      "Epoch 29/1000\n",
      "487/487 [==============================] - 51s 105ms/step - loss: 3.0001e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9960\n",
      "Epoch 30/1000\n",
      "487/487 [==============================] - 51s 106ms/step - loss: 2.4800e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9964\n",
      "Epoch 31/1000\n",
      "487/487 [==============================] - 51s 105ms/step - loss: 1.8293e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9968\n",
      "Epoch 32/1000\n",
      "487/487 [==============================] - 51s 106ms/step - loss: 1.4488e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9965\n",
      "Epoch 33/1000\n",
      "487/487 [==============================] - 51s 106ms/step - loss: 1.1854e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9965\n",
      "Epoch 34/1000\n",
      "487/487 [==============================] - 51s 106ms/step - loss: 9.2361e-06 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9967\n",
      "Epoch 35/1000\n",
      "487/487 [==============================] - 52s 106ms/step - loss: 7.0310e-06 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9967\n",
      "Epoch 36/1000\n",
      "487/487 [==============================] - 51s 106ms/step - loss: 5.6692e-06 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9965\n",
      "Epoch 37/1000\n",
      "487/487 [==============================] - 51s 106ms/step - loss: 4.6717e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9968\n",
      "Epoch 38/1000\n",
      "487/487 [==============================] - 51s 105ms/step - loss: 3.6437e-06 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9965\n",
      "Epoch 39/1000\n",
      "487/487 [==============================] - 51s 105ms/step - loss: 3.2142e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9966\n",
      "Epoch 40/1000\n",
      "487/487 [==============================] - 51s 105ms/step - loss: 2.4693e-06 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9969\n",
      "Epoch 41/1000\n",
      "487/487 [==============================] - 51s 106ms/step - loss: 2.0915e-06 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9969\n",
      "Epoch 42/1000\n",
      "487/487 [==============================] - 51s 105ms/step - loss: 1.7890e-06 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9962\n",
      "Epoch 43/1000\n",
      "487/487 [==============================] - 51s 105ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.0902 - val_accuracy: 0.9767\n",
      "Epoch 44/1000\n",
      "487/487 [==============================] - 51s 106ms/step - loss: 5.3018e-04 - accuracy: 0.9998 - val_loss: 0.0147 - val_accuracy: 0.9961\n",
      "Epoch 45/1000\n",
      "487/487 [==============================] - 52s 106ms/step - loss: 9.7181e-05 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9963\n",
      "Epoch 46/1000\n",
      "487/487 [==============================] - 51s 106ms/step - loss: 5.8923e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9969\n",
      "Epoch 47/1000\n",
      "487/487 [==============================] - 52s 106ms/step - loss: 4.1300e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9969\n",
      "Epoch 48/1000\n",
      "487/487 [==============================] - 52s 106ms/step - loss: 3.2811e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9969\n",
      "Epoch 49/1000\n",
      "487/487 [==============================] - 51s 106ms/step - loss: 2.5296e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9970\n",
      "Epoch 50/1000\n",
      "487/487 [==============================] - 51s 106ms/step - loss: 1.9623e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9969\n"
     ]
    }
   ],
   "source": [
    "print('Training model 1')\n",
    "opt = Adam(learning_rate=0.00001)\n",
    "earlystopping = callbacks.EarlyStopping(monitor=\"val_loss\", patience = 10, restore_best_weights = True)\n",
    "model1.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "# model1.summary()\n",
    "\n",
    "\n",
    "\n",
    "history_const = model1.fit(X_train, y_train,batch_size=50, epochs = 1000, validation_data=(X_test,y_test),\n",
    "                   callbacks= [earlystopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5b72d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving\n"
     ]
    }
   ],
   "source": [
    "print('Saving')\n",
    "np.save(load_path+model_name1+'_history.npy',history_const.history)\n",
    "model1.save(load_path+model_name1+'_model.h5') \n",
    "print(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40f84c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #load saved history\n",
    "# history_const=np.load(load_path+model_name1+'_history.npy',allow_pickle='TRUE').item()\n",
    "\n",
    "# # #load saved model\n",
    "# model1=load_model(load_path+model_name1+'_model.h5')\n",
    "\n",
    "# print(\"loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "caf213f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Plots')\n",
    "plt.plot(history_const.history['loss'])\n",
    "plt.plot(history_const.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "# plt.savefig('F:/VA/onehandtwohand/26words_DSLR_results/'+model_name1+'_loss.png')\n",
    "plt.savefig(load_path+model_name1+'_loss.png')\n",
    "plt.show()\n",
    "plt.plot(history_const.history['accuracy'])\n",
    "plt.plot(history_const.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig(load_path+model_name1+'_accuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4006fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion matrix')\n",
    "Y_pred = model1.predict(X_new)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_test1 = np.argmax(y_new, axis=1)\n",
    "\n",
    "cm=metrics.confusion_matrix(y_test1, y_pred)\n",
    "\n",
    "\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "a4_dims = (200, 100)\n",
    "fig,ax= plt.subplots(figsize=a4_dims)\n",
    "sns.heatmap(cm, annot=True, fmt=\".2f\", ax=ax,  linewidth=.5);  \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.set_xticklabels(CATEGORIES)\n",
    "ax.set_yticklabels(CATEGORIES)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.setp(ax.get_xticklabels(), rotation=90, horizontalalignment='right')\n",
    "plt.setp(ax.get_yticklabels(), rotation=0, horizontalalignment='right')\n",
    "plt.savefig(load_path+model_name1+'_cm.png',bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57902f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLot fractional incorrect misclassifications\n",
    "\n",
    "incorr_fraction = 1 - np.diag(cm) / np.sum(cm, axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plt.bar(np.arange(cat_len), incorr_fraction)\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Fraction of incorrect predictions')\n",
    "plt.xticks(np.arange(cat_len), CATEGORIES)\n",
    "plt.savefig(load_path+model_name1+'_incorrect_percentage.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c596ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK RANDOM IMAGES FROM TESTED DATA WHETHER RIGHT OR WRONG\n",
    "\n",
    "i = random.randint(1,cat_len)\n",
    "plt.imshow(X_new[i,:,:,2]) \n",
    "print(\"Predicted Label: \", CATEGORIES[int(y_pred[i])])\n",
    "print(\"True Label: \", CATEGORIES[int(y_test1[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fc757b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "794a50d2",
   "metadata": {},
   "source": [
    "# Colourful mediapipe testing with VA_create_3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f40106c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "    \n",
    "def draw_landmarks(image, results):   \n",
    "    #face\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        results.face_landmarks,\n",
    "        mp_holistic.FACEMESH_CONTOURS,\n",
    "        landmark_drawing_spec=None,\n",
    "        connection_drawing_spec=mp_drawing_styles\n",
    "        .get_default_face_mesh_contours_style())\n",
    "#     #pose\n",
    "#     mp_drawing.draw_landmarks(\n",
    "#         image,\n",
    "#         results.pose_landmarks,\n",
    "#         mp_holistic.POSE_CONNECTIONS,\n",
    "#         landmark_drawing_spec=mp_drawing_styles\n",
    "#         .get_default_pose_landmarks_style())\n",
    "    \n",
    "    #left hand\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        results.left_hand_landmarks,\n",
    "        mp_holistic.HAND_CONNECTIONS,\n",
    "#         landmark_drawing_spec=None,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())\n",
    "    # right hand\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        results.right_hand_landmarks,\n",
    "        mp_holistic.HAND_CONNECTIONS,\n",
    "#         landmark_drawing_spec=None,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a1bc8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    }
   ],
   "source": [
    "## For veryyyyyyyy beautiful webcam input:\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "org = (20, 20)  \n",
    "org1 = (310, 20) \n",
    "fontScale = 0.65  \n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "# Blue color in BGR\n",
    "color = (130, 0, 0)  \n",
    "# Line thickness of 2 px\n",
    "thickness = 1 \n",
    "thickness1 = -1\n",
    "start_point = (0,0)\n",
    "end_point = (480,30)\n",
    "color1 = (255, 255, 255)  \n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "      while cap.isOpened():\n",
    "        #image from feeder\n",
    "        r, img_array = cap.read()\n",
    "        img_array = cv2.flip(img_array, 1)\n",
    "        img_array = img_array[:, 80:560, :]\n",
    "        image, results = mediapipe_detection(img_array, holistic)\n",
    "        draw_landmarks(image, results)\n",
    "        if not (results.left_hand_landmarks or results.right_hand_landmarks):\n",
    "            continue\n",
    "\n",
    "        # white background\n",
    "        img = np.zeros([480,480,3],dtype=np.uint8)\n",
    "        img.fill(255) \n",
    "        draw_landmarks(img, results)\n",
    "\n",
    "        # for prediction\n",
    "        IMG_SIZE=128\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        X = np.array(img).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "        X = X.astype('float32')\n",
    "        X /= 255\n",
    "        X = np.array(X)\n",
    "        Y = model1.predict(X,verbose=1)\n",
    "\n",
    "        if np.max(Y)>0.2:\n",
    "            # for display\n",
    "            image = cv2.rectangle(image, start_point, end_point, color1, thickness1)\n",
    "            image = cv2.rectangle(image, (0,30), (480,30), color, 2)\n",
    "            image = cv2.putText(image,\"Prediction: \"+ CATEGORIES[np.argmax(Y)], org, font, \n",
    "                   fontScale, color, thickness, cv2.LINE_AA)\n",
    "            image = cv2.putText(image,\"Accuracy: \"+ \"%.2f\" % np.max(Y), org1, font, \n",
    "                   fontScale, color, thickness, cv2.LINE_AA)\n",
    "            #if np.max(Y)>0.95:\n",
    "                #cv2.imwrite(load_path+'/test_images/'+CATEGORIES[np.argmax(Y)]+str(np.max(Y))+'.jpg',image)\n",
    "\n",
    "\n",
    "        cv2.imshow('Realtime testing', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "# close the camera\n",
    "cap.release()\n",
    "\n",
    "# close all the opened windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c88845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
