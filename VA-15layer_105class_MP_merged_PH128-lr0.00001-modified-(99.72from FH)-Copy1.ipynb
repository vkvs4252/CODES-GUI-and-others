{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d962aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dropout, BatchNormalization, Dense, Flatten, LayerNormalization\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.applications as appl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from keras import callbacks  \n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13774f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path='E:/VA/onehandtwohand/128/DSLR testing/105words_dataset_DSLR/'\n",
    "# model\n",
    "\n",
    "\n",
    "# model_name1 = '15layer_105words_dslr128'\n",
    "model_name1 = '15layer_lr0.00001_105words_dslr128-99.54'\n",
    "#model_name1 = 'densenet121_lr0.00001_105words_dslr128'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f40f84c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "# #load saved history\n",
    "#history_const=np.load(load_path+model_name1+'_history.npy',allow_pickle='TRUE').item()\n",
    "\n",
    "# #load saved model\n",
    "model1=load_model(load_path+model_name1+'_model.h5')\n",
    "\n",
    "print(\"loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c285bf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    }
   ],
   "source": [
    "CATEGORIES=np.load(load_path+'cat_105.npy', allow_pickle=True)\n",
    "cat_len=len(CATEGORIES)\n",
    "print(cat_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794a50d2",
   "metadata": {},
   "source": [
    "# Colourful mediapipe testing with VA_create_3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f40106c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "    \n",
    "def draw_landmarks(image, results):   \n",
    "    #face\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        results.face_landmarks,\n",
    "        mp_holistic.FACEMESH_CONTOURS,\n",
    "        landmark_drawing_spec=None,\n",
    "        connection_drawing_spec=mp_drawing_styles\n",
    "        .get_default_face_mesh_contours_style())\n",
    "#     #pose\n",
    "#     mp_drawing.draw_landmarks(\n",
    "#         image,\n",
    "#         results.pose_landmarks,\n",
    "#         mp_holistic.POSE_CONNECTIONS,\n",
    "#         landmark_drawing_spec=mp_drawing_styles\n",
    "#         .get_default_pose_landmarks_style())\n",
    "    \n",
    "    #left hand\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        results.left_hand_landmarks,\n",
    "        mp_holistic.HAND_CONNECTIONS,\n",
    "#         landmark_drawing_spec=None,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())\n",
    "    # right hand\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        results.right_hand_landmarks,\n",
    "        mp_holistic.HAND_CONNECTIONS,\n",
    "#         landmark_drawing_spec=None,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22a3daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DSLR\n",
    "########## For veryyyyyyyy beautiful webcam input:\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "org = (20, 20)  \n",
    "org1 = (310, 20) \n",
    "fontScale = 0.65  \n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "# Blue color in BGR\n",
    "color = (130, 0, 0)  \n",
    "# Line thickness of 2 px\n",
    "thickness = 1 \n",
    "thickness1 = -1\n",
    "start_point = (0,0)\n",
    "end_point = (480,30)\n",
    "color1 = (255, 255, 255)  \n",
    "\n",
    "with mp_holistic.Holistic(static_image_mode=False,min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "      while cap.isOpened():\n",
    "        #image from feeder\n",
    "        r, img_array = cap.read()\n",
    "        img_array = cv2.flip(img_array, 1)\n",
    "        #webcam\n",
    "#         img_array = img_array[:, 80:560, :]\n",
    "        #dslr\n",
    "        img_array = img_array[:, 224:800, :]\n",
    "        img_array = cv2.resize(img_array, (480, 480))\n",
    "\n",
    "        image, results = mediapipe_detection(img_array, holistic)\n",
    "        draw_landmarks(image, results)\n",
    "        if not (results.left_hand_landmarks or results.right_hand_landmarks):\n",
    "            continue\n",
    "\n",
    "        # white background\n",
    "        img = np.zeros([480,480,3],dtype=np.uint8)\n",
    "        img.fill(255) \n",
    "        draw_landmarks(img, results)\n",
    "\n",
    "        # for prediction\n",
    "        IMG_SIZE=128\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        X = np.array(img).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "        X = X.astype('float32')\n",
    "        X /= 255\n",
    "        X = np.array(X)\n",
    "        Y = model1.predict(X,verbose=0)\n",
    "\n",
    "        if np.max(Y)>0.0:\n",
    "            # for display\n",
    "            image = cv2.rectangle(image, start_point, end_point, color1, thickness1)\n",
    "            image = cv2.rectangle(image, (0,30), (480,30), color, 2)\n",
    "            image = cv2.putText(image,\"Prediction: \"+ CATEGORIES[np.argmax(Y)], org, font, \n",
    "                   fontScale, color, thickness, cv2.LINE_AA)\n",
    "            image = cv2.putText(image,\"Accuracy: \"+ \"%.2f\" % np.max(Y), org1, font, \n",
    "                   fontScale, color, thickness, cv2.LINE_AA)\n",
    "#             if np.max(Y)>0.95:\n",
    "#                 cv2.imwrite(load_path+'/15layer_test_images/'+CATEGORIES[np.argmax(Y)]+str(np.max(Y))+'.jpg',image)\n",
    "\n",
    "\n",
    "        cv2.imshow('Realtime testing', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "# close the camera\n",
    "cap.release()\n",
    "\n",
    "# close all the opened windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c88845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7fe359",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
