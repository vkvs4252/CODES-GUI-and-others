{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d962aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dropout, BatchNormalization, Dense, Flatten, LayerNormalization\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.applications as appl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from keras import callbacks  \n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13774f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path='E:/VA/onehandtwohand/128/106words_DSLR_FH/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edaddf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES=np.load(load_path+'cat_106.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "659cb729",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12d7e2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n"
     ]
    }
   ],
   "source": [
    "cat_len=len(CATEGORIES)\n",
    "print(cat_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc104aa6",
   "metadata": {},
   "source": [
    "# Save combined data npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4dd8029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "# model_name1 = 'InceptionResNetV2'\n",
    "# model_name1 = '4layer'\n",
    "model_name1 = 'depthwise4_106words_dslr128'\n",
    "#model_name2 = 'VGG16'\n",
    "# model_name1 = 'DenseNet121'\n",
    "# model_name1 = 'InceptionV3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa37bec1",
   "metadata": {},
   "source": [
    "Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0def0f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load(load_path+'X_dslr.npy', allow_pickle=True)\n",
    "Y=np.load(load_path+'Y_dslr.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bac9e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype('float32')\n",
    "X /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89586ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting\n",
      "pass\n"
     ]
    }
   ],
   "source": [
    "print('Splitting') \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = cat_len)\n",
    "X_train, X_new, y_train, y_new = train_test_split(X_train, y_train, test_size = 0.2, random_state = cat_len)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "X_new = np.array(X_new)\n",
    "y_new = np.array(y_new)\n",
    "\n",
    "print(\"pass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f26320e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f75aadef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Data Augmentation\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('Image Data Augmentation')\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "val_generator = ImageDataGenerator(rotation_range=0, zoom_range=0.2, width_shift_range=0.2,\n",
    "    height_shift_range=0.2, shear_range=0.2)\n",
    "#                                     , horizontal_flip=True, brightness_range=[0.6,1.3])\n",
    "val_generator.fit(X_train)\n",
    "val_generator.fit(X_new)\n",
    "val_generator.fit(X_test)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48682243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " depthwise_conv2d_4 (Depthwi  (None, 128, 128, 3)      30        \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 128, 128, 3)      12        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 64, 64, 3)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " depthwise_conv2d_5 (Depthwi  (None, 64, 64, 3)        30        \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 64, 64, 3)        12        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 32, 32, 3)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " depthwise_conv2d_6 (Depthwi  (None, 32, 32, 3)        30        \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 32, 32, 3)        12        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 16, 16, 3)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " depthwise_conv2d_7 (Depthwi  (None, 16, 16, 3)        30        \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 16, 16, 3)        12        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 8, 8, 3)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              197632    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 106)               108650    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 306,450\n",
      "Trainable params: 306,426\n",
      "Non-trainable params: 24\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    # First layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu', input_shape=(128, 128, 3)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Second layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Third layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Fourth layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Flatten the output from convolutional layers\n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    # Add a dense layer to learn the final classification\n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    # Output layer with softmax activation function for multi-class classification\n",
    "    tf.keras.layers.Dense(106, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a88ad52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1\n",
      "Epoch 1/1000\n",
      "487/487 [==============================] - 21s 39ms/step - loss: 5.1424 - accuracy: 0.0127 - val_loss: 4.5525 - val_accuracy: 0.0284\n",
      "Epoch 2/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 4.7912 - accuracy: 0.0252 - val_loss: 4.3894 - val_accuracy: 0.0571\n",
      "Epoch 3/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 4.5396 - accuracy: 0.0462 - val_loss: 4.1721 - val_accuracy: 0.1064\n",
      "Epoch 4/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 4.3258 - accuracy: 0.0695 - val_loss: 3.9889 - val_accuracy: 0.1485\n",
      "Epoch 5/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 4.1476 - accuracy: 0.0989 - val_loss: 3.8416 - val_accuracy: 0.1803\n",
      "Epoch 6/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 3.9805 - accuracy: 0.1237 - val_loss: 3.7118 - val_accuracy: 0.2013\n",
      "Epoch 7/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 3.8469 - accuracy: 0.1437 - val_loss: 3.5942 - val_accuracy: 0.2190\n",
      "Epoch 8/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 3.7300 - accuracy: 0.1591 - val_loss: 3.4874 - val_accuracy: 0.2353\n",
      "Epoch 9/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 3.6113 - accuracy: 0.1779 - val_loss: 3.3880 - val_accuracy: 0.2501\n",
      "Epoch 10/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 3.5117 - accuracy: 0.1990 - val_loss: 3.2962 - val_accuracy: 0.2628\n",
      "Epoch 11/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 3.4215 - accuracy: 0.2088 - val_loss: 3.2058 - val_accuracy: 0.2741\n",
      "Epoch 12/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 3.3444 - accuracy: 0.2160 - val_loss: 3.1268 - val_accuracy: 0.2866\n",
      "Epoch 13/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 3.2552 - accuracy: 0.2353 - val_loss: 3.0495 - val_accuracy: 0.2976\n",
      "Epoch 14/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 3.1849 - accuracy: 0.2396 - val_loss: 2.9790 - val_accuracy: 0.3089\n",
      "Epoch 15/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 3.1098 - accuracy: 0.2539 - val_loss: 2.9153 - val_accuracy: 0.3205\n",
      "Epoch 16/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 3.0575 - accuracy: 0.2629 - val_loss: 2.8510 - val_accuracy: 0.3295\n",
      "Epoch 17/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 2.9899 - accuracy: 0.2712 - val_loss: 2.7962 - val_accuracy: 0.3381\n",
      "Epoch 18/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 2.9417 - accuracy: 0.2783 - val_loss: 2.7419 - val_accuracy: 0.3434\n",
      "Epoch 19/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 2.8885 - accuracy: 0.2859 - val_loss: 2.6940 - val_accuracy: 0.3511\n",
      "Epoch 20/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 2.8388 - accuracy: 0.2966 - val_loss: 2.6457 - val_accuracy: 0.3601\n",
      "Epoch 21/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 2.8058 - accuracy: 0.3023 - val_loss: 2.6009 - val_accuracy: 0.3664\n",
      "Epoch 22/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 2.7425 - accuracy: 0.3114 - val_loss: 2.5568 - val_accuracy: 0.3731\n",
      "Epoch 23/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 2.7035 - accuracy: 0.3234 - val_loss: 2.5155 - val_accuracy: 0.3809\n",
      "Epoch 24/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 2.6708 - accuracy: 0.3244 - val_loss: 2.4790 - val_accuracy: 0.3880\n",
      "Epoch 25/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 2.6296 - accuracy: 0.3319 - val_loss: 2.4391 - val_accuracy: 0.3931\n",
      "Epoch 26/1000\n",
      "487/487 [==============================] - 18s 38ms/step - loss: 2.5907 - accuracy: 0.3347 - val_loss: 2.4039 - val_accuracy: 0.4013\n",
      "Epoch 27/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 2.5543 - accuracy: 0.3435 - val_loss: 2.3661 - val_accuracy: 0.4097\n",
      "Epoch 28/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 2.5198 - accuracy: 0.3477 - val_loss: 2.3306 - val_accuracy: 0.4161\n",
      "Epoch 29/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 2.4849 - accuracy: 0.3528 - val_loss: 2.2953 - val_accuracy: 0.4231\n",
      "Epoch 30/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 2.4535 - accuracy: 0.3588 - val_loss: 2.2654 - val_accuracy: 0.4302\n",
      "Epoch 31/1000\n",
      "487/487 [==============================] - 19s 38ms/step - loss: 2.4278 - accuracy: 0.3667 - val_loss: 2.2303 - val_accuracy: 0.4349\n",
      "Epoch 32/1000\n",
      "487/487 [==============================] - 18s 38ms/step - loss: 2.3906 - accuracy: 0.3695 - val_loss: 2.1988 - val_accuracy: 0.4416\n",
      "Epoch 33/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 2.3611 - accuracy: 0.3786 - val_loss: 2.1685 - val_accuracy: 0.4485\n",
      "Epoch 34/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 2.3320 - accuracy: 0.3846 - val_loss: 2.1404 - val_accuracy: 0.4549\n",
      "Epoch 35/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 2.2865 - accuracy: 0.3919 - val_loss: 2.1066 - val_accuracy: 0.4600\n",
      "Epoch 36/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 2.2638 - accuracy: 0.3950 - val_loss: 2.0811 - val_accuracy: 0.4674\n",
      "Epoch 37/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 2.2428 - accuracy: 0.4044 - val_loss: 2.0523 - val_accuracy: 0.4727\n",
      "Epoch 38/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 2.2071 - accuracy: 0.4111 - val_loss: 2.0261 - val_accuracy: 0.4787\n",
      "Epoch 39/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 2.1784 - accuracy: 0.4174 - val_loss: 2.0005 - val_accuracy: 0.4840\n",
      "Epoch 40/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 2.1598 - accuracy: 0.4155 - val_loss: 1.9746 - val_accuracy: 0.4901\n",
      "Epoch 41/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 2.1273 - accuracy: 0.4274 - val_loss: 1.9509 - val_accuracy: 0.4958\n",
      "Epoch 42/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 2.1111 - accuracy: 0.4251 - val_loss: 1.9257 - val_accuracy: 0.5001\n",
      "Epoch 43/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 2.0758 - accuracy: 0.4368 - val_loss: 1.9026 - val_accuracy: 0.5048\n",
      "Epoch 44/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 2.0583 - accuracy: 0.4385 - val_loss: 1.8812 - val_accuracy: 0.5089\n",
      "Epoch 45/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 2.0359 - accuracy: 0.4429 - val_loss: 1.8564 - val_accuracy: 0.5163\n",
      "Epoch 46/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 2.0159 - accuracy: 0.4489 - val_loss: 1.8351 - val_accuracy: 0.5216\n",
      "Epoch 47/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.9885 - accuracy: 0.4548 - val_loss: 1.8136 - val_accuracy: 0.5253\n",
      "Epoch 48/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.9576 - accuracy: 0.4635 - val_loss: 1.7936 - val_accuracy: 0.5300\n",
      "Epoch 49/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 1.9493 - accuracy: 0.4659 - val_loss: 1.7715 - val_accuracy: 0.5352\n",
      "Epoch 50/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 1.9307 - accuracy: 0.4668 - val_loss: 1.7507 - val_accuracy: 0.5405\n",
      "Epoch 51/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 1.8962 - accuracy: 0.4752 - val_loss: 1.7280 - val_accuracy: 0.5450\n",
      "Epoch 52/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.8836 - accuracy: 0.4809 - val_loss: 1.7106 - val_accuracy: 0.5510\n",
      "Epoch 53/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.8607 - accuracy: 0.4874 - val_loss: 1.6894 - val_accuracy: 0.5578\n",
      "Epoch 54/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.8410 - accuracy: 0.4888 - val_loss: 1.6706 - val_accuracy: 0.5631\n",
      "Epoch 55/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.8161 - accuracy: 0.4933 - val_loss: 1.6486 - val_accuracy: 0.5691\n",
      "Epoch 56/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.8010 - accuracy: 0.5024 - val_loss: 1.6297 - val_accuracy: 0.5719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.7795 - accuracy: 0.5060 - val_loss: 1.6115 - val_accuracy: 0.5776\n",
      "Epoch 58/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.7611 - accuracy: 0.5084 - val_loss: 1.5951 - val_accuracy: 0.5831\n",
      "Epoch 59/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 1.7379 - accuracy: 0.5161 - val_loss: 1.5749 - val_accuracy: 0.5877\n",
      "Epoch 60/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 1.7161 - accuracy: 0.5223 - val_loss: 1.5574 - val_accuracy: 0.5932\n",
      "Epoch 61/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 1.7002 - accuracy: 0.5244 - val_loss: 1.5373 - val_accuracy: 0.5977\n",
      "Epoch 62/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.6876 - accuracy: 0.5269 - val_loss: 1.5202 - val_accuracy: 0.6029\n",
      "Epoch 63/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.6662 - accuracy: 0.5316 - val_loss: 1.5022 - val_accuracy: 0.6069\n",
      "Epoch 64/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.6436 - accuracy: 0.5380 - val_loss: 1.4850 - val_accuracy: 0.6113\n",
      "Epoch 65/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.6288 - accuracy: 0.5426 - val_loss: 1.4684 - val_accuracy: 0.6167\n",
      "Epoch 66/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 1.6004 - accuracy: 0.5497 - val_loss: 1.4501 - val_accuracy: 0.6210\n",
      "Epoch 67/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 1.5800 - accuracy: 0.5560 - val_loss: 1.4319 - val_accuracy: 0.6257\n",
      "Epoch 68/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 1.5749 - accuracy: 0.5560 - val_loss: 1.4159 - val_accuracy: 0.6316\n",
      "Epoch 69/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 1.5518 - accuracy: 0.5605 - val_loss: 1.4007 - val_accuracy: 0.6353\n",
      "Epoch 70/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 1.5360 - accuracy: 0.5664 - val_loss: 1.3844 - val_accuracy: 0.6400\n",
      "Epoch 71/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 1.5196 - accuracy: 0.5749 - val_loss: 1.3685 - val_accuracy: 0.6426\n",
      "Epoch 72/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.5063 - accuracy: 0.5755 - val_loss: 1.3521 - val_accuracy: 0.6467\n",
      "Epoch 73/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.4872 - accuracy: 0.5779 - val_loss: 1.3352 - val_accuracy: 0.6528\n",
      "Epoch 74/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.4704 - accuracy: 0.5838 - val_loss: 1.3215 - val_accuracy: 0.6559\n",
      "Epoch 75/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.4500 - accuracy: 0.5879 - val_loss: 1.3076 - val_accuracy: 0.6594\n",
      "Epoch 76/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.4320 - accuracy: 0.5974 - val_loss: 1.2932 - val_accuracy: 0.6629\n",
      "Epoch 77/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.4178 - accuracy: 0.5982 - val_loss: 1.2787 - val_accuracy: 0.6669\n",
      "Epoch 78/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.4100 - accuracy: 0.5995 - val_loss: 1.2653 - val_accuracy: 0.6707\n",
      "Epoch 79/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.3807 - accuracy: 0.6085 - val_loss: 1.2498 - val_accuracy: 0.6736\n",
      "Epoch 80/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.3746 - accuracy: 0.6103 - val_loss: 1.2374 - val_accuracy: 0.6776\n",
      "Epoch 81/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.3639 - accuracy: 0.6133 - val_loss: 1.2227 - val_accuracy: 0.6810\n",
      "Epoch 82/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.3527 - accuracy: 0.6137 - val_loss: 1.2107 - val_accuracy: 0.6840\n",
      "Epoch 83/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.3357 - accuracy: 0.6234 - val_loss: 1.1972 - val_accuracy: 0.6872\n",
      "Epoch 84/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.3226 - accuracy: 0.6239 - val_loss: 1.1865 - val_accuracy: 0.6902\n",
      "Epoch 85/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.3126 - accuracy: 0.6280 - val_loss: 1.1726 - val_accuracy: 0.6952\n",
      "Epoch 86/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.2926 - accuracy: 0.6300 - val_loss: 1.1594 - val_accuracy: 0.6988\n",
      "Epoch 87/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.2836 - accuracy: 0.6340 - val_loss: 1.1479 - val_accuracy: 0.7024\n",
      "Epoch 88/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.2723 - accuracy: 0.6344 - val_loss: 1.1368 - val_accuracy: 0.7056\n",
      "Epoch 89/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.2547 - accuracy: 0.6460 - val_loss: 1.1256 - val_accuracy: 0.7080\n",
      "Epoch 90/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.2478 - accuracy: 0.6437 - val_loss: 1.1153 - val_accuracy: 0.7107\n",
      "Epoch 91/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.2337 - accuracy: 0.6447 - val_loss: 1.1033 - val_accuracy: 0.7127\n",
      "Epoch 92/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.2196 - accuracy: 0.6511 - val_loss: 1.0931 - val_accuracy: 0.7154\n",
      "Epoch 93/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.2095 - accuracy: 0.6535 - val_loss: 1.0824 - val_accuracy: 0.7190\n",
      "Epoch 94/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.1905 - accuracy: 0.6580 - val_loss: 1.0696 - val_accuracy: 0.7205\n",
      "Epoch 95/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.1878 - accuracy: 0.6604 - val_loss: 1.0604 - val_accuracy: 0.7230\n",
      "Epoch 96/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.1733 - accuracy: 0.6642 - val_loss: 1.0501 - val_accuracy: 0.7264\n",
      "Epoch 97/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.1637 - accuracy: 0.6660 - val_loss: 1.0403 - val_accuracy: 0.7289\n",
      "Epoch 98/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.1501 - accuracy: 0.6695 - val_loss: 1.0304 - val_accuracy: 0.7300\n",
      "Epoch 99/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.1438 - accuracy: 0.6695 - val_loss: 1.0200 - val_accuracy: 0.7322\n",
      "Epoch 100/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.1300 - accuracy: 0.6778 - val_loss: 1.0112 - val_accuracy: 0.7356\n",
      "Epoch 101/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.1261 - accuracy: 0.6789 - val_loss: 1.0010 - val_accuracy: 0.7375\n",
      "Epoch 102/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.1153 - accuracy: 0.6819 - val_loss: 0.9917 - val_accuracy: 0.7414\n",
      "Epoch 103/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.0958 - accuracy: 0.6859 - val_loss: 0.9825 - val_accuracy: 0.7442\n",
      "Epoch 104/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.0943 - accuracy: 0.6825 - val_loss: 0.9740 - val_accuracy: 0.7452\n",
      "Epoch 105/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.0860 - accuracy: 0.6875 - val_loss: 0.9645 - val_accuracy: 0.7470\n",
      "Epoch 106/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.0681 - accuracy: 0.6907 - val_loss: 0.9543 - val_accuracy: 0.7496\n",
      "Epoch 107/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.0611 - accuracy: 0.6927 - val_loss: 0.9465 - val_accuracy: 0.7523\n",
      "Epoch 108/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.0491 - accuracy: 0.6987 - val_loss: 0.9383 - val_accuracy: 0.7553\n",
      "Epoch 109/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.0455 - accuracy: 0.7009 - val_loss: 0.9318 - val_accuracy: 0.7565\n",
      "Epoch 110/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.0339 - accuracy: 0.7051 - val_loss: 0.9210 - val_accuracy: 0.7574\n",
      "Epoch 111/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 1.0292 - accuracy: 0.7057 - val_loss: 0.9136 - val_accuracy: 0.7599\n",
      "Epoch 112/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 18s 37ms/step - loss: 1.0104 - accuracy: 0.7095 - val_loss: 0.9060 - val_accuracy: 0.7625\n",
      "Epoch 113/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.0060 - accuracy: 0.7103 - val_loss: 0.8969 - val_accuracy: 0.7651\n",
      "Epoch 114/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 1.0025 - accuracy: 0.7096 - val_loss: 0.8887 - val_accuracy: 0.7677\n",
      "Epoch 115/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.9946 - accuracy: 0.7138 - val_loss: 0.8815 - val_accuracy: 0.7691\n",
      "Epoch 116/1000\n",
      "487/487 [==============================] - 18s 38ms/step - loss: 0.9838 - accuracy: 0.7169 - val_loss: 0.8726 - val_accuracy: 0.7717\n",
      "Epoch 117/1000\n",
      "487/487 [==============================] - 19s 38ms/step - loss: 0.9780 - accuracy: 0.7164 - val_loss: 0.8662 - val_accuracy: 0.7749\n",
      "Epoch 118/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.9696 - accuracy: 0.7181 - val_loss: 0.8581 - val_accuracy: 0.7766\n",
      "Epoch 119/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.9613 - accuracy: 0.7232 - val_loss: 0.8499 - val_accuracy: 0.7785\n",
      "Epoch 120/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.9493 - accuracy: 0.7258 - val_loss: 0.8438 - val_accuracy: 0.7803\n",
      "Epoch 121/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.9394 - accuracy: 0.7294 - val_loss: 0.8358 - val_accuracy: 0.7816\n",
      "Epoch 122/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.9399 - accuracy: 0.7285 - val_loss: 0.8294 - val_accuracy: 0.7841\n",
      "Epoch 123/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.9282 - accuracy: 0.7304 - val_loss: 0.8219 - val_accuracy: 0.7867\n",
      "Epoch 124/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.9163 - accuracy: 0.7354 - val_loss: 0.8152 - val_accuracy: 0.7898\n",
      "Epoch 125/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.9128 - accuracy: 0.7369 - val_loss: 0.8101 - val_accuracy: 0.7896\n",
      "Epoch 126/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.9077 - accuracy: 0.7357 - val_loss: 0.8026 - val_accuracy: 0.7921\n",
      "Epoch 127/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.9010 - accuracy: 0.7370 - val_loss: 0.7951 - val_accuracy: 0.7933\n",
      "Epoch 128/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.8889 - accuracy: 0.7424 - val_loss: 0.7875 - val_accuracy: 0.7955\n",
      "Epoch 129/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.8864 - accuracy: 0.7398 - val_loss: 0.7825 - val_accuracy: 0.7973\n",
      "Epoch 130/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.8716 - accuracy: 0.7471 - val_loss: 0.7741 - val_accuracy: 0.7997\n",
      "Epoch 131/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.8583 - accuracy: 0.7518 - val_loss: 0.7687 - val_accuracy: 0.8013\n",
      "Epoch 132/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.8592 - accuracy: 0.7496 - val_loss: 0.7618 - val_accuracy: 0.8025\n",
      "Epoch 133/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.8574 - accuracy: 0.7503 - val_loss: 0.7554 - val_accuracy: 0.8059\n",
      "Epoch 134/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.8492 - accuracy: 0.7523 - val_loss: 0.7496 - val_accuracy: 0.8071\n",
      "Epoch 135/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.8435 - accuracy: 0.7545 - val_loss: 0.7429 - val_accuracy: 0.8083\n",
      "Epoch 136/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.8354 - accuracy: 0.7559 - val_loss: 0.7381 - val_accuracy: 0.8100\n",
      "Epoch 137/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.8227 - accuracy: 0.7589 - val_loss: 0.7294 - val_accuracy: 0.8111\n",
      "Epoch 138/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.8225 - accuracy: 0.7560 - val_loss: 0.7252 - val_accuracy: 0.8131\n",
      "Epoch 139/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.8161 - accuracy: 0.7631 - val_loss: 0.7189 - val_accuracy: 0.8143\n",
      "Epoch 140/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.8046 - accuracy: 0.7658 - val_loss: 0.7139 - val_accuracy: 0.8153\n",
      "Epoch 141/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.7991 - accuracy: 0.7665 - val_loss: 0.7077 - val_accuracy: 0.8167\n",
      "Epoch 142/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.7932 - accuracy: 0.7690 - val_loss: 0.7012 - val_accuracy: 0.8190\n",
      "Epoch 143/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.7872 - accuracy: 0.7726 - val_loss: 0.6954 - val_accuracy: 0.8209\n",
      "Epoch 144/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.7747 - accuracy: 0.7767 - val_loss: 0.6900 - val_accuracy: 0.8225\n",
      "Epoch 145/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.7749 - accuracy: 0.7727 - val_loss: 0.6859 - val_accuracy: 0.8226\n",
      "Epoch 146/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.7745 - accuracy: 0.7726 - val_loss: 0.6802 - val_accuracy: 0.8232\n",
      "Epoch 147/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.7639 - accuracy: 0.7771 - val_loss: 0.6746 - val_accuracy: 0.8258\n",
      "Epoch 148/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.7530 - accuracy: 0.7816 - val_loss: 0.6696 - val_accuracy: 0.8274\n",
      "Epoch 149/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.7486 - accuracy: 0.7814 - val_loss: 0.6624 - val_accuracy: 0.8282\n",
      "Epoch 150/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.7393 - accuracy: 0.7831 - val_loss: 0.6586 - val_accuracy: 0.8295\n",
      "Epoch 151/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.7403 - accuracy: 0.7830 - val_loss: 0.6534 - val_accuracy: 0.8316\n",
      "Epoch 152/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.7351 - accuracy: 0.7842 - val_loss: 0.6468 - val_accuracy: 0.8325\n",
      "Epoch 153/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.7328 - accuracy: 0.7850 - val_loss: 0.6438 - val_accuracy: 0.8344\n",
      "Epoch 154/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.7271 - accuracy: 0.7884 - val_loss: 0.6394 - val_accuracy: 0.8348\n",
      "Epoch 155/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.7147 - accuracy: 0.7927 - val_loss: 0.6338 - val_accuracy: 0.8362\n",
      "Epoch 156/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.7120 - accuracy: 0.7897 - val_loss: 0.6278 - val_accuracy: 0.8385\n",
      "Epoch 157/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.7075 - accuracy: 0.7922 - val_loss: 0.6221 - val_accuracy: 0.8391\n",
      "Epoch 158/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.6923 - accuracy: 0.7976 - val_loss: 0.6181 - val_accuracy: 0.8403\n",
      "Epoch 159/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.6976 - accuracy: 0.7969 - val_loss: 0.6115 - val_accuracy: 0.8417\n",
      "Epoch 160/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.6924 - accuracy: 0.7948 - val_loss: 0.6066 - val_accuracy: 0.8430\n",
      "Epoch 161/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.6864 - accuracy: 0.8015 - val_loss: 0.6030 - val_accuracy: 0.8444\n",
      "Epoch 162/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.6824 - accuracy: 0.8013 - val_loss: 0.5988 - val_accuracy: 0.8456\n",
      "Epoch 163/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.6689 - accuracy: 0.8074 - val_loss: 0.5952 - val_accuracy: 0.8474\n",
      "Epoch 164/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.6741 - accuracy: 0.8029 - val_loss: 0.5902 - val_accuracy: 0.8479\n",
      "Epoch 165/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.6620 - accuracy: 0.8066 - val_loss: 0.5848 - val_accuracy: 0.8486\n",
      "Epoch 166/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.6566 - accuracy: 0.8098 - val_loss: 0.5802 - val_accuracy: 0.8503\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 18s 37ms/step - loss: 0.6524 - accuracy: 0.8107 - val_loss: 0.5757 - val_accuracy: 0.8512\n",
      "Epoch 168/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.6532 - accuracy: 0.8074 - val_loss: 0.5712 - val_accuracy: 0.8529\n",
      "Epoch 169/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.6462 - accuracy: 0.8118 - val_loss: 0.5682 - val_accuracy: 0.8542\n",
      "Epoch 170/1000\n",
      "487/487 [==============================] - 18s 38ms/step - loss: 0.6364 - accuracy: 0.8145 - val_loss: 0.5627 - val_accuracy: 0.8545\n",
      "Epoch 171/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.6363 - accuracy: 0.8145 - val_loss: 0.5588 - val_accuracy: 0.8571\n",
      "Epoch 172/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.6308 - accuracy: 0.8153 - val_loss: 0.5548 - val_accuracy: 0.8586\n",
      "Epoch 173/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.6277 - accuracy: 0.8155 - val_loss: 0.5524 - val_accuracy: 0.8597\n",
      "Epoch 174/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.6239 - accuracy: 0.8175 - val_loss: 0.5474 - val_accuracy: 0.8604\n",
      "Epoch 175/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.6180 - accuracy: 0.8207 - val_loss: 0.5433 - val_accuracy: 0.8626\n",
      "Epoch 176/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.6148 - accuracy: 0.8178 - val_loss: 0.5397 - val_accuracy: 0.8635\n",
      "Epoch 177/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.6123 - accuracy: 0.8215 - val_loss: 0.5348 - val_accuracy: 0.8643\n",
      "Epoch 178/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.6062 - accuracy: 0.8245 - val_loss: 0.5320 - val_accuracy: 0.8650\n",
      "Epoch 179/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.5970 - accuracy: 0.8263 - val_loss: 0.5290 - val_accuracy: 0.8650\n",
      "Epoch 180/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.5952 - accuracy: 0.8245 - val_loss: 0.5261 - val_accuracy: 0.8652\n",
      "Epoch 181/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.5928 - accuracy: 0.8298 - val_loss: 0.5220 - val_accuracy: 0.8684\n",
      "Epoch 182/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.5892 - accuracy: 0.8283 - val_loss: 0.5175 - val_accuracy: 0.8691\n",
      "Epoch 183/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.5873 - accuracy: 0.8290 - val_loss: 0.5141 - val_accuracy: 0.8700\n",
      "Epoch 184/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.5781 - accuracy: 0.8338 - val_loss: 0.5088 - val_accuracy: 0.8719\n",
      "Epoch 185/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.5763 - accuracy: 0.8296 - val_loss: 0.5060 - val_accuracy: 0.8714\n",
      "Epoch 186/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.5736 - accuracy: 0.8329 - val_loss: 0.5023 - val_accuracy: 0.8728\n",
      "Epoch 187/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.5722 - accuracy: 0.8345 - val_loss: 0.4995 - val_accuracy: 0.8738\n",
      "Epoch 188/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.5684 - accuracy: 0.8344 - val_loss: 0.4955 - val_accuracy: 0.8745\n",
      "Epoch 189/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.5639 - accuracy: 0.8345 - val_loss: 0.4931 - val_accuracy: 0.8761\n",
      "Epoch 190/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.5576 - accuracy: 0.8357 - val_loss: 0.4896 - val_accuracy: 0.8766\n",
      "Epoch 191/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.5515 - accuracy: 0.8401 - val_loss: 0.4873 - val_accuracy: 0.8782\n",
      "Epoch 192/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.5511 - accuracy: 0.8382 - val_loss: 0.4816 - val_accuracy: 0.8792\n",
      "Epoch 193/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.5434 - accuracy: 0.8428 - val_loss: 0.4805 - val_accuracy: 0.8795\n",
      "Epoch 194/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.5404 - accuracy: 0.8413 - val_loss: 0.4763 - val_accuracy: 0.8804\n",
      "Epoch 195/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.5366 - accuracy: 0.8458 - val_loss: 0.4710 - val_accuracy: 0.8816\n",
      "Epoch 196/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.5380 - accuracy: 0.8428 - val_loss: 0.4702 - val_accuracy: 0.8818\n",
      "Epoch 197/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.5324 - accuracy: 0.8440 - val_loss: 0.4675 - val_accuracy: 0.8831\n",
      "Epoch 198/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.5285 - accuracy: 0.8465 - val_loss: 0.4631 - val_accuracy: 0.8842\n",
      "Epoch 199/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.5253 - accuracy: 0.8475 - val_loss: 0.4602 - val_accuracy: 0.8847\n",
      "Epoch 200/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.5254 - accuracy: 0.8460 - val_loss: 0.4566 - val_accuracy: 0.8861\n",
      "Epoch 201/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.5208 - accuracy: 0.8495 - val_loss: 0.4567 - val_accuracy: 0.8863\n",
      "Epoch 202/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.5213 - accuracy: 0.8480 - val_loss: 0.4533 - val_accuracy: 0.8864\n",
      "Epoch 203/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.5136 - accuracy: 0.8505 - val_loss: 0.4496 - val_accuracy: 0.8883\n",
      "Epoch 204/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.5104 - accuracy: 0.8521 - val_loss: 0.4462 - val_accuracy: 0.8897\n",
      "Epoch 205/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.5042 - accuracy: 0.8556 - val_loss: 0.4431 - val_accuracy: 0.8901\n",
      "Epoch 206/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4979 - accuracy: 0.8566 - val_loss: 0.4403 - val_accuracy: 0.8897\n",
      "Epoch 207/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.5000 - accuracy: 0.8544 - val_loss: 0.4396 - val_accuracy: 0.8913\n",
      "Epoch 208/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4918 - accuracy: 0.8587 - val_loss: 0.4350 - val_accuracy: 0.8921\n",
      "Epoch 209/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4915 - accuracy: 0.8559 - val_loss: 0.4325 - val_accuracy: 0.8920\n",
      "Epoch 210/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4884 - accuracy: 0.8577 - val_loss: 0.4298 - val_accuracy: 0.8926\n",
      "Epoch 211/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4833 - accuracy: 0.8604 - val_loss: 0.4264 - val_accuracy: 0.8935\n",
      "Epoch 212/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4790 - accuracy: 0.8631 - val_loss: 0.4247 - val_accuracy: 0.8936\n",
      "Epoch 213/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4781 - accuracy: 0.8628 - val_loss: 0.4214 - val_accuracy: 0.8943\n",
      "Epoch 214/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4735 - accuracy: 0.8644 - val_loss: 0.4194 - val_accuracy: 0.8946\n",
      "Epoch 215/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4725 - accuracy: 0.8619 - val_loss: 0.4181 - val_accuracy: 0.8956\n",
      "Epoch 216/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4697 - accuracy: 0.8616 - val_loss: 0.4134 - val_accuracy: 0.8966\n",
      "Epoch 217/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4664 - accuracy: 0.8644 - val_loss: 0.4114 - val_accuracy: 0.8972\n",
      "Epoch 218/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4656 - accuracy: 0.8653 - val_loss: 0.4101 - val_accuracy: 0.8972\n",
      "Epoch 219/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4592 - accuracy: 0.8671 - val_loss: 0.4064 - val_accuracy: 0.8975\n",
      "Epoch 220/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4622 - accuracy: 0.8654 - val_loss: 0.4046 - val_accuracy: 0.8974\n",
      "Epoch 221/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4579 - accuracy: 0.8660 - val_loss: 0.4018 - val_accuracy: 0.8986\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4518 - accuracy: 0.8688 - val_loss: 0.3993 - val_accuracy: 0.8984\n",
      "Epoch 223/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4519 - accuracy: 0.8686 - val_loss: 0.3968 - val_accuracy: 0.8998\n",
      "Epoch 224/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4506 - accuracy: 0.8698 - val_loss: 0.3950 - val_accuracy: 0.8999\n",
      "Epoch 225/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4479 - accuracy: 0.8691 - val_loss: 0.3931 - val_accuracy: 0.9004\n",
      "Epoch 226/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4421 - accuracy: 0.8725 - val_loss: 0.3906 - val_accuracy: 0.9002\n",
      "Epoch 227/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4342 - accuracy: 0.8747 - val_loss: 0.3877 - val_accuracy: 0.9011\n",
      "Epoch 228/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4368 - accuracy: 0.8736 - val_loss: 0.3844 - val_accuracy: 0.9018\n",
      "Epoch 229/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4348 - accuracy: 0.8736 - val_loss: 0.3831 - val_accuracy: 0.9012\n",
      "Epoch 230/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4335 - accuracy: 0.8731 - val_loss: 0.3810 - val_accuracy: 0.9025\n",
      "Epoch 231/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4298 - accuracy: 0.8742 - val_loss: 0.3785 - val_accuracy: 0.9029\n",
      "Epoch 232/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4269 - accuracy: 0.8748 - val_loss: 0.3762 - val_accuracy: 0.9030\n",
      "Epoch 233/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4218 - accuracy: 0.8769 - val_loss: 0.3748 - val_accuracy: 0.9035\n",
      "Epoch 234/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4177 - accuracy: 0.8766 - val_loss: 0.3718 - val_accuracy: 0.9045\n",
      "Epoch 235/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4199 - accuracy: 0.8781 - val_loss: 0.3716 - val_accuracy: 0.9038\n",
      "Epoch 236/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4145 - accuracy: 0.8802 - val_loss: 0.3678 - val_accuracy: 0.9048\n",
      "Epoch 237/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4108 - accuracy: 0.8789 - val_loss: 0.3665 - val_accuracy: 0.9050\n",
      "Epoch 238/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4120 - accuracy: 0.8806 - val_loss: 0.3644 - val_accuracy: 0.9060\n",
      "Epoch 239/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4088 - accuracy: 0.8811 - val_loss: 0.3616 - val_accuracy: 0.9061\n",
      "Epoch 240/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4081 - accuracy: 0.8791 - val_loss: 0.3603 - val_accuracy: 0.9070\n",
      "Epoch 241/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4093 - accuracy: 0.8807 - val_loss: 0.3576 - val_accuracy: 0.9069\n",
      "Epoch 242/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3958 - accuracy: 0.8851 - val_loss: 0.3553 - val_accuracy: 0.9077\n",
      "Epoch 243/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.4027 - accuracy: 0.8834 - val_loss: 0.3549 - val_accuracy: 0.9081\n",
      "Epoch 244/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3992 - accuracy: 0.8830 - val_loss: 0.3514 - val_accuracy: 0.9091\n",
      "Epoch 245/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3917 - accuracy: 0.8886 - val_loss: 0.3499 - val_accuracy: 0.9087\n",
      "Epoch 246/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3927 - accuracy: 0.8869 - val_loss: 0.3492 - val_accuracy: 0.9095\n",
      "Epoch 247/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3915 - accuracy: 0.8865 - val_loss: 0.3463 - val_accuracy: 0.9097\n",
      "Epoch 248/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3859 - accuracy: 0.8868 - val_loss: 0.3463 - val_accuracy: 0.9099\n",
      "Epoch 249/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3859 - accuracy: 0.8895 - val_loss: 0.3426 - val_accuracy: 0.9107\n",
      "Epoch 250/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3802 - accuracy: 0.8892 - val_loss: 0.3403 - val_accuracy: 0.9113\n",
      "Epoch 251/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3774 - accuracy: 0.8903 - val_loss: 0.3387 - val_accuracy: 0.9120\n",
      "Epoch 252/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3775 - accuracy: 0.8907 - val_loss: 0.3377 - val_accuracy: 0.9135\n",
      "Epoch 253/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3747 - accuracy: 0.8917 - val_loss: 0.3345 - val_accuracy: 0.9129\n",
      "Epoch 254/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3772 - accuracy: 0.8896 - val_loss: 0.3333 - val_accuracy: 0.9138\n",
      "Epoch 255/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.3740 - accuracy: 0.8908 - val_loss: 0.3318 - val_accuracy: 0.9140\n",
      "Epoch 256/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3704 - accuracy: 0.8910 - val_loss: 0.3301 - val_accuracy: 0.9138\n",
      "Epoch 257/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3679 - accuracy: 0.8930 - val_loss: 0.3283 - val_accuracy: 0.9140\n",
      "Epoch 258/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3664 - accuracy: 0.8936 - val_loss: 0.3265 - val_accuracy: 0.9147\n",
      "Epoch 259/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3612 - accuracy: 0.8941 - val_loss: 0.3249 - val_accuracy: 0.9153\n",
      "Epoch 260/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3555 - accuracy: 0.8980 - val_loss: 0.3231 - val_accuracy: 0.9154\n",
      "Epoch 261/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3615 - accuracy: 0.8941 - val_loss: 0.3205 - val_accuracy: 0.9160\n",
      "Epoch 262/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3586 - accuracy: 0.8951 - val_loss: 0.3190 - val_accuracy: 0.9170\n",
      "Epoch 263/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3528 - accuracy: 0.8992 - val_loss: 0.3186 - val_accuracy: 0.9164\n",
      "Epoch 264/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3537 - accuracy: 0.8984 - val_loss: 0.3155 - val_accuracy: 0.9169\n",
      "Epoch 265/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3517 - accuracy: 0.8973 - val_loss: 0.3143 - val_accuracy: 0.9176\n",
      "Epoch 266/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3530 - accuracy: 0.8968 - val_loss: 0.3139 - val_accuracy: 0.9173\n",
      "Epoch 267/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3445 - accuracy: 0.9007 - val_loss: 0.3118 - val_accuracy: 0.9176\n",
      "Epoch 268/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3474 - accuracy: 0.9012 - val_loss: 0.3100 - val_accuracy: 0.9180\n",
      "Epoch 269/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3378 - accuracy: 0.9023 - val_loss: 0.3078 - val_accuracy: 0.9183\n",
      "Epoch 270/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3420 - accuracy: 0.8998 - val_loss: 0.3069 - val_accuracy: 0.9184\n",
      "Epoch 271/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3435 - accuracy: 0.8990 - val_loss: 0.3054 - val_accuracy: 0.9195\n",
      "Epoch 272/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3397 - accuracy: 0.9019 - val_loss: 0.3047 - val_accuracy: 0.9203\n",
      "Epoch 273/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3391 - accuracy: 0.9011 - val_loss: 0.3021 - val_accuracy: 0.9203\n",
      "Epoch 274/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3331 - accuracy: 0.9035 - val_loss: 0.3009 - val_accuracy: 0.9202\n",
      "Epoch 275/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3371 - accuracy: 0.9002 - val_loss: 0.2989 - val_accuracy: 0.9209\n",
      "Epoch 276/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3338 - accuracy: 0.9021 - val_loss: 0.2978 - val_accuracy: 0.9219\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3313 - accuracy: 0.9056 - val_loss: 0.2966 - val_accuracy: 0.9219\n",
      "Epoch 278/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3291 - accuracy: 0.9070 - val_loss: 0.2946 - val_accuracy: 0.9224\n",
      "Epoch 279/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3257 - accuracy: 0.9054 - val_loss: 0.2939 - val_accuracy: 0.9226\n",
      "Epoch 280/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3263 - accuracy: 0.9056 - val_loss: 0.2924 - val_accuracy: 0.9229\n",
      "Epoch 281/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3213 - accuracy: 0.9060 - val_loss: 0.2908 - val_accuracy: 0.9234\n",
      "Epoch 282/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3193 - accuracy: 0.9070 - val_loss: 0.2887 - val_accuracy: 0.9241\n",
      "Epoch 283/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3190 - accuracy: 0.9061 - val_loss: 0.2882 - val_accuracy: 0.9242\n",
      "Epoch 284/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3200 - accuracy: 0.9073 - val_loss: 0.2865 - val_accuracy: 0.9245\n",
      "Epoch 285/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3144 - accuracy: 0.9094 - val_loss: 0.2853 - val_accuracy: 0.9246\n",
      "Epoch 286/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3131 - accuracy: 0.9099 - val_loss: 0.2845 - val_accuracy: 0.9252\n",
      "Epoch 287/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3127 - accuracy: 0.9108 - val_loss: 0.2828 - val_accuracy: 0.9249\n",
      "Epoch 288/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3128 - accuracy: 0.9086 - val_loss: 0.2815 - val_accuracy: 0.9255\n",
      "Epoch 289/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3086 - accuracy: 0.9110 - val_loss: 0.2808 - val_accuracy: 0.9262\n",
      "Epoch 290/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3087 - accuracy: 0.9088 - val_loss: 0.2783 - val_accuracy: 0.9260\n",
      "Epoch 291/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3020 - accuracy: 0.9128 - val_loss: 0.2784 - val_accuracy: 0.9270\n",
      "Epoch 292/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3032 - accuracy: 0.9128 - val_loss: 0.2761 - val_accuracy: 0.9269\n",
      "Epoch 293/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3018 - accuracy: 0.9152 - val_loss: 0.2743 - val_accuracy: 0.9278\n",
      "Epoch 294/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3007 - accuracy: 0.9127 - val_loss: 0.2733 - val_accuracy: 0.9278\n",
      "Epoch 295/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.3011 - accuracy: 0.9132 - val_loss: 0.2715 - val_accuracy: 0.9286\n",
      "Epoch 296/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2975 - accuracy: 0.9139 - val_loss: 0.2711 - val_accuracy: 0.9295\n",
      "Epoch 297/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2973 - accuracy: 0.9136 - val_loss: 0.2697 - val_accuracy: 0.9293\n",
      "Epoch 298/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2977 - accuracy: 0.9136 - val_loss: 0.2686 - val_accuracy: 0.9292\n",
      "Epoch 299/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2986 - accuracy: 0.9129 - val_loss: 0.2676 - val_accuracy: 0.9296\n",
      "Epoch 300/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2958 - accuracy: 0.9159 - val_loss: 0.2661 - val_accuracy: 0.9299\n",
      "Epoch 301/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2880 - accuracy: 0.9176 - val_loss: 0.2648 - val_accuracy: 0.9303\n",
      "Epoch 302/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2893 - accuracy: 0.9155 - val_loss: 0.2631 - val_accuracy: 0.9311\n",
      "Epoch 303/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2829 - accuracy: 0.9168 - val_loss: 0.2626 - val_accuracy: 0.9308\n",
      "Epoch 304/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2887 - accuracy: 0.9165 - val_loss: 0.2616 - val_accuracy: 0.9301\n",
      "Epoch 305/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2874 - accuracy: 0.9151 - val_loss: 0.2601 - val_accuracy: 0.9308\n",
      "Epoch 306/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2851 - accuracy: 0.9157 - val_loss: 0.2589 - val_accuracy: 0.9321\n",
      "Epoch 307/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2827 - accuracy: 0.9176 - val_loss: 0.2590 - val_accuracy: 0.9309\n",
      "Epoch 308/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2813 - accuracy: 0.9182 - val_loss: 0.2574 - val_accuracy: 0.9327\n",
      "Epoch 309/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2824 - accuracy: 0.9175 - val_loss: 0.2565 - val_accuracy: 0.9324\n",
      "Epoch 310/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2803 - accuracy: 0.9177 - val_loss: 0.2539 - val_accuracy: 0.9325\n",
      "Epoch 311/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2801 - accuracy: 0.9194 - val_loss: 0.2536 - val_accuracy: 0.9327\n",
      "Epoch 312/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2775 - accuracy: 0.9204 - val_loss: 0.2523 - val_accuracy: 0.9332\n",
      "Epoch 313/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2715 - accuracy: 0.9233 - val_loss: 0.2514 - val_accuracy: 0.9329\n",
      "Epoch 314/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2747 - accuracy: 0.9187 - val_loss: 0.2521 - val_accuracy: 0.9334\n",
      "Epoch 315/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2688 - accuracy: 0.9222 - val_loss: 0.2494 - val_accuracy: 0.9345\n",
      "Epoch 316/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2687 - accuracy: 0.9211 - val_loss: 0.2483 - val_accuracy: 0.9346\n",
      "Epoch 317/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2671 - accuracy: 0.9240 - val_loss: 0.2478 - val_accuracy: 0.9344\n",
      "Epoch 318/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2686 - accuracy: 0.9220 - val_loss: 0.2462 - val_accuracy: 0.9347\n",
      "Epoch 319/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2650 - accuracy: 0.9247 - val_loss: 0.2466 - val_accuracy: 0.9349\n",
      "Epoch 320/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2656 - accuracy: 0.9234 - val_loss: 0.2430 - val_accuracy: 0.9360\n",
      "Epoch 321/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2647 - accuracy: 0.9229 - val_loss: 0.2418 - val_accuracy: 0.9356\n",
      "Epoch 322/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2599 - accuracy: 0.9255 - val_loss: 0.2421 - val_accuracy: 0.9357\n",
      "Epoch 323/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2608 - accuracy: 0.9264 - val_loss: 0.2415 - val_accuracy: 0.9363\n",
      "Epoch 324/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2624 - accuracy: 0.9234 - val_loss: 0.2397 - val_accuracy: 0.9367\n",
      "Epoch 325/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2574 - accuracy: 0.9249 - val_loss: 0.2390 - val_accuracy: 0.9363\n",
      "Epoch 326/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2617 - accuracy: 0.9222 - val_loss: 0.2385 - val_accuracy: 0.9369\n",
      "Epoch 327/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2572 - accuracy: 0.9250 - val_loss: 0.2370 - val_accuracy: 0.9375\n",
      "Epoch 328/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2550 - accuracy: 0.9254 - val_loss: 0.2352 - val_accuracy: 0.9374\n",
      "Epoch 329/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2560 - accuracy: 0.9248 - val_loss: 0.2334 - val_accuracy: 0.9384\n",
      "Epoch 330/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.2525 - accuracy: 0.9268 - val_loss: 0.2344 - val_accuracy: 0.9384\n",
      "Epoch 331/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.2519 - accuracy: 0.9268 - val_loss: 0.2328 - val_accuracy: 0.9382\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2483 - accuracy: 0.9293 - val_loss: 0.2331 - val_accuracy: 0.9383\n",
      "Epoch 333/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2475 - accuracy: 0.9281 - val_loss: 0.2314 - val_accuracy: 0.9387\n",
      "Epoch 334/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2467 - accuracy: 0.9307 - val_loss: 0.2308 - val_accuracy: 0.9389\n",
      "Epoch 335/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2488 - accuracy: 0.9259 - val_loss: 0.2302 - val_accuracy: 0.9392\n",
      "Epoch 336/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2482 - accuracy: 0.9272 - val_loss: 0.2290 - val_accuracy: 0.9400\n",
      "Epoch 337/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2448 - accuracy: 0.9299 - val_loss: 0.2262 - val_accuracy: 0.9406\n",
      "Epoch 338/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2431 - accuracy: 0.9307 - val_loss: 0.2258 - val_accuracy: 0.9398\n",
      "Epoch 339/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2424 - accuracy: 0.9293 - val_loss: 0.2262 - val_accuracy: 0.9406\n",
      "Epoch 340/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2427 - accuracy: 0.9288 - val_loss: 0.2245 - val_accuracy: 0.9404\n",
      "Epoch 341/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2376 - accuracy: 0.9325 - val_loss: 0.2237 - val_accuracy: 0.9410\n",
      "Epoch 342/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2396 - accuracy: 0.9293 - val_loss: 0.2214 - val_accuracy: 0.9409\n",
      "Epoch 343/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2366 - accuracy: 0.9327 - val_loss: 0.2218 - val_accuracy: 0.9407\n",
      "Epoch 344/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2360 - accuracy: 0.9324 - val_loss: 0.2205 - val_accuracy: 0.9410\n",
      "Epoch 345/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2379 - accuracy: 0.9311 - val_loss: 0.2196 - val_accuracy: 0.9416\n",
      "Epoch 346/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2330 - accuracy: 0.9336 - val_loss: 0.2179 - val_accuracy: 0.9415\n",
      "Epoch 347/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.2304 - accuracy: 0.9355 - val_loss: 0.2178 - val_accuracy: 0.9417\n",
      "Epoch 348/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2318 - accuracy: 0.9348 - val_loss: 0.2169 - val_accuracy: 0.9425\n",
      "Epoch 349/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2320 - accuracy: 0.9318 - val_loss: 0.2170 - val_accuracy: 0.9424\n",
      "Epoch 350/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2283 - accuracy: 0.9339 - val_loss: 0.2151 - val_accuracy: 0.9423\n",
      "Epoch 351/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2282 - accuracy: 0.9341 - val_loss: 0.2156 - val_accuracy: 0.9426\n",
      "Epoch 352/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2284 - accuracy: 0.9321 - val_loss: 0.2153 - val_accuracy: 0.9435\n",
      "Epoch 353/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2278 - accuracy: 0.9338 - val_loss: 0.2144 - val_accuracy: 0.9428\n",
      "Epoch 354/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2246 - accuracy: 0.9359 - val_loss: 0.2125 - val_accuracy: 0.9429\n",
      "Epoch 355/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2261 - accuracy: 0.9332 - val_loss: 0.2128 - val_accuracy: 0.9433\n",
      "Epoch 356/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2211 - accuracy: 0.9353 - val_loss: 0.2114 - val_accuracy: 0.9436\n",
      "Epoch 357/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2244 - accuracy: 0.9332 - val_loss: 0.2113 - val_accuracy: 0.9436\n",
      "Epoch 358/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2202 - accuracy: 0.9383 - val_loss: 0.2109 - val_accuracy: 0.9446\n",
      "Epoch 359/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2221 - accuracy: 0.9359 - val_loss: 0.2093 - val_accuracy: 0.9448\n",
      "Epoch 360/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2205 - accuracy: 0.9351 - val_loss: 0.2069 - val_accuracy: 0.9446\n",
      "Epoch 361/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2158 - accuracy: 0.9376 - val_loss: 0.2066 - val_accuracy: 0.9449\n",
      "Epoch 362/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2180 - accuracy: 0.9374 - val_loss: 0.2064 - val_accuracy: 0.9449\n",
      "Epoch 363/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2236 - accuracy: 0.9349 - val_loss: 0.2049 - val_accuracy: 0.9450\n",
      "Epoch 364/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2148 - accuracy: 0.9381 - val_loss: 0.2056 - val_accuracy: 0.9446\n",
      "Epoch 365/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2172 - accuracy: 0.9369 - val_loss: 0.2034 - val_accuracy: 0.9457\n",
      "Epoch 366/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2131 - accuracy: 0.9384 - val_loss: 0.2031 - val_accuracy: 0.9456\n",
      "Epoch 367/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2102 - accuracy: 0.9409 - val_loss: 0.2021 - val_accuracy: 0.9463\n",
      "Epoch 368/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2085 - accuracy: 0.9409 - val_loss: 0.2012 - val_accuracy: 0.9464\n",
      "Epoch 369/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.2134 - accuracy: 0.9381 - val_loss: 0.2014 - val_accuracy: 0.9472\n",
      "Epoch 370/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2084 - accuracy: 0.9389 - val_loss: 0.1997 - val_accuracy: 0.9464\n",
      "Epoch 371/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2106 - accuracy: 0.9388 - val_loss: 0.1994 - val_accuracy: 0.9472\n",
      "Epoch 372/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2073 - accuracy: 0.9412 - val_loss: 0.1992 - val_accuracy: 0.9466\n",
      "Epoch 373/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2074 - accuracy: 0.9408 - val_loss: 0.1985 - val_accuracy: 0.9471\n",
      "Epoch 374/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2081 - accuracy: 0.9401 - val_loss: 0.1974 - val_accuracy: 0.9477\n",
      "Epoch 375/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2033 - accuracy: 0.9408 - val_loss: 0.1970 - val_accuracy: 0.9476\n",
      "Epoch 376/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2069 - accuracy: 0.9412 - val_loss: 0.1955 - val_accuracy: 0.9479\n",
      "Epoch 377/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2045 - accuracy: 0.9411 - val_loss: 0.1959 - val_accuracy: 0.9477\n",
      "Epoch 378/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2024 - accuracy: 0.9415 - val_loss: 0.1945 - val_accuracy: 0.9479\n",
      "Epoch 379/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2017 - accuracy: 0.9413 - val_loss: 0.1946 - val_accuracy: 0.9481\n",
      "Epoch 380/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2014 - accuracy: 0.9413 - val_loss: 0.1928 - val_accuracy: 0.9482\n",
      "Epoch 381/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.2007 - accuracy: 0.9423 - val_loss: 0.1917 - val_accuracy: 0.9485\n",
      "Epoch 382/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1981 - accuracy: 0.9437 - val_loss: 0.1913 - val_accuracy: 0.9489\n",
      "Epoch 383/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1996 - accuracy: 0.9416 - val_loss: 0.1908 - val_accuracy: 0.9489\n",
      "Epoch 384/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1989 - accuracy: 0.9426 - val_loss: 0.1897 - val_accuracy: 0.9492\n",
      "Epoch 385/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1964 - accuracy: 0.9436 - val_loss: 0.1902 - val_accuracy: 0.9495\n",
      "Epoch 386/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1941 - accuracy: 0.9438 - val_loss: 0.1886 - val_accuracy: 0.9497\n",
      "Epoch 387/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1948 - accuracy: 0.9441 - val_loss: 0.1886 - val_accuracy: 0.9495\n",
      "Epoch 388/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1967 - accuracy: 0.9422 - val_loss: 0.1885 - val_accuracy: 0.9499\n",
      "Epoch 389/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1962 - accuracy: 0.9420 - val_loss: 0.1864 - val_accuracy: 0.9502\n",
      "Epoch 390/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1926 - accuracy: 0.9458 - val_loss: 0.1868 - val_accuracy: 0.9500\n",
      "Epoch 391/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1918 - accuracy: 0.9457 - val_loss: 0.1857 - val_accuracy: 0.9502\n",
      "Epoch 392/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1890 - accuracy: 0.9453 - val_loss: 0.1862 - val_accuracy: 0.9504\n",
      "Epoch 393/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1898 - accuracy: 0.9449 - val_loss: 0.1839 - val_accuracy: 0.9512\n",
      "Epoch 394/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1903 - accuracy: 0.9456 - val_loss: 0.1842 - val_accuracy: 0.9508\n",
      "Epoch 395/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1868 - accuracy: 0.9446 - val_loss: 0.1832 - val_accuracy: 0.9506\n",
      "Epoch 396/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1858 - accuracy: 0.9468 - val_loss: 0.1829 - val_accuracy: 0.9508\n",
      "Epoch 397/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1843 - accuracy: 0.9484 - val_loss: 0.1818 - val_accuracy: 0.9512\n",
      "Epoch 398/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1856 - accuracy: 0.9461 - val_loss: 0.1822 - val_accuracy: 0.9513\n",
      "Epoch 399/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1877 - accuracy: 0.9446 - val_loss: 0.1798 - val_accuracy: 0.9520\n",
      "Epoch 400/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1859 - accuracy: 0.9447 - val_loss: 0.1801 - val_accuracy: 0.9518\n",
      "Epoch 401/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1827 - accuracy: 0.9468 - val_loss: 0.1791 - val_accuracy: 0.9518\n",
      "Epoch 402/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1793 - accuracy: 0.9484 - val_loss: 0.1792 - val_accuracy: 0.9525\n",
      "Epoch 403/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1823 - accuracy: 0.9466 - val_loss: 0.1789 - val_accuracy: 0.9519\n",
      "Epoch 404/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1789 - accuracy: 0.9483 - val_loss: 0.1760 - val_accuracy: 0.9531\n",
      "Epoch 405/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1773 - accuracy: 0.9500 - val_loss: 0.1771 - val_accuracy: 0.9531\n",
      "Epoch 406/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1800 - accuracy: 0.9477 - val_loss: 0.1756 - val_accuracy: 0.9525\n",
      "Epoch 407/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1794 - accuracy: 0.9473 - val_loss: 0.1756 - val_accuracy: 0.9526\n",
      "Epoch 408/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1808 - accuracy: 0.9476 - val_loss: 0.1746 - val_accuracy: 0.9531\n",
      "Epoch 409/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1813 - accuracy: 0.9456 - val_loss: 0.1748 - val_accuracy: 0.9528\n",
      "Epoch 410/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1782 - accuracy: 0.9463 - val_loss: 0.1742 - val_accuracy: 0.9523\n",
      "Epoch 411/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1739 - accuracy: 0.9496 - val_loss: 0.1732 - val_accuracy: 0.9524\n",
      "Epoch 412/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.1755 - accuracy: 0.9474 - val_loss: 0.1729 - val_accuracy: 0.9527\n",
      "Epoch 413/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1726 - accuracy: 0.9496 - val_loss: 0.1718 - val_accuracy: 0.9527\n",
      "Epoch 414/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1740 - accuracy: 0.9477 - val_loss: 0.1726 - val_accuracy: 0.9531\n",
      "Epoch 415/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1777 - accuracy: 0.9487 - val_loss: 0.1717 - val_accuracy: 0.9535\n",
      "Epoch 416/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1717 - accuracy: 0.9511 - val_loss: 0.1705 - val_accuracy: 0.9536\n",
      "Epoch 417/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1699 - accuracy: 0.9516 - val_loss: 0.1701 - val_accuracy: 0.9537\n",
      "Epoch 418/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1702 - accuracy: 0.9506 - val_loss: 0.1685 - val_accuracy: 0.9538\n",
      "Epoch 419/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1734 - accuracy: 0.9495 - val_loss: 0.1685 - val_accuracy: 0.9535\n",
      "Epoch 420/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1702 - accuracy: 0.9519 - val_loss: 0.1691 - val_accuracy: 0.9540\n",
      "Epoch 421/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1712 - accuracy: 0.9515 - val_loss: 0.1685 - val_accuracy: 0.9542\n",
      "Epoch 422/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1688 - accuracy: 0.9506 - val_loss: 0.1669 - val_accuracy: 0.9544\n",
      "Epoch 423/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1670 - accuracy: 0.9541 - val_loss: 0.1673 - val_accuracy: 0.9538\n",
      "Epoch 424/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1647 - accuracy: 0.9529 - val_loss: 0.1661 - val_accuracy: 0.9552\n",
      "Epoch 425/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1652 - accuracy: 0.9518 - val_loss: 0.1660 - val_accuracy: 0.9550\n",
      "Epoch 426/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1647 - accuracy: 0.9526 - val_loss: 0.1657 - val_accuracy: 0.9550\n",
      "Epoch 427/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1654 - accuracy: 0.9532 - val_loss: 0.1648 - val_accuracy: 0.9551\n",
      "Epoch 428/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1657 - accuracy: 0.9521 - val_loss: 0.1665 - val_accuracy: 0.9551\n",
      "Epoch 429/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1617 - accuracy: 0.9526 - val_loss: 0.1649 - val_accuracy: 0.9545\n",
      "Epoch 430/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1603 - accuracy: 0.9546 - val_loss: 0.1632 - val_accuracy: 0.9547\n",
      "Epoch 431/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1608 - accuracy: 0.9528 - val_loss: 0.1634 - val_accuracy: 0.9553\n",
      "Epoch 432/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1656 - accuracy: 0.9519 - val_loss: 0.1629 - val_accuracy: 0.9551\n",
      "Epoch 433/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1610 - accuracy: 0.9534 - val_loss: 0.1625 - val_accuracy: 0.9550\n",
      "Epoch 434/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1615 - accuracy: 0.9525 - val_loss: 0.1606 - val_accuracy: 0.9549\n",
      "Epoch 435/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1605 - accuracy: 0.9538 - val_loss: 0.1607 - val_accuracy: 0.9554\n",
      "Epoch 436/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1621 - accuracy: 0.9518 - val_loss: 0.1601 - val_accuracy: 0.9562\n",
      "Epoch 437/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1559 - accuracy: 0.9560 - val_loss: 0.1602 - val_accuracy: 0.9560\n",
      "Epoch 438/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1578 - accuracy: 0.9545 - val_loss: 0.1596 - val_accuracy: 0.9565\n",
      "Epoch 439/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1590 - accuracy: 0.9539 - val_loss: 0.1598 - val_accuracy: 0.9561\n",
      "Epoch 440/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1546 - accuracy: 0.9576 - val_loss: 0.1595 - val_accuracy: 0.9560\n",
      "Epoch 441/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1570 - accuracy: 0.9534 - val_loss: 0.1581 - val_accuracy: 0.9569\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1543 - accuracy: 0.9537 - val_loss: 0.1582 - val_accuracy: 0.9564\n",
      "Epoch 443/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1537 - accuracy: 0.9561 - val_loss: 0.1579 - val_accuracy: 0.9562\n",
      "Epoch 444/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1549 - accuracy: 0.9564 - val_loss: 0.1581 - val_accuracy: 0.9563\n",
      "Epoch 445/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1540 - accuracy: 0.9555 - val_loss: 0.1553 - val_accuracy: 0.9572\n",
      "Epoch 446/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1545 - accuracy: 0.9552 - val_loss: 0.1577 - val_accuracy: 0.9577\n",
      "Epoch 447/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1519 - accuracy: 0.9571 - val_loss: 0.1553 - val_accuracy: 0.9573\n",
      "Epoch 448/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1526 - accuracy: 0.9557 - val_loss: 0.1540 - val_accuracy: 0.9573\n",
      "Epoch 449/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1539 - accuracy: 0.9545 - val_loss: 0.1542 - val_accuracy: 0.9582\n",
      "Epoch 450/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1484 - accuracy: 0.9567 - val_loss: 0.1544 - val_accuracy: 0.9578\n",
      "Epoch 451/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1481 - accuracy: 0.9568 - val_loss: 0.1534 - val_accuracy: 0.9577\n",
      "Epoch 452/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1507 - accuracy: 0.9567 - val_loss: 0.1535 - val_accuracy: 0.9582\n",
      "Epoch 453/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1456 - accuracy: 0.9587 - val_loss: 0.1520 - val_accuracy: 0.9582\n",
      "Epoch 454/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1492 - accuracy: 0.9571 - val_loss: 0.1520 - val_accuracy: 0.9581\n",
      "Epoch 455/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1486 - accuracy: 0.9574 - val_loss: 0.1515 - val_accuracy: 0.9574\n",
      "Epoch 456/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1466 - accuracy: 0.9567 - val_loss: 0.1505 - val_accuracy: 0.9581\n",
      "Epoch 457/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1454 - accuracy: 0.9583 - val_loss: 0.1514 - val_accuracy: 0.9580\n",
      "Epoch 458/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1456 - accuracy: 0.9578 - val_loss: 0.1514 - val_accuracy: 0.9587\n",
      "Epoch 459/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1479 - accuracy: 0.9564 - val_loss: 0.1500 - val_accuracy: 0.9591\n",
      "Epoch 460/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1474 - accuracy: 0.9570 - val_loss: 0.1502 - val_accuracy: 0.9588\n",
      "Epoch 461/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1426 - accuracy: 0.9589 - val_loss: 0.1490 - val_accuracy: 0.9588\n",
      "Epoch 462/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1442 - accuracy: 0.9578 - val_loss: 0.1502 - val_accuracy: 0.9593\n",
      "Epoch 463/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1424 - accuracy: 0.9588 - val_loss: 0.1483 - val_accuracy: 0.9598\n",
      "Epoch 464/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1407 - accuracy: 0.9598 - val_loss: 0.1478 - val_accuracy: 0.9593\n",
      "Epoch 465/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1403 - accuracy: 0.9597 - val_loss: 0.1480 - val_accuracy: 0.9596\n",
      "Epoch 466/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1459 - accuracy: 0.9581 - val_loss: 0.1465 - val_accuracy: 0.9595\n",
      "Epoch 467/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1425 - accuracy: 0.9589 - val_loss: 0.1463 - val_accuracy: 0.9597\n",
      "Epoch 468/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1428 - accuracy: 0.9584 - val_loss: 0.1461 - val_accuracy: 0.9600\n",
      "Epoch 469/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1399 - accuracy: 0.9593 - val_loss: 0.1457 - val_accuracy: 0.9600\n",
      "Epoch 470/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1383 - accuracy: 0.9619 - val_loss: 0.1451 - val_accuracy: 0.9600\n",
      "Epoch 471/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1372 - accuracy: 0.9608 - val_loss: 0.1443 - val_accuracy: 0.9605\n",
      "Epoch 472/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1359 - accuracy: 0.9609 - val_loss: 0.1450 - val_accuracy: 0.9607\n",
      "Epoch 473/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1364 - accuracy: 0.9602 - val_loss: 0.1442 - val_accuracy: 0.9606\n",
      "Epoch 474/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1395 - accuracy: 0.9595 - val_loss: 0.1450 - val_accuracy: 0.9604\n",
      "Epoch 475/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1346 - accuracy: 0.9625 - val_loss: 0.1439 - val_accuracy: 0.9613\n",
      "Epoch 476/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1354 - accuracy: 0.9611 - val_loss: 0.1430 - val_accuracy: 0.9607\n",
      "Epoch 477/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1364 - accuracy: 0.9610 - val_loss: 0.1434 - val_accuracy: 0.9610\n",
      "Epoch 478/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1365 - accuracy: 0.9612 - val_loss: 0.1420 - val_accuracy: 0.9614\n",
      "Epoch 479/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1361 - accuracy: 0.9609 - val_loss: 0.1438 - val_accuracy: 0.9607\n",
      "Epoch 480/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1366 - accuracy: 0.9606 - val_loss: 0.1425 - val_accuracy: 0.9616\n",
      "Epoch 481/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1339 - accuracy: 0.9625 - val_loss: 0.1435 - val_accuracy: 0.9607\n",
      "Epoch 482/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1343 - accuracy: 0.9605 - val_loss: 0.1429 - val_accuracy: 0.9616\n",
      "Epoch 483/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1332 - accuracy: 0.9613 - val_loss: 0.1407 - val_accuracy: 0.9614\n",
      "Epoch 484/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1355 - accuracy: 0.9599 - val_loss: 0.1411 - val_accuracy: 0.9617\n",
      "Epoch 485/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1319 - accuracy: 0.9615 - val_loss: 0.1414 - val_accuracy: 0.9616\n",
      "Epoch 486/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1308 - accuracy: 0.9622 - val_loss: 0.1390 - val_accuracy: 0.9617\n",
      "Epoch 487/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1309 - accuracy: 0.9616 - val_loss: 0.1399 - val_accuracy: 0.9616\n",
      "Epoch 488/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1316 - accuracy: 0.9622 - val_loss: 0.1384 - val_accuracy: 0.9619\n",
      "Epoch 489/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1282 - accuracy: 0.9625 - val_loss: 0.1385 - val_accuracy: 0.9621\n",
      "Epoch 490/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1283 - accuracy: 0.9611 - val_loss: 0.1392 - val_accuracy: 0.9620\n",
      "Epoch 491/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1280 - accuracy: 0.9642 - val_loss: 0.1383 - val_accuracy: 0.9627\n",
      "Epoch 492/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1284 - accuracy: 0.9632 - val_loss: 0.1381 - val_accuracy: 0.9627\n",
      "Epoch 493/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1272 - accuracy: 0.9625 - val_loss: 0.1383 - val_accuracy: 0.9628\n",
      "Epoch 494/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1229 - accuracy: 0.9659 - val_loss: 0.1365 - val_accuracy: 0.9624\n",
      "Epoch 495/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1262 - accuracy: 0.9640 - val_loss: 0.1365 - val_accuracy: 0.9624\n",
      "Epoch 496/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1256 - accuracy: 0.9645 - val_loss: 0.1364 - val_accuracy: 0.9627\n",
      "Epoch 497/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1266 - accuracy: 0.9641 - val_loss: 0.1364 - val_accuracy: 0.9633\n",
      "Epoch 498/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1263 - accuracy: 0.9637 - val_loss: 0.1355 - val_accuracy: 0.9627\n",
      "Epoch 499/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1260 - accuracy: 0.9632 - val_loss: 0.1367 - val_accuracy: 0.9634\n",
      "Epoch 500/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1214 - accuracy: 0.9658 - val_loss: 0.1345 - val_accuracy: 0.9630\n",
      "Epoch 501/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1244 - accuracy: 0.9645 - val_loss: 0.1347 - val_accuracy: 0.9632\n",
      "Epoch 502/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1267 - accuracy: 0.9631 - val_loss: 0.1339 - val_accuracy: 0.9633\n",
      "Epoch 503/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1236 - accuracy: 0.9650 - val_loss: 0.1354 - val_accuracy: 0.9634\n",
      "Epoch 504/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1214 - accuracy: 0.9662 - val_loss: 0.1341 - val_accuracy: 0.9637\n",
      "Epoch 505/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1225 - accuracy: 0.9655 - val_loss: 0.1334 - val_accuracy: 0.9643\n",
      "Epoch 506/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1208 - accuracy: 0.9652 - val_loss: 0.1321 - val_accuracy: 0.9642\n",
      "Epoch 507/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1251 - accuracy: 0.9642 - val_loss: 0.1326 - val_accuracy: 0.9642\n",
      "Epoch 508/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1203 - accuracy: 0.9657 - val_loss: 0.1318 - val_accuracy: 0.9639\n",
      "Epoch 509/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1210 - accuracy: 0.9660 - val_loss: 0.1316 - val_accuracy: 0.9646\n",
      "Epoch 510/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1220 - accuracy: 0.9643 - val_loss: 0.1329 - val_accuracy: 0.9642\n",
      "Epoch 511/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1197 - accuracy: 0.9660 - val_loss: 0.1306 - val_accuracy: 0.9650\n",
      "Epoch 512/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1200 - accuracy: 0.9656 - val_loss: 0.1312 - val_accuracy: 0.9645\n",
      "Epoch 513/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1199 - accuracy: 0.9661 - val_loss: 0.1319 - val_accuracy: 0.9647\n",
      "Epoch 514/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1188 - accuracy: 0.9666 - val_loss: 0.1299 - val_accuracy: 0.9650\n",
      "Epoch 515/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1185 - accuracy: 0.9658 - val_loss: 0.1294 - val_accuracy: 0.9645\n",
      "Epoch 516/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1197 - accuracy: 0.9655 - val_loss: 0.1301 - val_accuracy: 0.9646\n",
      "Epoch 517/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1187 - accuracy: 0.9659 - val_loss: 0.1297 - val_accuracy: 0.9650\n",
      "Epoch 518/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1163 - accuracy: 0.9678 - val_loss: 0.1294 - val_accuracy: 0.9650\n",
      "Epoch 519/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1167 - accuracy: 0.9670 - val_loss: 0.1301 - val_accuracy: 0.9651\n",
      "Epoch 520/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1159 - accuracy: 0.9681 - val_loss: 0.1297 - val_accuracy: 0.9651\n",
      "Epoch 521/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1158 - accuracy: 0.9677 - val_loss: 0.1276 - val_accuracy: 0.9656\n",
      "Epoch 522/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1121 - accuracy: 0.9696 - val_loss: 0.1288 - val_accuracy: 0.9658\n",
      "Epoch 523/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1136 - accuracy: 0.9677 - val_loss: 0.1281 - val_accuracy: 0.9652\n",
      "Epoch 524/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1159 - accuracy: 0.9673 - val_loss: 0.1277 - val_accuracy: 0.9656\n",
      "Epoch 525/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1140 - accuracy: 0.9677 - val_loss: 0.1271 - val_accuracy: 0.9661\n",
      "Epoch 526/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1148 - accuracy: 0.9685 - val_loss: 0.1292 - val_accuracy: 0.9649\n",
      "Epoch 527/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1135 - accuracy: 0.9673 - val_loss: 0.1275 - val_accuracy: 0.9656\n",
      "Epoch 528/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1109 - accuracy: 0.9694 - val_loss: 0.1270 - val_accuracy: 0.9653\n",
      "Epoch 529/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1110 - accuracy: 0.9673 - val_loss: 0.1263 - val_accuracy: 0.9656\n",
      "Epoch 530/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1114 - accuracy: 0.9684 - val_loss: 0.1265 - val_accuracy: 0.9662\n",
      "Epoch 531/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1107 - accuracy: 0.9685 - val_loss: 0.1261 - val_accuracy: 0.9661\n",
      "Epoch 532/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.1145 - accuracy: 0.9666 - val_loss: 0.1267 - val_accuracy: 0.9663\n",
      "Epoch 533/1000\n",
      "487/487 [==============================] - 18s 38ms/step - loss: 0.1122 - accuracy: 0.9671 - val_loss: 0.1259 - val_accuracy: 0.9661\n",
      "Epoch 534/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.1094 - accuracy: 0.9705 - val_loss: 0.1256 - val_accuracy: 0.9660\n",
      "Epoch 535/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.1093 - accuracy: 0.9685 - val_loss: 0.1244 - val_accuracy: 0.9660\n",
      "Epoch 536/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.1111 - accuracy: 0.9677 - val_loss: 0.1245 - val_accuracy: 0.9660\n",
      "Epoch 537/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.1092 - accuracy: 0.9687 - val_loss: 0.1244 - val_accuracy: 0.9663\n",
      "Epoch 538/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1085 - accuracy: 0.9698 - val_loss: 0.1243 - val_accuracy: 0.9658\n",
      "Epoch 539/1000\n",
      "487/487 [==============================] - 18s 38ms/step - loss: 0.1087 - accuracy: 0.9678 - val_loss: 0.1239 - val_accuracy: 0.9664\n",
      "Epoch 540/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.1057 - accuracy: 0.9698 - val_loss: 0.1232 - val_accuracy: 0.9663\n",
      "Epoch 541/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.1105 - accuracy: 0.9682 - val_loss: 0.1228 - val_accuracy: 0.9658\n",
      "Epoch 542/1000\n",
      "487/487 [==============================] - 53s 108ms/step - loss: 0.1059 - accuracy: 0.9696 - val_loss: 0.1232 - val_accuracy: 0.9666\n",
      "Epoch 543/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.1054 - accuracy: 0.9701 - val_loss: 0.1224 - val_accuracy: 0.9668\n",
      "Epoch 544/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1050 - accuracy: 0.9705 - val_loss: 0.1232 - val_accuracy: 0.9663\n",
      "Epoch 545/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1060 - accuracy: 0.9694 - val_loss: 0.1215 - val_accuracy: 0.9670\n",
      "Epoch 546/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.1060 - accuracy: 0.9704 - val_loss: 0.1221 - val_accuracy: 0.9670\n",
      "Epoch 547/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.1057 - accuracy: 0.9696 - val_loss: 0.1204 - val_accuracy: 0.9672\n",
      "Epoch 548/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.1054 - accuracy: 0.9699 - val_loss: 0.1213 - val_accuracy: 0.9671\n",
      "Epoch 549/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1031 - accuracy: 0.9725 - val_loss: 0.1208 - val_accuracy: 0.9673\n",
      "Epoch 550/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1047 - accuracy: 0.9697 - val_loss: 0.1200 - val_accuracy: 0.9671\n",
      "Epoch 551/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.1048 - accuracy: 0.9694 - val_loss: 0.1212 - val_accuracy: 0.9669\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1029 - accuracy: 0.9710 - val_loss: 0.1208 - val_accuracy: 0.9670\n",
      "Epoch 553/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.1034 - accuracy: 0.9696 - val_loss: 0.1204 - val_accuracy: 0.9673\n",
      "Epoch 554/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.1019 - accuracy: 0.9718 - val_loss: 0.1196 - val_accuracy: 0.9673\n",
      "Epoch 555/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.1006 - accuracy: 0.9721 - val_loss: 0.1209 - val_accuracy: 0.9673\n",
      "Epoch 556/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0997 - accuracy: 0.9720 - val_loss: 0.1196 - val_accuracy: 0.9674\n",
      "Epoch 557/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.1006 - accuracy: 0.9716 - val_loss: 0.1189 - val_accuracy: 0.9679\n",
      "Epoch 558/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.1001 - accuracy: 0.9707 - val_loss: 0.1191 - val_accuracy: 0.9684\n",
      "Epoch 559/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.1027 - accuracy: 0.9702 - val_loss: 0.1189 - val_accuracy: 0.9677\n",
      "Epoch 560/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1041 - accuracy: 0.9709 - val_loss: 0.1185 - val_accuracy: 0.9685\n",
      "Epoch 561/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0990 - accuracy: 0.9725 - val_loss: 0.1194 - val_accuracy: 0.9679\n",
      "Epoch 562/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.1000 - accuracy: 0.9710 - val_loss: 0.1176 - val_accuracy: 0.9685\n",
      "Epoch 563/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.1001 - accuracy: 0.9708 - val_loss: 0.1176 - val_accuracy: 0.9690\n",
      "Epoch 564/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0988 - accuracy: 0.9722 - val_loss: 0.1182 - val_accuracy: 0.9683\n",
      "Epoch 565/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.1002 - accuracy: 0.9714 - val_loss: 0.1174 - val_accuracy: 0.9686\n",
      "Epoch 566/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.1010 - accuracy: 0.9710 - val_loss: 0.1165 - val_accuracy: 0.9689\n",
      "Epoch 567/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.1001 - accuracy: 0.9710 - val_loss: 0.1167 - val_accuracy: 0.9684\n",
      "Epoch 568/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.1006 - accuracy: 0.9713 - val_loss: 0.1172 - val_accuracy: 0.9683\n",
      "Epoch 569/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0970 - accuracy: 0.9722 - val_loss: 0.1157 - val_accuracy: 0.9687\n",
      "Epoch 570/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0974 - accuracy: 0.9720 - val_loss: 0.1152 - val_accuracy: 0.9692\n",
      "Epoch 571/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0979 - accuracy: 0.9718 - val_loss: 0.1162 - val_accuracy: 0.9693\n",
      "Epoch 572/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0977 - accuracy: 0.9729 - val_loss: 0.1152 - val_accuracy: 0.9690\n",
      "Epoch 573/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0968 - accuracy: 0.9724 - val_loss: 0.1146 - val_accuracy: 0.9690\n",
      "Epoch 574/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0981 - accuracy: 0.9706 - val_loss: 0.1153 - val_accuracy: 0.9689\n",
      "Epoch 575/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0953 - accuracy: 0.9741 - val_loss: 0.1154 - val_accuracy: 0.9691\n",
      "Epoch 576/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0938 - accuracy: 0.9739 - val_loss: 0.1141 - val_accuracy: 0.9693\n",
      "Epoch 577/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0969 - accuracy: 0.9730 - val_loss: 0.1149 - val_accuracy: 0.9693\n",
      "Epoch 578/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0937 - accuracy: 0.9735 - val_loss: 0.1136 - val_accuracy: 0.9696\n",
      "Epoch 579/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0928 - accuracy: 0.9734 - val_loss: 0.1141 - val_accuracy: 0.9693\n",
      "Epoch 580/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0918 - accuracy: 0.9747 - val_loss: 0.1147 - val_accuracy: 0.9692\n",
      "Epoch 581/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0943 - accuracy: 0.9727 - val_loss: 0.1141 - val_accuracy: 0.9692\n",
      "Epoch 582/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0927 - accuracy: 0.9733 - val_loss: 0.1138 - val_accuracy: 0.9685\n",
      "Epoch 583/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0919 - accuracy: 0.9747 - val_loss: 0.1130 - val_accuracy: 0.9699\n",
      "Epoch 584/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0917 - accuracy: 0.9746 - val_loss: 0.1128 - val_accuracy: 0.9692\n",
      "Epoch 585/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0934 - accuracy: 0.9737 - val_loss: 0.1137 - val_accuracy: 0.9690\n",
      "Epoch 586/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0929 - accuracy: 0.9728 - val_loss: 0.1122 - val_accuracy: 0.9700\n",
      "Epoch 587/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0927 - accuracy: 0.9734 - val_loss: 0.1119 - val_accuracy: 0.9689\n",
      "Epoch 588/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0915 - accuracy: 0.9738 - val_loss: 0.1112 - val_accuracy: 0.9692\n",
      "Epoch 589/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0890 - accuracy: 0.9744 - val_loss: 0.1118 - val_accuracy: 0.9691\n",
      "Epoch 590/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0891 - accuracy: 0.9756 - val_loss: 0.1111 - val_accuracy: 0.9698\n",
      "Epoch 591/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0924 - accuracy: 0.9719 - val_loss: 0.1108 - val_accuracy: 0.9698\n",
      "Epoch 592/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0878 - accuracy: 0.9756 - val_loss: 0.1117 - val_accuracy: 0.9698\n",
      "Epoch 593/1000\n",
      "487/487 [==============================] - 18s 38ms/step - loss: 0.0889 - accuracy: 0.9748 - val_loss: 0.1114 - val_accuracy: 0.9699\n",
      "Epoch 594/1000\n",
      "487/487 [==============================] - 18s 38ms/step - loss: 0.0902 - accuracy: 0.9747 - val_loss: 0.1114 - val_accuracy: 0.9696\n",
      "Epoch 595/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0901 - accuracy: 0.9744 - val_loss: 0.1109 - val_accuracy: 0.9695\n",
      "Epoch 596/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0902 - accuracy: 0.9736 - val_loss: 0.1098 - val_accuracy: 0.9699\n",
      "Epoch 597/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0886 - accuracy: 0.9757 - val_loss: 0.1097 - val_accuracy: 0.9702\n",
      "Epoch 598/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0885 - accuracy: 0.9753 - val_loss: 0.1104 - val_accuracy: 0.9697\n",
      "Epoch 599/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0914 - accuracy: 0.9732 - val_loss: 0.1096 - val_accuracy: 0.9706\n",
      "Epoch 600/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0897 - accuracy: 0.9752 - val_loss: 0.1098 - val_accuracy: 0.9704\n",
      "Epoch 601/1000\n",
      "487/487 [==============================] - 18s 38ms/step - loss: 0.0898 - accuracy: 0.9750 - val_loss: 0.1098 - val_accuracy: 0.9705\n",
      "Epoch 602/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0879 - accuracy: 0.9755 - val_loss: 0.1089 - val_accuracy: 0.9706\n",
      "Epoch 603/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0847 - accuracy: 0.9769 - val_loss: 0.1098 - val_accuracy: 0.9706\n",
      "Epoch 604/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0892 - accuracy: 0.9745 - val_loss: 0.1101 - val_accuracy: 0.9708\n",
      "Epoch 605/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0866 - accuracy: 0.9765 - val_loss: 0.1088 - val_accuracy: 0.9705\n",
      "Epoch 606/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0871 - accuracy: 0.9759 - val_loss: 0.1093 - val_accuracy: 0.9704\n",
      "Epoch 607/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0860 - accuracy: 0.9755 - val_loss: 0.1101 - val_accuracy: 0.9699\n",
      "Epoch 608/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0860 - accuracy: 0.9765 - val_loss: 0.1080 - val_accuracy: 0.9709\n",
      "Epoch 609/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0860 - accuracy: 0.9753 - val_loss: 0.1080 - val_accuracy: 0.9709\n",
      "Epoch 610/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0857 - accuracy: 0.9760 - val_loss: 0.1088 - val_accuracy: 0.9704\n",
      "Epoch 611/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0859 - accuracy: 0.9763 - val_loss: 0.1073 - val_accuracy: 0.9712\n",
      "Epoch 612/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0865 - accuracy: 0.9750 - val_loss: 0.1073 - val_accuracy: 0.9709\n",
      "Epoch 613/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0856 - accuracy: 0.9758 - val_loss: 0.1068 - val_accuracy: 0.9712\n",
      "Epoch 614/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0846 - accuracy: 0.9764 - val_loss: 0.1079 - val_accuracy: 0.9708\n",
      "Epoch 615/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0856 - accuracy: 0.9752 - val_loss: 0.1063 - val_accuracy: 0.9711\n",
      "Epoch 616/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0840 - accuracy: 0.9762 - val_loss: 0.1064 - val_accuracy: 0.9709\n",
      "Epoch 617/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0850 - accuracy: 0.9753 - val_loss: 0.1064 - val_accuracy: 0.9716\n",
      "Epoch 618/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0842 - accuracy: 0.9765 - val_loss: 0.1060 - val_accuracy: 0.9714\n",
      "Epoch 619/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0844 - accuracy: 0.9767 - val_loss: 0.1060 - val_accuracy: 0.9710\n",
      "Epoch 620/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0834 - accuracy: 0.9758 - val_loss: 0.1054 - val_accuracy: 0.9712\n",
      "Epoch 621/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0815 - accuracy: 0.9777 - val_loss: 0.1060 - val_accuracy: 0.9714\n",
      "Epoch 622/1000\n",
      "487/487 [==============================] - 18s 38ms/step - loss: 0.0844 - accuracy: 0.9763 - val_loss: 0.1051 - val_accuracy: 0.9715\n",
      "Epoch 623/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0808 - accuracy: 0.9769 - val_loss: 0.1053 - val_accuracy: 0.9718\n",
      "Epoch 624/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0788 - accuracy: 0.9784 - val_loss: 0.1053 - val_accuracy: 0.9717\n",
      "Epoch 625/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.0792 - accuracy: 0.9783 - val_loss: 0.1055 - val_accuracy: 0.9717\n",
      "Epoch 626/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0809 - accuracy: 0.9769 - val_loss: 0.1060 - val_accuracy: 0.9718\n",
      "Epoch 627/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0811 - accuracy: 0.9768 - val_loss: 0.1055 - val_accuracy: 0.9720\n",
      "Epoch 628/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0801 - accuracy: 0.9769 - val_loss: 0.1047 - val_accuracy: 0.9716\n",
      "Epoch 629/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0821 - accuracy: 0.9766 - val_loss: 0.1042 - val_accuracy: 0.9722\n",
      "Epoch 630/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0805 - accuracy: 0.9783 - val_loss: 0.1039 - val_accuracy: 0.9716\n",
      "Epoch 631/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0796 - accuracy: 0.9781 - val_loss: 0.1040 - val_accuracy: 0.9720\n",
      "Epoch 632/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0802 - accuracy: 0.9779 - val_loss: 0.1044 - val_accuracy: 0.9714\n",
      "Epoch 633/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0822 - accuracy: 0.9771 - val_loss: 0.1040 - val_accuracy: 0.9720\n",
      "Epoch 634/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0803 - accuracy: 0.9784 - val_loss: 0.1043 - val_accuracy: 0.9722\n",
      "Epoch 635/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0789 - accuracy: 0.9785 - val_loss: 0.1031 - val_accuracy: 0.9721\n",
      "Epoch 636/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0772 - accuracy: 0.9783 - val_loss: 0.1029 - val_accuracy: 0.9723\n",
      "Epoch 637/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0809 - accuracy: 0.9768 - val_loss: 0.1049 - val_accuracy: 0.9723\n",
      "Epoch 638/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.0792 - accuracy: 0.9770 - val_loss: 0.1034 - val_accuracy: 0.9721\n",
      "Epoch 639/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.0796 - accuracy: 0.9784 - val_loss: 0.1036 - val_accuracy: 0.9721\n",
      "Epoch 640/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0798 - accuracy: 0.9769 - val_loss: 0.1040 - val_accuracy: 0.9719\n",
      "Epoch 641/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0757 - accuracy: 0.9788 - val_loss: 0.1035 - val_accuracy: 0.9723\n",
      "Epoch 642/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0759 - accuracy: 0.9793 - val_loss: 0.1033 - val_accuracy: 0.9720\n",
      "Epoch 643/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0766 - accuracy: 0.9778 - val_loss: 0.1028 - val_accuracy: 0.9722\n",
      "Epoch 644/1000\n",
      "487/487 [==============================] - 18s 38ms/step - loss: 0.0771 - accuracy: 0.9786 - val_loss: 0.1026 - val_accuracy: 0.9718\n",
      "Epoch 645/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0762 - accuracy: 0.9791 - val_loss: 0.1025 - val_accuracy: 0.9725\n",
      "Epoch 646/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0749 - accuracy: 0.9795 - val_loss: 0.1037 - val_accuracy: 0.9725\n",
      "Epoch 647/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0752 - accuracy: 0.9789 - val_loss: 0.1014 - val_accuracy: 0.9727\n",
      "Epoch 648/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0778 - accuracy: 0.9768 - val_loss: 0.1024 - val_accuracy: 0.9723\n",
      "Epoch 649/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0792 - accuracy: 0.9776 - val_loss: 0.1025 - val_accuracy: 0.9728\n",
      "Epoch 650/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0775 - accuracy: 0.9775 - val_loss: 0.1020 - val_accuracy: 0.9724\n",
      "Epoch 651/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0753 - accuracy: 0.9793 - val_loss: 0.1023 - val_accuracy: 0.9725\n",
      "Epoch 652/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0732 - accuracy: 0.9795 - val_loss: 0.1011 - val_accuracy: 0.9731\n",
      "Epoch 653/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0748 - accuracy: 0.9789 - val_loss: 0.1021 - val_accuracy: 0.9728\n",
      "Epoch 654/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0758 - accuracy: 0.9788 - val_loss: 0.1002 - val_accuracy: 0.9729\n",
      "Epoch 655/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.0746 - accuracy: 0.9793 - val_loss: 0.1005 - val_accuracy: 0.9728\n",
      "Epoch 656/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0710 - accuracy: 0.9807 - val_loss: 0.1012 - val_accuracy: 0.9727\n",
      "Epoch 657/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.0744 - accuracy: 0.9797 - val_loss: 0.1001 - val_accuracy: 0.9733\n",
      "Epoch 658/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.0742 - accuracy: 0.9796 - val_loss: 0.1004 - val_accuracy: 0.9722\n",
      "Epoch 659/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.0722 - accuracy: 0.9801 - val_loss: 0.0990 - val_accuracy: 0.9725\n",
      "Epoch 660/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.0760 - accuracy: 0.9774 - val_loss: 0.1003 - val_accuracy: 0.9729\n",
      "Epoch 661/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.0725 - accuracy: 0.9797 - val_loss: 0.1007 - val_accuracy: 0.9730\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 17s 36ms/step - loss: 0.0734 - accuracy: 0.9796 - val_loss: 0.1004 - val_accuracy: 0.9729\n",
      "Epoch 663/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0709 - accuracy: 0.9801 - val_loss: 0.0994 - val_accuracy: 0.9727\n",
      "Epoch 664/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0749 - accuracy: 0.9776 - val_loss: 0.1001 - val_accuracy: 0.9732\n",
      "Epoch 665/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0716 - accuracy: 0.9799 - val_loss: 0.1001 - val_accuracy: 0.9737\n",
      "Epoch 666/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0725 - accuracy: 0.9800 - val_loss: 0.0988 - val_accuracy: 0.9731\n",
      "Epoch 667/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0715 - accuracy: 0.9798 - val_loss: 0.0995 - val_accuracy: 0.9731\n",
      "Epoch 668/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.0727 - accuracy: 0.9796 - val_loss: 0.0981 - val_accuracy: 0.9735\n",
      "Epoch 669/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0728 - accuracy: 0.9803 - val_loss: 0.0998 - val_accuracy: 0.9731\n",
      "Epoch 670/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0720 - accuracy: 0.9797 - val_loss: 0.0982 - val_accuracy: 0.9732\n",
      "Epoch 671/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0705 - accuracy: 0.9795 - val_loss: 0.0998 - val_accuracy: 0.9726\n",
      "Epoch 672/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0715 - accuracy: 0.9799 - val_loss: 0.0988 - val_accuracy: 0.9731\n",
      "Epoch 673/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0729 - accuracy: 0.9787 - val_loss: 0.0993 - val_accuracy: 0.9734\n",
      "Epoch 674/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.0688 - accuracy: 0.9814 - val_loss: 0.0984 - val_accuracy: 0.9737\n",
      "Epoch 675/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.0701 - accuracy: 0.9808 - val_loss: 0.0978 - val_accuracy: 0.9740\n",
      "Epoch 676/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.0703 - accuracy: 0.9804 - val_loss: 0.0971 - val_accuracy: 0.9736\n",
      "Epoch 677/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0698 - accuracy: 0.9799 - val_loss: 0.0973 - val_accuracy: 0.9736\n",
      "Epoch 678/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0679 - accuracy: 0.9802 - val_loss: 0.0980 - val_accuracy: 0.9740\n",
      "Epoch 679/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0693 - accuracy: 0.9804 - val_loss: 0.0983 - val_accuracy: 0.9739\n",
      "Epoch 680/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0690 - accuracy: 0.9813 - val_loss: 0.0974 - val_accuracy: 0.9737\n",
      "Epoch 681/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0668 - accuracy: 0.9810 - val_loss: 0.0978 - val_accuracy: 0.9738\n",
      "Epoch 682/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0710 - accuracy: 0.9803 - val_loss: 0.0972 - val_accuracy: 0.9738\n",
      "Epoch 683/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.0702 - accuracy: 0.9803 - val_loss: 0.0969 - val_accuracy: 0.9744\n",
      "Epoch 684/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.0682 - accuracy: 0.9810 - val_loss: 0.0961 - val_accuracy: 0.9734\n",
      "Epoch 685/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.0677 - accuracy: 0.9813 - val_loss: 0.0972 - val_accuracy: 0.9741\n",
      "Epoch 686/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.0681 - accuracy: 0.9816 - val_loss: 0.0971 - val_accuracy: 0.9739\n",
      "Epoch 687/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0685 - accuracy: 0.9796 - val_loss: 0.0975 - val_accuracy: 0.9739\n",
      "Epoch 688/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0699 - accuracy: 0.9794 - val_loss: 0.0970 - val_accuracy: 0.9739\n",
      "Epoch 689/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0651 - accuracy: 0.9825 - val_loss: 0.0968 - val_accuracy: 0.9735\n",
      "Epoch 690/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0679 - accuracy: 0.9805 - val_loss: 0.0981 - val_accuracy: 0.9736\n",
      "Epoch 691/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0691 - accuracy: 0.9806 - val_loss: 0.0969 - val_accuracy: 0.9742\n",
      "Epoch 692/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0671 - accuracy: 0.9818 - val_loss: 0.0965 - val_accuracy: 0.9737\n",
      "Epoch 693/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.0670 - accuracy: 0.9800 - val_loss: 0.0972 - val_accuracy: 0.9740\n",
      "Epoch 694/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0661 - accuracy: 0.9819 - val_loss: 0.0956 - val_accuracy: 0.9743\n",
      "Epoch 695/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0668 - accuracy: 0.9813 - val_loss: 0.0964 - val_accuracy: 0.9742\n",
      "Epoch 696/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.0648 - accuracy: 0.9816 - val_loss: 0.0959 - val_accuracy: 0.9750\n",
      "Epoch 697/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0660 - accuracy: 0.9818 - val_loss: 0.0959 - val_accuracy: 0.9743\n",
      "Epoch 698/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0660 - accuracy: 0.9824 - val_loss: 0.0953 - val_accuracy: 0.9740\n",
      "Epoch 699/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0662 - accuracy: 0.9819 - val_loss: 0.0959 - val_accuracy: 0.9742\n",
      "Epoch 700/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0673 - accuracy: 0.9813 - val_loss: 0.0951 - val_accuracy: 0.9744\n",
      "Epoch 701/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0629 - accuracy: 0.9829 - val_loss: 0.0948 - val_accuracy: 0.9746\n",
      "Epoch 702/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0662 - accuracy: 0.9809 - val_loss: 0.0971 - val_accuracy: 0.9745\n",
      "Epoch 703/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0653 - accuracy: 0.9812 - val_loss: 0.0960 - val_accuracy: 0.9749\n",
      "Epoch 704/1000\n",
      "487/487 [==============================] - 18s 38ms/step - loss: 0.0638 - accuracy: 0.9823 - val_loss: 0.0952 - val_accuracy: 0.9751\n",
      "Epoch 705/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0639 - accuracy: 0.9826 - val_loss: 0.0953 - val_accuracy: 0.9746\n",
      "Epoch 706/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0628 - accuracy: 0.9825 - val_loss: 0.0960 - val_accuracy: 0.9746\n",
      "Epoch 707/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0651 - accuracy: 0.9820 - val_loss: 0.0945 - val_accuracy: 0.9752\n",
      "Epoch 708/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0658 - accuracy: 0.9822 - val_loss: 0.0953 - val_accuracy: 0.9749\n",
      "Epoch 709/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0617 - accuracy: 0.9835 - val_loss: 0.0940 - val_accuracy: 0.9748\n",
      "Epoch 710/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0639 - accuracy: 0.9816 - val_loss: 0.0939 - val_accuracy: 0.9751\n",
      "Epoch 711/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0632 - accuracy: 0.9815 - val_loss: 0.0935 - val_accuracy: 0.9748\n",
      "Epoch 712/1000\n",
      "487/487 [==============================] - 18s 38ms/step - loss: 0.0641 - accuracy: 0.9823 - val_loss: 0.0932 - val_accuracy: 0.9744\n",
      "Epoch 713/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0642 - accuracy: 0.9818 - val_loss: 0.0926 - val_accuracy: 0.9751\n",
      "Epoch 714/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0633 - accuracy: 0.9820 - val_loss: 0.0947 - val_accuracy: 0.9749\n",
      "Epoch 715/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0630 - accuracy: 0.9832 - val_loss: 0.0953 - val_accuracy: 0.9746\n",
      "Epoch 716/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0628 - accuracy: 0.9828 - val_loss: 0.0935 - val_accuracy: 0.9749\n",
      "Epoch 717/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0618 - accuracy: 0.9832 - val_loss: 0.0941 - val_accuracy: 0.9748\n",
      "Epoch 718/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0642 - accuracy: 0.9811 - val_loss: 0.0940 - val_accuracy: 0.9749\n",
      "Epoch 719/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0613 - accuracy: 0.9830 - val_loss: 0.0938 - val_accuracy: 0.9746\n",
      "Epoch 720/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0631 - accuracy: 0.9823 - val_loss: 0.0932 - val_accuracy: 0.9750\n",
      "Epoch 721/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0609 - accuracy: 0.9837 - val_loss: 0.0926 - val_accuracy: 0.9752\n",
      "Epoch 722/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0624 - accuracy: 0.9827 - val_loss: 0.0934 - val_accuracy: 0.9751\n",
      "Epoch 723/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0632 - accuracy: 0.9825 - val_loss: 0.0928 - val_accuracy: 0.9757\n",
      "Epoch 724/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0609 - accuracy: 0.9834 - val_loss: 0.0926 - val_accuracy: 0.9749\n",
      "Epoch 725/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.0594 - accuracy: 0.9846 - val_loss: 0.0925 - val_accuracy: 0.9758\n",
      "Epoch 726/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0594 - accuracy: 0.9843 - val_loss: 0.0925 - val_accuracy: 0.9753\n",
      "Epoch 727/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0627 - accuracy: 0.9815 - val_loss: 0.0917 - val_accuracy: 0.9751\n",
      "Epoch 728/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0591 - accuracy: 0.9840 - val_loss: 0.0936 - val_accuracy: 0.9750\n",
      "Epoch 729/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.0614 - accuracy: 0.9831 - val_loss: 0.0915 - val_accuracy: 0.9757\n",
      "Epoch 730/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.0590 - accuracy: 0.9839 - val_loss: 0.0938 - val_accuracy: 0.9751\n",
      "Epoch 731/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0575 - accuracy: 0.9848 - val_loss: 0.0928 - val_accuracy: 0.9753\n",
      "Epoch 732/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0611 - accuracy: 0.9830 - val_loss: 0.0919 - val_accuracy: 0.9752\n",
      "Epoch 733/1000\n",
      "487/487 [==============================] - 18s 38ms/step - loss: 0.0581 - accuracy: 0.9841 - val_loss: 0.0911 - val_accuracy: 0.9758\n",
      "Epoch 734/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0620 - accuracy: 0.9823 - val_loss: 0.0910 - val_accuracy: 0.9755\n",
      "Epoch 735/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0597 - accuracy: 0.9837 - val_loss: 0.0915 - val_accuracy: 0.9757\n",
      "Epoch 736/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.0612 - accuracy: 0.9824 - val_loss: 0.0907 - val_accuracy: 0.9750\n",
      "Epoch 737/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0594 - accuracy: 0.9840 - val_loss: 0.0909 - val_accuracy: 0.9752\n",
      "Epoch 738/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0614 - accuracy: 0.9827 - val_loss: 0.0915 - val_accuracy: 0.9757\n",
      "Epoch 739/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0580 - accuracy: 0.9843 - val_loss: 0.0908 - val_accuracy: 0.9760\n",
      "Epoch 740/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0572 - accuracy: 0.9848 - val_loss: 0.0907 - val_accuracy: 0.9755\n",
      "Epoch 741/1000\n",
      "487/487 [==============================] - 18s 37ms/step - loss: 0.0596 - accuracy: 0.9830 - val_loss: 0.0912 - val_accuracy: 0.9757\n",
      "Epoch 742/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0563 - accuracy: 0.9856 - val_loss: 0.0911 - val_accuracy: 0.9760\n",
      "Epoch 743/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0584 - accuracy: 0.9833 - val_loss: 0.0913 - val_accuracy: 0.9758\n",
      "Epoch 744/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0578 - accuracy: 0.9832 - val_loss: 0.0921 - val_accuracy: 0.9762\n",
      "Epoch 745/1000\n",
      "487/487 [==============================] - 17s 36ms/step - loss: 0.0575 - accuracy: 0.9848 - val_loss: 0.0915 - val_accuracy: 0.9764\n",
      "Epoch 746/1000\n",
      "487/487 [==============================] - 18s 36ms/step - loss: 0.0569 - accuracy: 0.9841 - val_loss: 0.0920 - val_accuracy: 0.9761\n"
     ]
    }
   ],
   "source": [
    "print('Training model 1')\n",
    "opt = Adam(learning_rate=0.00001)\n",
    "earlystopping = callbacks.EarlyStopping(monitor=\"val_loss\", patience = 10, restore_best_weights = True)\n",
    "# Compile the model with categorical crossentropy loss function and Adam optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "# model1.summary()\n",
    "\n",
    "\n",
    "\n",
    "history_const = model.fit(X_train, y_train,batch_size=50, epochs = 1000, validation_data=(X_test,y_test),\n",
    "                   callbacks= [earlystopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d5b72d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving\n",
      "saved\n"
     ]
    }
   ],
   "source": [
    "print('Saving')\n",
    "np.save(load_path+model_name1+'_history.npy',history_const.history)\n",
    "model1.save(load_path+model_name1+'_model.h5') \n",
    "print(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f40f84c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "# #load saved history\n",
    "history_const=np.load(load_path+model_name1+'_history.npy',allow_pickle='TRUE').item()\n",
    "\n",
    "# #load saved model\n",
    "model1=load_model(load_path+model_name1+'_model.h5')\n",
    "\n",
    "print(\"loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "caf213f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Plots')\n",
    "plt.plot(history_const.history['loss'])\n",
    "plt.plot(history_const.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "# plt.savefig('F:/VA/onehandtwohand/26words_DSLR_results/'+model_name1+'_loss.png')\n",
    "plt.savefig(load_path+model_name1+'_loss.png')\n",
    "plt.show()\n",
    "plt.plot(history_const.history['accuracy'])\n",
    "plt.plot(history_const.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig(load_path+model_name1+'_accuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4006fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion matrix')\n",
    "Y_pred = model1.predict(X_new)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_test1 = np.argmax(y_new, axis=1)\n",
    "\n",
    "cm=metrics.confusion_matrix(y_test1, y_pred)\n",
    "\n",
    "\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "a4_dims = (200, 100)\n",
    "fig,ax= plt.subplots(figsize=a4_dims)\n",
    "sns.heatmap(cm, annot=True, fmt=\".2f\", ax=ax,  linewidth=.5);  \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.set_xticklabels(CATEGORIES)\n",
    "ax.set_yticklabels(CATEGORIES)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.setp(ax.get_xticklabels(), rotation=90, horizontalalignment='right')\n",
    "plt.setp(ax.get_yticklabels(), rotation=0, horizontalalignment='right')\n",
    "plt.savefig(load_path+model_name1+'_cm.png',bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57902f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLot fractional incorrect misclassifications\n",
    "\n",
    "incorr_fraction = 1 - np.diag(cm) / np.sum(cm, axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plt.bar(np.arange(cat_len), incorr_fraction)\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Fraction of incorrect predictions')\n",
    "plt.xticks(np.arange(cat_len), CATEGORIES)\n",
    "plt.savefig(load_path+model_name1+'_incorrect_percentage.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c596ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK RANDOM IMAGES FROM TESTED DATA WHETHER RIGHT OR WRONG\n",
    "\n",
    "i = random.randint(1,cat_len)\n",
    "plt.imshow(X_new[i,:,:,2]) \n",
    "print(\"Predicted Label: \", CATEGORIES[int(y_pred[i])])\n",
    "print(\"True Label: \", CATEGORIES[int(y_test1[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fc757b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "794a50d2",
   "metadata": {},
   "source": [
    "# Colourful mediapipe testing with VA_create_3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f40106c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "    \n",
    "def draw_landmarks(image, results):   \n",
    "    #face\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        results.face_landmarks,\n",
    "        mp_holistic.FACEMESH_CONTOURS,\n",
    "        landmark_drawing_spec=None,\n",
    "        connection_drawing_spec=mp_drawing_styles\n",
    "        .get_default_face_mesh_contours_style())\n",
    "#     #pose\n",
    "#     mp_drawing.draw_landmarks(\n",
    "#         image,\n",
    "#         results.pose_landmarks,\n",
    "#         mp_holistic.POSE_CONNECTIONS,\n",
    "#         landmark_drawing_spec=mp_drawing_styles\n",
    "#         .get_default_pose_landmarks_style())\n",
    "    \n",
    "    #left hand\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        results.left_hand_landmarks,\n",
    "        mp_holistic.HAND_CONNECTIONS,\n",
    "#         landmark_drawing_spec=None,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())\n",
    "    # right hand\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        results.right_hand_landmarks,\n",
    "        mp_holistic.HAND_CONNECTIONS,\n",
    "#         landmark_drawing_spec=None,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a1bc8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For veryyyyyyyy beautiful webcam input:\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "org = (20, 20)  \n",
    "org1 = (310, 20) \n",
    "fontScale = 0.65  \n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "# Blue color in BGR\n",
    "color = (130, 0, 0)  \n",
    "# Line thickness of 2 px\n",
    "thickness = 1 \n",
    "thickness1 = -1\n",
    "start_point = (0,0)\n",
    "end_point = (480,30)\n",
    "color1 = (255, 255, 255)  \n",
    "cls='R'\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "      while cap.isOpened():\n",
    "        #image from feeder\n",
    "        r, img_array = cap.read()\n",
    "        img_array = cv2.flip(img_array, 1)\n",
    "        #webcam\n",
    "        img_array = img_array[:, 80:560, :]\n",
    "        #dslr\n",
    "#         img_array = cv2.resize(img_array[:, 224:800, :],(480,480))\n",
    "        \n",
    "        image, results = mediapipe_detection(img_array, holistic)\n",
    "        draw_landmarks(image, results)\n",
    "        if not (results.left_hand_landmarks or results.right_hand_landmarks):\n",
    "            continue\n",
    "\n",
    "        # white background\n",
    "        img = np.zeros([480,480,3],dtype=np.uint8)\n",
    "        img.fill(255) \n",
    "        draw_landmarks(img, results)\n",
    "\n",
    "        # for prediction\n",
    "        IMG_SIZE=128\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        X = np.array(img).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "        X = X.astype('float32')\n",
    "        X /= 255\n",
    "        X = np.array(X)\n",
    "        Y = model1.predict(X,verbose=0)\n",
    "\n",
    "        if np.max(Y)>0.2:\n",
    "            # for display\n",
    "            image = cv2.rectangle(image, start_point, end_point, color1, thickness1)\n",
    "            image = cv2.rectangle(image, (0,30), (480,30), color, 2)\n",
    "            image = cv2.putText(image,\"Prediction: \"+ CATEGORIES[np.argmax(Y)], org, font, \n",
    "                   fontScale, color, thickness, cv2.LINE_AA)\n",
    "            image = cv2.putText(image,\"Accuracy: \"+ \"%.2f\" % np.max(Y), org1, font, \n",
    "                   fontScale, color, thickness, cv2.LINE_AA)\n",
    "#             if CATEGORIES[np.argmax(Y)]==cls:\n",
    "            if np.max(Y)>0.8:\n",
    "                cv2.imwrite(load_path+'/99.79_misc_rajesh/mp_'+\n",
    "                            CATEGORIES[np.argmax(Y)]+'_'+str(np.max(Y))+'.jpg',image)\n",
    "                cv2.imwrite(load_path+'/99.79_misc_rajesh/ori_'+\n",
    "                            CATEGORIES[np.argmax(Y)]+'_'+str(np.max(Y))+'.jpg',img_array)\n",
    "\n",
    "\n",
    "        cv2.imshow('Realtime testing', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "# close the camera\n",
    "cap.release()\n",
    "\n",
    "# close all the opened windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c88845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8a99bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
