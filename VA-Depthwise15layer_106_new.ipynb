{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d962aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dropout, BatchNormalization, Dense, Flatten, LayerNormalization\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.applications as appl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from keras import callbacks  \n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13774f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path='E:/VA/onehandtwohand/128/106words_DSLR_FH/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edaddf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES=np.load(load_path+'cat_106.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "659cb729",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12d7e2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n"
     ]
    }
   ],
   "source": [
    "cat_len=len(CATEGORIES)\n",
    "print(cat_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc104aa6",
   "metadata": {},
   "source": [
    "# Save combined data npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4dd8029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "# model_name1 = 'InceptionResNetV2'\n",
    "# model_name1 = '4layer'\n",
    "model_name1 = 'depthwise15_106words_dslr128'\n",
    "#model_name2 = 'VGG16'\n",
    "# model_name1 = 'DenseNet121'\n",
    "# model_name1 = 'InceptionV3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa37bec1",
   "metadata": {},
   "source": [
    "Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0def0f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load(load_path+'X_dslr.npy', allow_pickle=True)\n",
    "Y=np.load(load_path+'Y_dslr.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bac9e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype('float32')\n",
    "X /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89586ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting\n",
      "pass\n"
     ]
    }
   ],
   "source": [
    "print('Splitting') \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = cat_len)\n",
    "X_train, X_new, y_train, y_new = train_test_split(X_train, y_train, test_size = 0.2, random_state = cat_len)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "X_new = np.array(X_new)\n",
    "y_new = np.array(y_new)\n",
    "\n",
    "print(\"pass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f26320e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f75aadef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Data Augmentation\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('Image Data Augmentation')\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "val_generator = ImageDataGenerator(rotation_range=0, zoom_range=0.2, width_shift_range=0.2,\n",
    "    height_shift_range=0.2, shear_range=0.2)\n",
    "#                                     , horizontal_flip=True, brightness_range=[0.6,1.3])\n",
    "val_generator.fit(X_train)\n",
    "val_generator.fit(X_new)\n",
    "val_generator.fit(X_test)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48682243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " depthwise_conv2d (Depthwise  (None, 128, 128, 3)      30        \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128, 128, 3)      12        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " depthwise_conv2d_1 (Depthwi  (None, 128, 128, 3)      30        \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " depthwise_conv2d_2 (Depthwi  (None, 128, 128, 3)      30        \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128, 128, 3)      12        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 64, 3)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_3 (Depthwi  (None, 64, 64, 3)        30        \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " depthwise_conv2d_4 (Depthwi  (None, 64, 64, 3)        30        \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64, 64, 3)        12        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " depthwise_conv2d_5 (Depthwi  (None, 64, 64, 3)        30        \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 3)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " depthwise_conv2d_6 (Depthwi  (None, 32, 32, 3)        30        \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 32, 32, 3)        12        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " depthwise_conv2d_7 (Depthwi  (None, 32, 32, 3)        30        \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " depthwise_conv2d_8 (Depthwi  (None, 32, 32, 3)        30        \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 32, 32, 3)        12        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 16, 3)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " depthwise_conv2d_9 (Depthwi  (None, 16, 16, 3)        30        \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " depthwise_conv2d_10 (Depthw  (None, 16, 16, 3)        30        \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " depthwise_conv2d_11 (Depthw  (None, 16, 16, 3)        30        \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 8, 8, 3)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 192)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2048)              395264    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 106)               108650    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,602,510\n",
      "Trainable params: 2,602,480\n",
      "Non-trainable params: 30\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    # First layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu', input_shape=(128, 128, 3)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Second layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Third layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Fourth layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Fifth layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Sixth layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Seventh layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Eighth layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Nineth layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # 10th layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # 11th layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # 12th layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "   \n",
    "    # Flatten the output from convolutional layers\n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    # Add a dense layer to learn the final classification\n",
    "    tf.keras.layers.Dense(2048, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    # Output layer with softmax activation function for multi-class classification\n",
    "    tf.keras.layers.Dense(106, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a88ad52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1\n",
      "Epoch 1/1000\n",
      "244/244 [==============================] - 46s 178ms/step - loss: 4.6449 - accuracy: 0.0158 - val_loss: 4.6619 - val_accuracy: 0.0165\n",
      "Epoch 2/1000\n",
      "244/244 [==============================] - 42s 174ms/step - loss: 4.5412 - accuracy: 0.0359 - val_loss: 4.6225 - val_accuracy: 0.0793\n",
      "Epoch 3/1000\n",
      "244/244 [==============================] - 42s 174ms/step - loss: 4.4151 - accuracy: 0.0611 - val_loss: 4.3566 - val_accuracy: 0.1100\n",
      "Epoch 4/1000\n",
      "244/244 [==============================] - 43s 177ms/step - loss: 4.2470 - accuracy: 0.0834 - val_loss: 4.0669 - val_accuracy: 0.1254\n",
      "Epoch 5/1000\n",
      "244/244 [==============================] - 47s 194ms/step - loss: 4.0576 - accuracy: 0.0980 - val_loss: 3.8210 - val_accuracy: 0.1538\n",
      "Epoch 6/1000\n",
      "244/244 [==============================] - 195s 801ms/step - loss: 3.8674 - accuracy: 0.1170 - val_loss: 3.6038 - val_accuracy: 0.1965\n",
      "Epoch 7/1000\n",
      "244/244 [==============================] - 45s 186ms/step - loss: 3.7016 - accuracy: 0.1340 - val_loss: 3.4185 - val_accuracy: 0.2247\n",
      "Epoch 8/1000\n",
      "244/244 [==============================] - 44s 181ms/step - loss: 3.5577 - accuracy: 0.1543 - val_loss: 3.2634 - val_accuracy: 0.2459\n",
      "Epoch 9/1000\n",
      "244/244 [==============================] - 44s 180ms/step - loss: 3.4408 - accuracy: 0.1688 - val_loss: 3.1306 - val_accuracy: 0.2699\n",
      "Epoch 10/1000\n",
      "244/244 [==============================] - 43s 176ms/step - loss: 3.3426 - accuracy: 0.1826 - val_loss: 3.0244 - val_accuracy: 0.2861\n",
      "Epoch 11/1000\n",
      "244/244 [==============================] - 46s 190ms/step - loss: 3.2542 - accuracy: 0.1974 - val_loss: 2.9332 - val_accuracy: 0.2990\n",
      "Epoch 12/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 3.1824 - accuracy: 0.2045 - val_loss: 2.8524 - val_accuracy: 0.3111\n",
      "Epoch 13/1000\n",
      "244/244 [==============================] - 44s 182ms/step - loss: 3.1104 - accuracy: 0.2179 - val_loss: 2.7844 - val_accuracy: 0.3225\n",
      "Epoch 14/1000\n",
      "244/244 [==============================] - 45s 182ms/step - loss: 3.0530 - accuracy: 0.2247 - val_loss: 2.7214 - val_accuracy: 0.3329\n",
      "Epoch 15/1000\n",
      "244/244 [==============================] - 44s 182ms/step - loss: 2.9890 - accuracy: 0.2395 - val_loss: 2.6616 - val_accuracy: 0.3402\n",
      "Epoch 16/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 2.9282 - accuracy: 0.2491 - val_loss: 2.6022 - val_accuracy: 0.3540\n",
      "Epoch 17/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 2.8834 - accuracy: 0.2541 - val_loss: 2.5490 - val_accuracy: 0.3631\n",
      "Epoch 18/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 2.8250 - accuracy: 0.2664 - val_loss: 2.4987 - val_accuracy: 0.3713\n",
      "Epoch 19/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 2.7695 - accuracy: 0.2763 - val_loss: 2.4492 - val_accuracy: 0.3787\n",
      "Epoch 20/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 2.7367 - accuracy: 0.2841 - val_loss: 2.4072 - val_accuracy: 0.3865\n",
      "Epoch 21/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 2.6928 - accuracy: 0.2924 - val_loss: 2.3628 - val_accuracy: 0.3952\n",
      "Epoch 22/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 2.6425 - accuracy: 0.3032 - val_loss: 2.3228 - val_accuracy: 0.4033\n",
      "Epoch 23/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 2.6050 - accuracy: 0.3091 - val_loss: 2.2774 - val_accuracy: 0.4110\n",
      "Epoch 24/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 2.5566 - accuracy: 0.3181 - val_loss: 2.2369 - val_accuracy: 0.4195\n",
      "Epoch 25/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 2.5298 - accuracy: 0.3232 - val_loss: 2.2003 - val_accuracy: 0.4268\n",
      "Epoch 26/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 2.4871 - accuracy: 0.3340 - val_loss: 2.1621 - val_accuracy: 0.4338\n",
      "Epoch 27/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 2.4452 - accuracy: 0.3388 - val_loss: 2.1241 - val_accuracy: 0.4417\n",
      "Epoch 28/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 2.4039 - accuracy: 0.3496 - val_loss: 2.0887 - val_accuracy: 0.4510\n",
      "Epoch 29/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 2.3637 - accuracy: 0.3599 - val_loss: 2.0530 - val_accuracy: 0.4561\n",
      "Epoch 30/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 2.3332 - accuracy: 0.3655 - val_loss: 2.0182 - val_accuracy: 0.4632\n",
      "Epoch 31/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 2.3059 - accuracy: 0.3702 - val_loss: 1.9867 - val_accuracy: 0.4724\n",
      "Epoch 32/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 2.2712 - accuracy: 0.3781 - val_loss: 1.9565 - val_accuracy: 0.4782\n",
      "Epoch 33/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 2.2292 - accuracy: 0.3902 - val_loss: 1.9234 - val_accuracy: 0.4851\n",
      "Epoch 34/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 2.2017 - accuracy: 0.3942 - val_loss: 1.8938 - val_accuracy: 0.4933\n",
      "Epoch 35/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 2.1700 - accuracy: 0.4005 - val_loss: 1.8600 - val_accuracy: 0.5003\n",
      "Epoch 36/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 2.1425 - accuracy: 0.4065 - val_loss: 1.8309 - val_accuracy: 0.5076\n",
      "Epoch 37/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 2.1058 - accuracy: 0.4125 - val_loss: 1.8023 - val_accuracy: 0.5141\n",
      "Epoch 38/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 2.0955 - accuracy: 0.4186 - val_loss: 1.7743 - val_accuracy: 0.5220\n",
      "Epoch 39/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 2.0491 - accuracy: 0.4267 - val_loss: 1.7435 - val_accuracy: 0.5271\n",
      "Epoch 40/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 2.0143 - accuracy: 0.4369 - val_loss: 1.7147 - val_accuracy: 0.5352\n",
      "Epoch 41/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.9912 - accuracy: 0.4417 - val_loss: 1.6878 - val_accuracy: 0.5414\n",
      "Epoch 42/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.9568 - accuracy: 0.4485 - val_loss: 1.6608 - val_accuracy: 0.5480\n",
      "Epoch 43/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.9294 - accuracy: 0.4551 - val_loss: 1.6357 - val_accuracy: 0.5516\n",
      "Epoch 44/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.9092 - accuracy: 0.4585 - val_loss: 1.6061 - val_accuracy: 0.5608\n",
      "Epoch 45/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.8824 - accuracy: 0.4657 - val_loss: 1.5835 - val_accuracy: 0.5652\n",
      "Epoch 46/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 1.8623 - accuracy: 0.4692 - val_loss: 1.5573 - val_accuracy: 0.5731\n",
      "Epoch 47/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.8326 - accuracy: 0.4757 - val_loss: 1.5312 - val_accuracy: 0.5799\n",
      "Epoch 48/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.7974 - accuracy: 0.4878 - val_loss: 1.5059 - val_accuracy: 0.5829\n",
      "Epoch 49/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.7742 - accuracy: 0.4917 - val_loss: 1.4812 - val_accuracy: 0.5891\n",
      "Epoch 50/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.7519 - accuracy: 0.4938 - val_loss: 1.4565 - val_accuracy: 0.5977\n",
      "Epoch 51/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 1.7290 - accuracy: 0.4993 - val_loss: 1.4346 - val_accuracy: 0.6032\n",
      "Epoch 52/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.6954 - accuracy: 0.5120 - val_loss: 1.4121 - val_accuracy: 0.6078\n",
      "Epoch 53/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.6779 - accuracy: 0.5133 - val_loss: 1.3873 - val_accuracy: 0.6139\n",
      "Epoch 54/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 1.6555 - accuracy: 0.5210 - val_loss: 1.3646 - val_accuracy: 0.6187\n",
      "Epoch 55/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 1.6361 - accuracy: 0.5297 - val_loss: 1.3454 - val_accuracy: 0.6250\n",
      "Epoch 56/1000\n",
      "244/244 [==============================] - 44s 181ms/step - loss: 1.6191 - accuracy: 0.5299 - val_loss: 1.3225 - val_accuracy: 0.6337\n",
      "Epoch 57/1000\n",
      "244/244 [==============================] - 44s 181ms/step - loss: 1.5833 - accuracy: 0.5421 - val_loss: 1.3016 - val_accuracy: 0.6388\n",
      "Epoch 58/1000\n",
      "244/244 [==============================] - 44s 181ms/step - loss: 1.5599 - accuracy: 0.5455 - val_loss: 1.2805 - val_accuracy: 0.6449\n",
      "Epoch 59/1000\n",
      "244/244 [==============================] - 44s 182ms/step - loss: 1.5464 - accuracy: 0.5474 - val_loss: 1.2588 - val_accuracy: 0.6514\n",
      "Epoch 60/1000\n",
      "244/244 [==============================] - 44s 182ms/step - loss: 1.5259 - accuracy: 0.5545 - val_loss: 1.2429 - val_accuracy: 0.6566\n",
      "Epoch 61/1000\n",
      "244/244 [==============================] - 44s 182ms/step - loss: 1.5003 - accuracy: 0.5619 - val_loss: 1.2228 - val_accuracy: 0.6612\n",
      "Epoch 62/1000\n",
      "244/244 [==============================] - 44s 182ms/step - loss: 1.4786 - accuracy: 0.5669 - val_loss: 1.2016 - val_accuracy: 0.6651\n",
      "Epoch 63/1000\n",
      "244/244 [==============================] - 44s 181ms/step - loss: 1.4695 - accuracy: 0.5661 - val_loss: 1.1829 - val_accuracy: 0.6710\n",
      "Epoch 64/1000\n",
      "244/244 [==============================] - 44s 182ms/step - loss: 1.4440 - accuracy: 0.5786 - val_loss: 1.1659 - val_accuracy: 0.6759\n",
      "Epoch 65/1000\n",
      "244/244 [==============================] - 44s 182ms/step - loss: 1.4212 - accuracy: 0.5809 - val_loss: 1.1475 - val_accuracy: 0.6805\n",
      "Epoch 66/1000\n",
      "244/244 [==============================] - 44s 182ms/step - loss: 1.4031 - accuracy: 0.5832 - val_loss: 1.1258 - val_accuracy: 0.6877\n",
      "Epoch 67/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.3792 - accuracy: 0.5921 - val_loss: 1.1084 - val_accuracy: 0.6908\n",
      "Epoch 68/1000\n",
      "244/244 [==============================] - 44s 182ms/step - loss: 1.3661 - accuracy: 0.5959 - val_loss: 1.0931 - val_accuracy: 0.6954\n",
      "Epoch 69/1000\n",
      "244/244 [==============================] - 44s 182ms/step - loss: 1.3521 - accuracy: 0.5978 - val_loss: 1.0756 - val_accuracy: 0.7010\n",
      "Epoch 70/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.3305 - accuracy: 0.6061 - val_loss: 1.0601 - val_accuracy: 0.7043\n",
      "Epoch 71/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.3113 - accuracy: 0.6080 - val_loss: 1.0438 - val_accuracy: 0.7108\n",
      "Epoch 72/1000\n",
      "244/244 [==============================] - 44s 182ms/step - loss: 1.2893 - accuracy: 0.6218 - val_loss: 1.0270 - val_accuracy: 0.7135\n",
      "Epoch 73/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.2704 - accuracy: 0.6238 - val_loss: 1.0138 - val_accuracy: 0.7187\n",
      "Epoch 74/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.2485 - accuracy: 0.6296 - val_loss: 0.9981 - val_accuracy: 0.7216\n",
      "Epoch 75/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.2384 - accuracy: 0.6325 - val_loss: 0.9820 - val_accuracy: 0.7269\n",
      "Epoch 76/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.2212 - accuracy: 0.6358 - val_loss: 0.9590 - val_accuracy: 0.7306\n",
      "Epoch 77/1000\n",
      "244/244 [==============================] - 45s 182ms/step - loss: 1.1978 - accuracy: 0.6422 - val_loss: 0.9466 - val_accuracy: 0.7363\n",
      "Epoch 78/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.1874 - accuracy: 0.6460 - val_loss: 0.9394 - val_accuracy: 0.7395\n",
      "Epoch 79/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.1732 - accuracy: 0.6482 - val_loss: 0.9207 - val_accuracy: 0.7432\n",
      "Epoch 80/1000\n",
      "244/244 [==============================] - 44s 182ms/step - loss: 1.1592 - accuracy: 0.6537 - val_loss: 0.9030 - val_accuracy: 0.7487\n",
      "Epoch 81/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.1444 - accuracy: 0.6565 - val_loss: 0.8936 - val_accuracy: 0.7533\n",
      "Epoch 82/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.1298 - accuracy: 0.6614 - val_loss: 0.8759 - val_accuracy: 0.7555\n",
      "Epoch 83/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.1087 - accuracy: 0.6696 - val_loss: 0.8638 - val_accuracy: 0.7604\n",
      "Epoch 84/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.1022 - accuracy: 0.6710 - val_loss: 0.8568 - val_accuracy: 0.7621\n",
      "Epoch 85/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.0771 - accuracy: 0.6766 - val_loss: 0.8349 - val_accuracy: 0.7665\n",
      "Epoch 86/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 1.0765 - accuracy: 0.6753 - val_loss: 0.8295 - val_accuracy: 0.7681\n",
      "Epoch 87/1000\n",
      "244/244 [==============================] - 45s 185ms/step - loss: 1.0628 - accuracy: 0.6790 - val_loss: 0.8097 - val_accuracy: 0.7709\n",
      "Epoch 88/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 1.0402 - accuracy: 0.6865 - val_loss: 0.8035 - val_accuracy: 0.7752\n",
      "Epoch 89/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.0323 - accuracy: 0.6895 - val_loss: 0.7958 - val_accuracy: 0.7766\n",
      "Epoch 90/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 1.0156 - accuracy: 0.6912 - val_loss: 0.7760 - val_accuracy: 0.7821\n",
      "Epoch 91/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.9998 - accuracy: 0.6948 - val_loss: 0.7661 - val_accuracy: 0.7849\n",
      "Epoch 92/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.9953 - accuracy: 0.6962 - val_loss: 0.7577 - val_accuracy: 0.7895\n",
      "Epoch 93/1000\n",
      "244/244 [==============================] - 45s 185ms/step - loss: 0.9780 - accuracy: 0.7020 - val_loss: 0.7439 - val_accuracy: 0.7924\n",
      "Epoch 94/1000\n",
      "244/244 [==============================] - 45s 186ms/step - loss: 0.9682 - accuracy: 0.7061 - val_loss: 0.7348 - val_accuracy: 0.7933\n",
      "Epoch 95/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.9619 - accuracy: 0.7094 - val_loss: 0.7239 - val_accuracy: 0.7975\n",
      "Epoch 96/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.9328 - accuracy: 0.7165 - val_loss: 0.7258 - val_accuracy: 0.7949\n",
      "Epoch 97/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.9294 - accuracy: 0.7142 - val_loss: 0.7097 - val_accuracy: 0.7987\n",
      "Epoch 98/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.9151 - accuracy: 0.7215 - val_loss: 0.6922 - val_accuracy: 0.8048\n",
      "Epoch 99/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.9088 - accuracy: 0.7239 - val_loss: 0.6827 - val_accuracy: 0.8063\n",
      "Epoch 100/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.8935 - accuracy: 0.7287 - val_loss: 0.6750 - val_accuracy: 0.8101\n",
      "Epoch 101/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.8868 - accuracy: 0.7276 - val_loss: 0.6626 - val_accuracy: 0.8142\n",
      "Epoch 102/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.8776 - accuracy: 0.7349 - val_loss: 0.6536 - val_accuracy: 0.8151\n",
      "Epoch 103/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.8562 - accuracy: 0.7372 - val_loss: 0.6458 - val_accuracy: 0.8187\n",
      "Epoch 104/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.8520 - accuracy: 0.7391 - val_loss: 0.6338 - val_accuracy: 0.8212\n",
      "Epoch 105/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.8409 - accuracy: 0.7425 - val_loss: 0.6254 - val_accuracy: 0.8220\n",
      "Epoch 106/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.8325 - accuracy: 0.7434 - val_loss: 0.6175 - val_accuracy: 0.8271\n",
      "Epoch 107/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.8198 - accuracy: 0.7482 - val_loss: 0.6091 - val_accuracy: 0.8282\n",
      "Epoch 108/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.8065 - accuracy: 0.7525 - val_loss: 0.6010 - val_accuracy: 0.8300\n",
      "Epoch 109/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.7970 - accuracy: 0.7546 - val_loss: 0.5875 - val_accuracy: 0.8356\n",
      "Epoch 110/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.7875 - accuracy: 0.7605 - val_loss: 0.5833 - val_accuracy: 0.8361\n",
      "Epoch 111/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 44s 181ms/step - loss: 0.7816 - accuracy: 0.7612 - val_loss: 0.5725 - val_accuracy: 0.8396\n",
      "Epoch 112/1000\n",
      "244/244 [==============================] - 44s 181ms/step - loss: 0.7667 - accuracy: 0.7642 - val_loss: 0.5678 - val_accuracy: 0.8405\n",
      "Epoch 113/1000\n",
      "244/244 [==============================] - 44s 182ms/step - loss: 0.7593 - accuracy: 0.7654 - val_loss: 0.5588 - val_accuracy: 0.8434\n",
      "Epoch 114/1000\n",
      "244/244 [==============================] - 44s 182ms/step - loss: 0.7493 - accuracy: 0.7709 - val_loss: 0.5559 - val_accuracy: 0.8432\n",
      "Epoch 115/1000\n",
      "244/244 [==============================] - 45s 186ms/step - loss: 0.7385 - accuracy: 0.7706 - val_loss: 0.5397 - val_accuracy: 0.8473\n",
      "Epoch 116/1000\n",
      "244/244 [==============================] - 44s 180ms/step - loss: 0.7436 - accuracy: 0.7688 - val_loss: 0.5347 - val_accuracy: 0.8496\n",
      "Epoch 117/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.7193 - accuracy: 0.7783 - val_loss: 0.5259 - val_accuracy: 0.8509\n",
      "Epoch 118/1000\n",
      "244/244 [==============================] - 43s 177ms/step - loss: 0.7126 - accuracy: 0.7814 - val_loss: 0.5174 - val_accuracy: 0.8545\n",
      "Epoch 119/1000\n",
      "244/244 [==============================] - 46s 187ms/step - loss: 0.7070 - accuracy: 0.7826 - val_loss: 0.5121 - val_accuracy: 0.8545\n",
      "Epoch 120/1000\n",
      "244/244 [==============================] - 49s 203ms/step - loss: 0.6981 - accuracy: 0.7838 - val_loss: 0.5029 - val_accuracy: 0.8566\n",
      "Epoch 121/1000\n",
      "244/244 [==============================] - 52s 214ms/step - loss: 0.6857 - accuracy: 0.7887 - val_loss: 0.4953 - val_accuracy: 0.8581\n",
      "Epoch 122/1000\n",
      "244/244 [==============================] - 53s 217ms/step - loss: 0.6842 - accuracy: 0.7874 - val_loss: 0.4893 - val_accuracy: 0.8598\n",
      "Epoch 123/1000\n",
      "244/244 [==============================] - 52s 215ms/step - loss: 0.6771 - accuracy: 0.7895 - val_loss: 0.4877 - val_accuracy: 0.8611\n",
      "Epoch 124/1000\n",
      "244/244 [==============================] - 56s 228ms/step - loss: 0.6632 - accuracy: 0.7937 - val_loss: 0.4785 - val_accuracy: 0.8642\n",
      "Epoch 125/1000\n",
      "244/244 [==============================] - 54s 220ms/step - loss: 0.6571 - accuracy: 0.7961 - val_loss: 0.4717 - val_accuracy: 0.8649\n",
      "Epoch 126/1000\n",
      "244/244 [==============================] - 58s 238ms/step - loss: 0.6493 - accuracy: 0.7963 - val_loss: 0.4688 - val_accuracy: 0.8671\n",
      "Epoch 127/1000\n",
      "244/244 [==============================] - 44s 181ms/step - loss: 0.6408 - accuracy: 0.8016 - val_loss: 0.4563 - val_accuracy: 0.8689\n",
      "Epoch 128/1000\n",
      "244/244 [==============================] - 48s 195ms/step - loss: 0.6329 - accuracy: 0.8039 - val_loss: 0.4517 - val_accuracy: 0.8703\n",
      "Epoch 129/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.6341 - accuracy: 0.8011 - val_loss: 0.4459 - val_accuracy: 0.8723\n",
      "Epoch 130/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.6198 - accuracy: 0.8088 - val_loss: 0.4395 - val_accuracy: 0.8736\n",
      "Epoch 131/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.6173 - accuracy: 0.8076 - val_loss: 0.4343 - val_accuracy: 0.8753\n",
      "Epoch 132/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.6007 - accuracy: 0.8119 - val_loss: 0.4304 - val_accuracy: 0.8761\n",
      "Epoch 133/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.5940 - accuracy: 0.8149 - val_loss: 0.4211 - val_accuracy: 0.8792\n",
      "Epoch 134/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.5882 - accuracy: 0.8128 - val_loss: 0.4223 - val_accuracy: 0.8787\n",
      "Epoch 135/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.5787 - accuracy: 0.8202 - val_loss: 0.4148 - val_accuracy: 0.8805\n",
      "Epoch 136/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.5769 - accuracy: 0.8202 - val_loss: 0.4065 - val_accuracy: 0.8828\n",
      "Epoch 137/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.5689 - accuracy: 0.8193 - val_loss: 0.4017 - val_accuracy: 0.8851\n",
      "Epoch 138/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.5639 - accuracy: 0.8249 - val_loss: 0.3941 - val_accuracy: 0.8857\n",
      "Epoch 139/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.5680 - accuracy: 0.8220 - val_loss: 0.3897 - val_accuracy: 0.8886\n",
      "Epoch 140/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.5486 - accuracy: 0.8272 - val_loss: 0.3862 - val_accuracy: 0.8896\n",
      "Epoch 141/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.5506 - accuracy: 0.8265 - val_loss: 0.3863 - val_accuracy: 0.8903\n",
      "Epoch 142/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.5402 - accuracy: 0.8284 - val_loss: 0.3804 - val_accuracy: 0.8912\n",
      "Epoch 143/1000\n",
      "244/244 [==============================] - 45s 185ms/step - loss: 0.5255 - accuracy: 0.8350 - val_loss: 0.3707 - val_accuracy: 0.8940\n",
      "Epoch 144/1000\n",
      "244/244 [==============================] - 47s 194ms/step - loss: 0.5256 - accuracy: 0.8337 - val_loss: 0.3649 - val_accuracy: 0.8950\n",
      "Epoch 145/1000\n",
      "244/244 [==============================] - 47s 191ms/step - loss: 0.5202 - accuracy: 0.8342 - val_loss: 0.3646 - val_accuracy: 0.8959\n",
      "Epoch 146/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.5141 - accuracy: 0.8397 - val_loss: 0.3580 - val_accuracy: 0.8987\n",
      "Epoch 147/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.5062 - accuracy: 0.8415 - val_loss: 0.3532 - val_accuracy: 0.8990\n",
      "Epoch 148/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.5033 - accuracy: 0.8406 - val_loss: 0.3460 - val_accuracy: 0.9006\n",
      "Epoch 149/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.4970 - accuracy: 0.8431 - val_loss: 0.3422 - val_accuracy: 0.9018\n",
      "Epoch 150/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.4880 - accuracy: 0.8469 - val_loss: 0.3392 - val_accuracy: 0.9030\n",
      "Epoch 151/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.4917 - accuracy: 0.8450 - val_loss: 0.3351 - val_accuracy: 0.9042\n",
      "Epoch 152/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.4843 - accuracy: 0.8487 - val_loss: 0.3329 - val_accuracy: 0.9041\n",
      "Epoch 153/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.4744 - accuracy: 0.8496 - val_loss: 0.3265 - val_accuracy: 0.9045\n",
      "Epoch 154/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.4702 - accuracy: 0.8524 - val_loss: 0.3234 - val_accuracy: 0.9066\n",
      "Epoch 155/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.4671 - accuracy: 0.8526 - val_loss: 0.3206 - val_accuracy: 0.9068\n",
      "Epoch 156/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.4593 - accuracy: 0.8556 - val_loss: 0.3156 - val_accuracy: 0.9099\n",
      "Epoch 157/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.4520 - accuracy: 0.8563 - val_loss: 0.3107 - val_accuracy: 0.9098\n",
      "Epoch 158/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.4499 - accuracy: 0.8574 - val_loss: 0.3063 - val_accuracy: 0.9110\n",
      "Epoch 159/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.4475 - accuracy: 0.8568 - val_loss: 0.3023 - val_accuracy: 0.9125\n",
      "Epoch 160/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.4399 - accuracy: 0.8610 - val_loss: 0.2987 - val_accuracy: 0.9143\n",
      "Epoch 161/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.4426 - accuracy: 0.8579 - val_loss: 0.2953 - val_accuracy: 0.9161\n",
      "Epoch 162/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.4306 - accuracy: 0.8623 - val_loss: 0.2936 - val_accuracy: 0.9160\n",
      "Epoch 163/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.4231 - accuracy: 0.8663 - val_loss: 0.2903 - val_accuracy: 0.9176\n",
      "Epoch 164/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.4222 - accuracy: 0.8687 - val_loss: 0.2857 - val_accuracy: 0.9181\n",
      "Epoch 165/1000\n",
      "244/244 [==============================] - 46s 188ms/step - loss: 0.4220 - accuracy: 0.8655 - val_loss: 0.2822 - val_accuracy: 0.9192\n",
      "Epoch 166/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 44s 181ms/step - loss: 0.4195 - accuracy: 0.8653 - val_loss: 0.2808 - val_accuracy: 0.9189\n",
      "Epoch 167/1000\n",
      "244/244 [==============================] - 44s 182ms/step - loss: 0.4169 - accuracy: 0.8666 - val_loss: 0.2757 - val_accuracy: 0.9211\n",
      "Epoch 168/1000\n",
      "244/244 [==============================] - 44s 182ms/step - loss: 0.4093 - accuracy: 0.8692 - val_loss: 0.2745 - val_accuracy: 0.9217\n",
      "Epoch 169/1000\n",
      "244/244 [==============================] - 44s 182ms/step - loss: 0.4008 - accuracy: 0.8721 - val_loss: 0.2706 - val_accuracy: 0.9232\n",
      "Epoch 170/1000\n",
      "244/244 [==============================] - 44s 182ms/step - loss: 0.3970 - accuracy: 0.8766 - val_loss: 0.2678 - val_accuracy: 0.9227\n",
      "Epoch 171/1000\n",
      "244/244 [==============================] - 44s 182ms/step - loss: 0.3886 - accuracy: 0.8772 - val_loss: 0.2639 - val_accuracy: 0.9237\n",
      "Epoch 172/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.3928 - accuracy: 0.8748 - val_loss: 0.2610 - val_accuracy: 0.9246\n",
      "Epoch 173/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.3852 - accuracy: 0.8771 - val_loss: 0.2571 - val_accuracy: 0.9256\n",
      "Epoch 174/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.3786 - accuracy: 0.8789 - val_loss: 0.2550 - val_accuracy: 0.9254\n",
      "Epoch 175/1000\n",
      "244/244 [==============================] - 45s 182ms/step - loss: 0.3784 - accuracy: 0.8782 - val_loss: 0.2532 - val_accuracy: 0.9274\n",
      "Epoch 176/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.3756 - accuracy: 0.8799 - val_loss: 0.2485 - val_accuracy: 0.9283\n",
      "Epoch 177/1000\n",
      "244/244 [==============================] - 44s 182ms/step - loss: 0.3670 - accuracy: 0.8844 - val_loss: 0.2471 - val_accuracy: 0.9278\n",
      "Epoch 178/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.3688 - accuracy: 0.8807 - val_loss: 0.2449 - val_accuracy: 0.9292\n",
      "Epoch 179/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.3661 - accuracy: 0.8826 - val_loss: 0.2425 - val_accuracy: 0.9295\n",
      "Epoch 180/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.3563 - accuracy: 0.8860 - val_loss: 0.2376 - val_accuracy: 0.9316\n",
      "Epoch 181/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.3580 - accuracy: 0.8855 - val_loss: 0.2366 - val_accuracy: 0.9319\n",
      "Epoch 182/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.3556 - accuracy: 0.8845 - val_loss: 0.2329 - val_accuracy: 0.9326\n",
      "Epoch 183/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.3430 - accuracy: 0.8925 - val_loss: 0.2298 - val_accuracy: 0.9336\n",
      "Epoch 184/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.3445 - accuracy: 0.8901 - val_loss: 0.2275 - val_accuracy: 0.9339\n",
      "Epoch 185/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.3469 - accuracy: 0.8877 - val_loss: 0.2262 - val_accuracy: 0.9341\n",
      "Epoch 186/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.3438 - accuracy: 0.8909 - val_loss: 0.2237 - val_accuracy: 0.9351\n",
      "Epoch 187/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.3362 - accuracy: 0.8903 - val_loss: 0.2213 - val_accuracy: 0.9351\n",
      "Epoch 188/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.3345 - accuracy: 0.8924 - val_loss: 0.2186 - val_accuracy: 0.9371\n",
      "Epoch 189/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.3294 - accuracy: 0.8940 - val_loss: 0.2149 - val_accuracy: 0.9368\n",
      "Epoch 190/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.3265 - accuracy: 0.8963 - val_loss: 0.2125 - val_accuracy: 0.9370\n",
      "Epoch 191/1000\n",
      "244/244 [==============================] - 48s 197ms/step - loss: 0.3193 - accuracy: 0.8987 - val_loss: 0.2116 - val_accuracy: 0.9382\n",
      "Epoch 192/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.3169 - accuracy: 0.8980 - val_loss: 0.2093 - val_accuracy: 0.9391\n",
      "Epoch 193/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.3195 - accuracy: 0.8998 - val_loss: 0.2081 - val_accuracy: 0.9393\n",
      "Epoch 194/1000\n",
      "244/244 [==============================] - 45s 185ms/step - loss: 0.3121 - accuracy: 0.8996 - val_loss: 0.2057 - val_accuracy: 0.9395\n",
      "Epoch 195/1000\n",
      "244/244 [==============================] - 45s 186ms/step - loss: 0.3088 - accuracy: 0.9007 - val_loss: 0.2034 - val_accuracy: 0.9406\n",
      "Epoch 196/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.3102 - accuracy: 0.9003 - val_loss: 0.2014 - val_accuracy: 0.9403\n",
      "Epoch 197/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.2972 - accuracy: 0.9054 - val_loss: 0.1977 - val_accuracy: 0.9412\n",
      "Epoch 198/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.2986 - accuracy: 0.9047 - val_loss: 0.1975 - val_accuracy: 0.9416\n",
      "Epoch 199/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.2986 - accuracy: 0.9043 - val_loss: 0.1950 - val_accuracy: 0.9426\n",
      "Epoch 200/1000\n",
      "244/244 [==============================] - 46s 188ms/step - loss: 0.2939 - accuracy: 0.9060 - val_loss: 0.1938 - val_accuracy: 0.9424\n",
      "Epoch 201/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.2859 - accuracy: 0.9086 - val_loss: 0.1910 - val_accuracy: 0.9445\n",
      "Epoch 202/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.2884 - accuracy: 0.9051 - val_loss: 0.1897 - val_accuracy: 0.9442\n",
      "Epoch 203/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.2873 - accuracy: 0.9082 - val_loss: 0.1870 - val_accuracy: 0.9448\n",
      "Epoch 204/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.2871 - accuracy: 0.9066 - val_loss: 0.1857 - val_accuracy: 0.9452\n",
      "Epoch 205/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.2869 - accuracy: 0.9097 - val_loss: 0.1855 - val_accuracy: 0.9455\n",
      "Epoch 206/1000\n",
      "244/244 [==============================] - 47s 193ms/step - loss: 0.2803 - accuracy: 0.9087 - val_loss: 0.1814 - val_accuracy: 0.9462\n",
      "Epoch 207/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.2716 - accuracy: 0.9120 - val_loss: 0.1808 - val_accuracy: 0.9472\n",
      "Epoch 208/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2741 - accuracy: 0.9132 - val_loss: 0.1802 - val_accuracy: 0.9468\n",
      "Epoch 209/1000\n",
      "244/244 [==============================] - 46s 187ms/step - loss: 0.2682 - accuracy: 0.9132 - val_loss: 0.1768 - val_accuracy: 0.9482\n",
      "Epoch 210/1000\n",
      "244/244 [==============================] - 46s 188ms/step - loss: 0.2734 - accuracy: 0.9127 - val_loss: 0.1744 - val_accuracy: 0.9485\n",
      "Epoch 211/1000\n",
      "244/244 [==============================] - 47s 194ms/step - loss: 0.2671 - accuracy: 0.9141 - val_loss: 0.1743 - val_accuracy: 0.9478\n",
      "Epoch 212/1000\n",
      "244/244 [==============================] - 49s 203ms/step - loss: 0.2619 - accuracy: 0.9142 - val_loss: 0.1710 - val_accuracy: 0.9498\n",
      "Epoch 213/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2620 - accuracy: 0.9147 - val_loss: 0.1706 - val_accuracy: 0.9502\n",
      "Epoch 214/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2542 - accuracy: 0.9185 - val_loss: 0.1672 - val_accuracy: 0.9502\n",
      "Epoch 215/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2499 - accuracy: 0.9198 - val_loss: 0.1665 - val_accuracy: 0.9499\n",
      "Epoch 216/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2567 - accuracy: 0.9154 - val_loss: 0.1654 - val_accuracy: 0.9505\n",
      "Epoch 217/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2580 - accuracy: 0.9155 - val_loss: 0.1651 - val_accuracy: 0.9509\n",
      "Epoch 218/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2523 - accuracy: 0.9169 - val_loss: 0.1633 - val_accuracy: 0.9511\n",
      "Epoch 219/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2505 - accuracy: 0.9166 - val_loss: 0.1619 - val_accuracy: 0.9519\n",
      "Epoch 220/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2459 - accuracy: 0.9213 - val_loss: 0.1589 - val_accuracy: 0.9525\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2484 - accuracy: 0.9199 - val_loss: 0.1592 - val_accuracy: 0.9515\n",
      "Epoch 222/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2427 - accuracy: 0.9224 - val_loss: 0.1590 - val_accuracy: 0.9527\n",
      "Epoch 223/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2380 - accuracy: 0.9233 - val_loss: 0.1562 - val_accuracy: 0.9523\n",
      "Epoch 224/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2356 - accuracy: 0.9223 - val_loss: 0.1541 - val_accuracy: 0.9535\n",
      "Epoch 225/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2373 - accuracy: 0.9227 - val_loss: 0.1542 - val_accuracy: 0.9536\n",
      "Epoch 226/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2367 - accuracy: 0.9229 - val_loss: 0.1522 - val_accuracy: 0.9545\n",
      "Epoch 227/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2315 - accuracy: 0.9256 - val_loss: 0.1509 - val_accuracy: 0.9542\n",
      "Epoch 228/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2298 - accuracy: 0.9262 - val_loss: 0.1493 - val_accuracy: 0.9550\n",
      "Epoch 229/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2333 - accuracy: 0.9228 - val_loss: 0.1527 - val_accuracy: 0.9532\n",
      "Epoch 230/1000\n",
      "244/244 [==============================] - 46s 188ms/step - loss: 0.2220 - accuracy: 0.9285 - val_loss: 0.1470 - val_accuracy: 0.9550\n",
      "Epoch 231/1000\n",
      "244/244 [==============================] - 43s 176ms/step - loss: 0.2307 - accuracy: 0.9237 - val_loss: 0.1464 - val_accuracy: 0.9553\n",
      "Epoch 232/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2170 - accuracy: 0.9296 - val_loss: 0.1437 - val_accuracy: 0.9565\n",
      "Epoch 233/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2187 - accuracy: 0.9282 - val_loss: 0.1438 - val_accuracy: 0.9571\n",
      "Epoch 234/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2156 - accuracy: 0.9288 - val_loss: 0.1435 - val_accuracy: 0.9570\n",
      "Epoch 235/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2102 - accuracy: 0.9317 - val_loss: 0.1407 - val_accuracy: 0.9566\n",
      "Epoch 236/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2170 - accuracy: 0.9299 - val_loss: 0.1396 - val_accuracy: 0.9574\n",
      "Epoch 237/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2168 - accuracy: 0.9278 - val_loss: 0.1387 - val_accuracy: 0.9579\n",
      "Epoch 238/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2126 - accuracy: 0.9315 - val_loss: 0.1373 - val_accuracy: 0.9584\n",
      "Epoch 239/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2116 - accuracy: 0.9316 - val_loss: 0.1367 - val_accuracy: 0.9588\n",
      "Epoch 240/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2056 - accuracy: 0.9340 - val_loss: 0.1360 - val_accuracy: 0.9591\n",
      "Epoch 241/1000\n",
      "244/244 [==============================] - 43s 176ms/step - loss: 0.2097 - accuracy: 0.9307 - val_loss: 0.1366 - val_accuracy: 0.9586\n",
      "Epoch 242/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2054 - accuracy: 0.9321 - val_loss: 0.1332 - val_accuracy: 0.9592\n",
      "Epoch 243/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2003 - accuracy: 0.9351 - val_loss: 0.1328 - val_accuracy: 0.9592\n",
      "Epoch 244/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2023 - accuracy: 0.9342 - val_loss: 0.1311 - val_accuracy: 0.9602\n",
      "Epoch 245/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.2009 - accuracy: 0.9356 - val_loss: 0.1314 - val_accuracy: 0.9594\n",
      "Epoch 246/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.1987 - accuracy: 0.9341 - val_loss: 0.1311 - val_accuracy: 0.9599\n",
      "Epoch 247/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.1993 - accuracy: 0.9342 - val_loss: 0.1284 - val_accuracy: 0.9602\n",
      "Epoch 248/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.1989 - accuracy: 0.9359 - val_loss: 0.1286 - val_accuracy: 0.9606\n",
      "Epoch 249/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.1941 - accuracy: 0.9385 - val_loss: 0.1274 - val_accuracy: 0.9613\n",
      "Epoch 250/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.1937 - accuracy: 0.9356 - val_loss: 0.1271 - val_accuracy: 0.9610\n",
      "Epoch 251/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.1907 - accuracy: 0.9380 - val_loss: 0.1286 - val_accuracy: 0.9600\n",
      "Epoch 252/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.1882 - accuracy: 0.9381 - val_loss: 0.1237 - val_accuracy: 0.9620\n",
      "Epoch 253/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.1846 - accuracy: 0.9403 - val_loss: 0.1224 - val_accuracy: 0.9632\n",
      "Epoch 254/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.1853 - accuracy: 0.9391 - val_loss: 0.1221 - val_accuracy: 0.9630\n",
      "Epoch 255/1000\n",
      "244/244 [==============================] - 43s 176ms/step - loss: 0.1825 - accuracy: 0.9408 - val_loss: 0.1226 - val_accuracy: 0.9631\n",
      "Epoch 256/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.1809 - accuracy: 0.9416 - val_loss: 0.1243 - val_accuracy: 0.9616\n",
      "Epoch 257/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.1807 - accuracy: 0.9414 - val_loss: 0.1198 - val_accuracy: 0.9638\n",
      "Epoch 258/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.1778 - accuracy: 0.9426 - val_loss: 0.1206 - val_accuracy: 0.9623\n",
      "Epoch 259/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.1832 - accuracy: 0.9396 - val_loss: 0.1179 - val_accuracy: 0.9635\n",
      "Epoch 260/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.1775 - accuracy: 0.9429 - val_loss: 0.1212 - val_accuracy: 0.9624\n",
      "Epoch 261/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.1759 - accuracy: 0.9432 - val_loss: 0.1163 - val_accuracy: 0.9644\n",
      "Epoch 262/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.1756 - accuracy: 0.9437 - val_loss: 0.1158 - val_accuracy: 0.9646\n",
      "Epoch 263/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.1711 - accuracy: 0.9438 - val_loss: 0.1132 - val_accuracy: 0.9655\n",
      "Epoch 264/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.1700 - accuracy: 0.9430 - val_loss: 0.1144 - val_accuracy: 0.9655\n",
      "Epoch 265/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.1702 - accuracy: 0.9445 - val_loss: 0.1126 - val_accuracy: 0.9652\n",
      "Epoch 266/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.1691 - accuracy: 0.9452 - val_loss: 0.1120 - val_accuracy: 0.9651\n",
      "Epoch 267/1000\n",
      "244/244 [==============================] - 44s 179ms/step - loss: 0.1713 - accuracy: 0.9444 - val_loss: 0.1133 - val_accuracy: 0.9648\n",
      "Epoch 268/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.1607 - accuracy: 0.9472 - val_loss: 0.1118 - val_accuracy: 0.9656\n",
      "Epoch 269/1000\n",
      "244/244 [==============================] - 43s 175ms/step - loss: 0.1624 - accuracy: 0.9484 - val_loss: 0.1101 - val_accuracy: 0.9660\n",
      "Epoch 270/1000\n",
      "244/244 [==============================] - 43s 176ms/step - loss: 0.1651 - accuracy: 0.9466 - val_loss: 0.1093 - val_accuracy: 0.9663\n",
      "Epoch 271/1000\n",
      "244/244 [==============================] - 43s 176ms/step - loss: 0.1625 - accuracy: 0.9453 - val_loss: 0.1086 - val_accuracy: 0.9667\n",
      "Epoch 272/1000\n",
      "244/244 [==============================] - 43s 176ms/step - loss: 0.1651 - accuracy: 0.9451 - val_loss: 0.1079 - val_accuracy: 0.9668\n",
      "Epoch 273/1000\n",
      "244/244 [==============================] - 43s 176ms/step - loss: 0.1610 - accuracy: 0.9474 - val_loss: 0.1073 - val_accuracy: 0.9670\n",
      "Epoch 274/1000\n",
      "244/244 [==============================] - 43s 176ms/step - loss: 0.1615 - accuracy: 0.9471 - val_loss: 0.1076 - val_accuracy: 0.9666\n",
      "Epoch 275/1000\n",
      "244/244 [==============================] - 43s 176ms/step - loss: 0.1559 - accuracy: 0.9488 - val_loss: 0.1069 - val_accuracy: 0.9676\n",
      "Epoch 276/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 44s 180ms/step - loss: 0.1591 - accuracy: 0.9473 - val_loss: 0.1057 - val_accuracy: 0.9671\n",
      "Epoch 277/1000\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.1584 - accuracy: 0.9486 - val_loss: 0.1051 - val_accuracy: 0.9682\n",
      "Epoch 278/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.1519 - accuracy: 0.9503 - val_loss: 0.1048 - val_accuracy: 0.9680\n",
      "Epoch 279/1000\n",
      "244/244 [==============================] - 46s 190ms/step - loss: 0.1512 - accuracy: 0.9511 - val_loss: 0.1047 - val_accuracy: 0.9676\n",
      "Epoch 280/1000\n",
      "244/244 [==============================] - 46s 189ms/step - loss: 0.1525 - accuracy: 0.9484 - val_loss: 0.1030 - val_accuracy: 0.9679\n",
      "Epoch 281/1000\n",
      "244/244 [==============================] - 45s 186ms/step - loss: 0.1508 - accuracy: 0.9500 - val_loss: 0.1026 - val_accuracy: 0.9678\n",
      "Epoch 282/1000\n",
      "244/244 [==============================] - 54s 221ms/step - loss: 0.1511 - accuracy: 0.9501 - val_loss: 0.1018 - val_accuracy: 0.9686\n",
      "Epoch 283/1000\n",
      "244/244 [==============================] - 69s 281ms/step - loss: 0.1493 - accuracy: 0.9504 - val_loss: 0.1016 - val_accuracy: 0.9693\n",
      "Epoch 284/1000\n",
      "244/244 [==============================] - 60s 247ms/step - loss: 0.1485 - accuracy: 0.9514 - val_loss: 0.1009 - val_accuracy: 0.9686\n",
      "Epoch 285/1000\n",
      "244/244 [==============================] - 61s 250ms/step - loss: 0.1470 - accuracy: 0.9528 - val_loss: 0.0995 - val_accuracy: 0.9696\n",
      "Epoch 286/1000\n",
      "244/244 [==============================] - 66s 272ms/step - loss: 0.1452 - accuracy: 0.9531 - val_loss: 0.1001 - val_accuracy: 0.9689\n",
      "Epoch 287/1000\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.1455 - accuracy: 0.9515 - val_loss: 0.0988 - val_accuracy: 0.9696\n",
      "Epoch 288/1000\n",
      "244/244 [==============================] - 45s 182ms/step - loss: 0.1455 - accuracy: 0.9514 - val_loss: 0.0982 - val_accuracy: 0.9700\n",
      "Epoch 289/1000\n",
      "244/244 [==============================] - 44s 179ms/step - loss: 0.1394 - accuracy: 0.9549 - val_loss: 0.0976 - val_accuracy: 0.9703\n",
      "Epoch 290/1000\n",
      "244/244 [==============================] - 44s 180ms/step - loss: 0.1388 - accuracy: 0.9545 - val_loss: 0.0977 - val_accuracy: 0.9699\n",
      "Epoch 291/1000\n",
      "244/244 [==============================] - 44s 180ms/step - loss: 0.1374 - accuracy: 0.9534 - val_loss: 0.0971 - val_accuracy: 0.9712\n",
      "Epoch 292/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.1429 - accuracy: 0.9527 - val_loss: 0.0955 - val_accuracy: 0.9712\n",
      "Epoch 293/1000\n",
      "244/244 [==============================] - 44s 179ms/step - loss: 0.1360 - accuracy: 0.9553 - val_loss: 0.0953 - val_accuracy: 0.9709\n",
      "Epoch 294/1000\n",
      "244/244 [==============================] - 44s 179ms/step - loss: 0.1390 - accuracy: 0.9553 - val_loss: 0.0946 - val_accuracy: 0.9713\n",
      "Epoch 295/1000\n",
      "244/244 [==============================] - 44s 179ms/step - loss: 0.1360 - accuracy: 0.9567 - val_loss: 0.0944 - val_accuracy: 0.9709\n",
      "Epoch 296/1000\n",
      "244/244 [==============================] - 44s 179ms/step - loss: 0.1331 - accuracy: 0.9566 - val_loss: 0.0938 - val_accuracy: 0.9709\n",
      "Epoch 297/1000\n",
      "244/244 [==============================] - 44s 179ms/step - loss: 0.1340 - accuracy: 0.9563 - val_loss: 0.0934 - val_accuracy: 0.9706\n",
      "Epoch 298/1000\n",
      "244/244 [==============================] - 44s 182ms/step - loss: 0.1324 - accuracy: 0.9559 - val_loss: 0.0933 - val_accuracy: 0.9706\n",
      "Epoch 299/1000\n",
      "244/244 [==============================] - 44s 180ms/step - loss: 0.1339 - accuracy: 0.9560 - val_loss: 0.0923 - val_accuracy: 0.9715\n",
      "Epoch 300/1000\n",
      "244/244 [==============================] - 47s 193ms/step - loss: 0.1321 - accuracy: 0.9565 - val_loss: 0.0912 - val_accuracy: 0.9711\n",
      "Epoch 301/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.1314 - accuracy: 0.9580 - val_loss: 0.0900 - val_accuracy: 0.9725\n",
      "Epoch 302/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.1309 - accuracy: 0.9574 - val_loss: 0.0908 - val_accuracy: 0.9717\n",
      "Epoch 303/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.1274 - accuracy: 0.9585 - val_loss: 0.0891 - val_accuracy: 0.9735\n",
      "Epoch 304/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.1302 - accuracy: 0.9587 - val_loss: 0.0902 - val_accuracy: 0.9721\n",
      "Epoch 305/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.1310 - accuracy: 0.9573 - val_loss: 0.0893 - val_accuracy: 0.9733\n",
      "Epoch 306/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.1262 - accuracy: 0.9588 - val_loss: 0.0893 - val_accuracy: 0.9725\n",
      "Epoch 307/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.1205 - accuracy: 0.9613 - val_loss: 0.0891 - val_accuracy: 0.9731\n",
      "Epoch 308/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.1257 - accuracy: 0.9585 - val_loss: 0.0900 - val_accuracy: 0.9718\n",
      "Epoch 309/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.1247 - accuracy: 0.9590 - val_loss: 0.0876 - val_accuracy: 0.9732\n",
      "Epoch 310/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.1200 - accuracy: 0.9603 - val_loss: 0.0873 - val_accuracy: 0.9727\n",
      "Epoch 311/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.1224 - accuracy: 0.9606 - val_loss: 0.0874 - val_accuracy: 0.9732\n",
      "Epoch 312/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.1202 - accuracy: 0.9608 - val_loss: 0.0874 - val_accuracy: 0.9732\n",
      "Epoch 313/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.1176 - accuracy: 0.9620 - val_loss: 0.0852 - val_accuracy: 0.9732\n",
      "Epoch 314/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.1182 - accuracy: 0.9613 - val_loss: 0.0853 - val_accuracy: 0.9737\n",
      "Epoch 315/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.1164 - accuracy: 0.9623 - val_loss: 0.0841 - val_accuracy: 0.9742\n",
      "Epoch 316/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.1135 - accuracy: 0.9624 - val_loss: 0.0846 - val_accuracy: 0.9739\n",
      "Epoch 317/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.1172 - accuracy: 0.9616 - val_loss: 0.0839 - val_accuracy: 0.9745\n",
      "Epoch 318/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.1160 - accuracy: 0.9597 - val_loss: 0.0840 - val_accuracy: 0.9742\n",
      "Epoch 319/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.1161 - accuracy: 0.9618 - val_loss: 0.0833 - val_accuracy: 0.9742\n",
      "Epoch 320/1000\n",
      "244/244 [==============================] - 45s 183ms/step - loss: 0.1151 - accuracy: 0.9632 - val_loss: 0.0832 - val_accuracy: 0.9752\n",
      "Epoch 321/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.1138 - accuracy: 0.9627 - val_loss: 0.0827 - val_accuracy: 0.9745\n",
      "Epoch 322/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.1127 - accuracy: 0.9628 - val_loss: 0.0821 - val_accuracy: 0.9742\n",
      "Epoch 323/1000\n",
      "244/244 [==============================] - 46s 189ms/step - loss: 0.1096 - accuracy: 0.9641 - val_loss: 0.0814 - val_accuracy: 0.9748\n",
      "Epoch 324/1000\n",
      "244/244 [==============================] - 47s 192ms/step - loss: 0.1123 - accuracy: 0.9636 - val_loss: 0.0821 - val_accuracy: 0.9750\n",
      "Epoch 325/1000\n",
      "244/244 [==============================] - 49s 200ms/step - loss: 0.1097 - accuracy: 0.9638 - val_loss: 0.0805 - val_accuracy: 0.9745\n",
      "Epoch 326/1000\n",
      "244/244 [==============================] - 51s 207ms/step - loss: 0.1111 - accuracy: 0.9625 - val_loss: 0.0816 - val_accuracy: 0.9752\n",
      "Epoch 327/1000\n",
      "244/244 [==============================] - 47s 194ms/step - loss: 0.1055 - accuracy: 0.9642 - val_loss: 0.0806 - val_accuracy: 0.9749\n",
      "Epoch 328/1000\n",
      "244/244 [==============================] - 47s 194ms/step - loss: 0.1109 - accuracy: 0.9645 - val_loss: 0.0804 - val_accuracy: 0.9763\n",
      "Epoch 329/1000\n",
      "244/244 [==============================] - 44s 182ms/step - loss: 0.1095 - accuracy: 0.9638 - val_loss: 0.0802 - val_accuracy: 0.9758\n",
      "Epoch 330/1000\n",
      "244/244 [==============================] - 45s 185ms/step - loss: 0.1073 - accuracy: 0.9655 - val_loss: 0.0793 - val_accuracy: 0.9760\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 44s 181ms/step - loss: 0.1063 - accuracy: 0.9644 - val_loss: 0.0789 - val_accuracy: 0.9758\n",
      "Epoch 332/1000\n",
      "244/244 [==============================] - 44s 180ms/step - loss: 0.1045 - accuracy: 0.9670 - val_loss: 0.0791 - val_accuracy: 0.9751\n",
      "Epoch 333/1000\n",
      "244/244 [==============================] - 44s 180ms/step - loss: 0.1062 - accuracy: 0.9652 - val_loss: 0.0807 - val_accuracy: 0.9764\n",
      "Epoch 334/1000\n",
      "244/244 [==============================] - 45s 185ms/step - loss: 0.1047 - accuracy: 0.9653 - val_loss: 0.0801 - val_accuracy: 0.9756\n",
      "Epoch 335/1000\n",
      "244/244 [==============================] - 47s 193ms/step - loss: 0.1010 - accuracy: 0.9665 - val_loss: 0.0788 - val_accuracy: 0.9767\n",
      "Epoch 336/1000\n",
      "244/244 [==============================] - 46s 189ms/step - loss: 0.1045 - accuracy: 0.9661 - val_loss: 0.0770 - val_accuracy: 0.9759\n",
      "Epoch 337/1000\n",
      "244/244 [==============================] - 44s 178ms/step - loss: 0.1014 - accuracy: 0.9662 - val_loss: 0.0764 - val_accuracy: 0.9769\n",
      "Epoch 338/1000\n",
      "244/244 [==============================] - 43s 178ms/step - loss: 0.0988 - accuracy: 0.9687 - val_loss: 0.0766 - val_accuracy: 0.9761\n",
      "Epoch 339/1000\n",
      "244/244 [==============================] - 43s 178ms/step - loss: 0.1024 - accuracy: 0.9671 - val_loss: 0.0762 - val_accuracy: 0.9765\n",
      "Epoch 340/1000\n",
      "244/244 [==============================] - 44s 179ms/step - loss: 0.0995 - accuracy: 0.9673 - val_loss: 0.0767 - val_accuracy: 0.9768\n",
      "Epoch 341/1000\n",
      "244/244 [==============================] - 43s 178ms/step - loss: 0.1003 - accuracy: 0.9667 - val_loss: 0.0753 - val_accuracy: 0.9768\n",
      "Epoch 342/1000\n",
      "244/244 [==============================] - 43s 178ms/step - loss: 0.0995 - accuracy: 0.9686 - val_loss: 0.0761 - val_accuracy: 0.9764\n",
      "Epoch 343/1000\n",
      "244/244 [==============================] - 43s 178ms/step - loss: 0.0999 - accuracy: 0.9673 - val_loss: 0.0755 - val_accuracy: 0.9764\n",
      "Epoch 344/1000\n",
      "244/244 [==============================] - 43s 178ms/step - loss: 0.0974 - accuracy: 0.9681 - val_loss: 0.0752 - val_accuracy: 0.9765\n",
      "Epoch 345/1000\n",
      "244/244 [==============================] - 44s 178ms/step - loss: 0.0974 - accuracy: 0.9686 - val_loss: 0.0751 - val_accuracy: 0.9771\n",
      "Epoch 346/1000\n",
      "244/244 [==============================] - 43s 178ms/step - loss: 0.0955 - accuracy: 0.9675 - val_loss: 0.0741 - val_accuracy: 0.9779\n",
      "Epoch 347/1000\n",
      "244/244 [==============================] - 44s 179ms/step - loss: 0.0980 - accuracy: 0.9684 - val_loss: 0.0732 - val_accuracy: 0.9778\n",
      "Epoch 348/1000\n",
      "244/244 [==============================] - 44s 179ms/step - loss: 0.0969 - accuracy: 0.9677 - val_loss: 0.0733 - val_accuracy: 0.9773\n",
      "Epoch 349/1000\n",
      "244/244 [==============================] - 44s 179ms/step - loss: 0.0937 - accuracy: 0.9691 - val_loss: 0.0732 - val_accuracy: 0.9779\n",
      "Epoch 350/1000\n",
      "244/244 [==============================] - 44s 179ms/step - loss: 0.0923 - accuracy: 0.9691 - val_loss: 0.0723 - val_accuracy: 0.9775\n",
      "Epoch 351/1000\n",
      "244/244 [==============================] - 44s 179ms/step - loss: 0.0903 - accuracy: 0.9701 - val_loss: 0.0719 - val_accuracy: 0.9778\n",
      "Epoch 352/1000\n",
      "244/244 [==============================] - 44s 179ms/step - loss: 0.0935 - accuracy: 0.9682 - val_loss: 0.0723 - val_accuracy: 0.9778\n",
      "Epoch 353/1000\n",
      "244/244 [==============================] - 44s 179ms/step - loss: 0.0923 - accuracy: 0.9699 - val_loss: 0.0717 - val_accuracy: 0.9782\n",
      "Epoch 354/1000\n",
      "244/244 [==============================] - 44s 179ms/step - loss: 0.0946 - accuracy: 0.9684 - val_loss: 0.0708 - val_accuracy: 0.9789\n",
      "Epoch 355/1000\n",
      "244/244 [==============================] - 57s 232ms/step - loss: 0.0907 - accuracy: 0.9701 - val_loss: 0.0718 - val_accuracy: 0.9780\n",
      "Epoch 356/1000\n",
      "244/244 [==============================] - 48s 195ms/step - loss: 0.0910 - accuracy: 0.9697 - val_loss: 0.0712 - val_accuracy: 0.9785\n",
      "Epoch 357/1000\n",
      "244/244 [==============================] - 46s 188ms/step - loss: 0.0888 - accuracy: 0.9710 - val_loss: 0.0709 - val_accuracy: 0.9783\n",
      "Epoch 358/1000\n",
      "244/244 [==============================] - 47s 191ms/step - loss: 0.0926 - accuracy: 0.9694 - val_loss: 0.0712 - val_accuracy: 0.9775\n",
      "Epoch 359/1000\n",
      "244/244 [==============================] - 46s 187ms/step - loss: 0.0862 - accuracy: 0.9717 - val_loss: 0.0707 - val_accuracy: 0.9786\n",
      "Epoch 360/1000\n",
      "244/244 [==============================] - 49s 201ms/step - loss: 0.0894 - accuracy: 0.9713 - val_loss: 0.0695 - val_accuracy: 0.9785\n",
      "Epoch 361/1000\n",
      "244/244 [==============================] - 48s 196ms/step - loss: 0.0869 - accuracy: 0.9711 - val_loss: 0.0693 - val_accuracy: 0.9788\n",
      "Epoch 362/1000\n",
      "244/244 [==============================] - 51s 209ms/step - loss: 0.0884 - accuracy: 0.9717 - val_loss: 0.0685 - val_accuracy: 0.9785\n",
      "Epoch 363/1000\n",
      "244/244 [==============================] - 46s 189ms/step - loss: 0.0877 - accuracy: 0.9715 - val_loss: 0.0691 - val_accuracy: 0.9794\n",
      "Epoch 364/1000\n",
      "244/244 [==============================] - 45s 185ms/step - loss: 0.0863 - accuracy: 0.9730 - val_loss: 0.0683 - val_accuracy: 0.9796\n",
      "Epoch 365/1000\n",
      "244/244 [==============================] - 46s 188ms/step - loss: 0.0846 - accuracy: 0.9724 - val_loss: 0.0680 - val_accuracy: 0.9798\n",
      "Epoch 366/1000\n",
      "244/244 [==============================] - 44s 182ms/step - loss: 0.0881 - accuracy: 0.9722 - val_loss: 0.0689 - val_accuracy: 0.9792\n",
      "Epoch 367/1000\n",
      "244/244 [==============================] - 45s 186ms/step - loss: 0.0851 - accuracy: 0.9721 - val_loss: 0.0680 - val_accuracy: 0.9780\n",
      "Epoch 368/1000\n",
      "244/244 [==============================] - 44s 181ms/step - loss: 0.0833 - accuracy: 0.9737 - val_loss: 0.0689 - val_accuracy: 0.9791\n",
      "Epoch 369/1000\n",
      "244/244 [==============================] - 45s 184ms/step - loss: 0.0825 - accuracy: 0.9735 - val_loss: 0.0694 - val_accuracy: 0.9791\n",
      "Epoch 370/1000\n",
      "244/244 [==============================] - 48s 197ms/step - loss: 0.0820 - accuracy: 0.9733 - val_loss: 0.0674 - val_accuracy: 0.9795\n",
      "Epoch 371/1000\n",
      "244/244 [==============================] - 51s 211ms/step - loss: 0.0841 - accuracy: 0.9721 - val_loss: 0.0681 - val_accuracy: 0.9794\n",
      "Epoch 372/1000\n",
      "244/244 [==============================] - 50s 207ms/step - loss: 0.0853 - accuracy: 0.9717 - val_loss: 0.0668 - val_accuracy: 0.9792\n",
      "Epoch 373/1000\n",
      "244/244 [==============================] - 50s 204ms/step - loss: 0.0817 - accuracy: 0.9728 - val_loss: 0.0688 - val_accuracy: 0.9798\n",
      "Epoch 374/1000\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.0784 - accuracy: 0.9747 - val_loss: 0.0667 - val_accuracy: 0.9799\n",
      "Epoch 375/1000\n",
      "244/244 [==============================] - 48s 197ms/step - loss: 0.0761 - accuracy: 0.9749 - val_loss: 0.0655 - val_accuracy: 0.9801\n",
      "Epoch 376/1000\n",
      "244/244 [==============================] - 50s 206ms/step - loss: 0.0774 - accuracy: 0.9731 - val_loss: 0.0665 - val_accuracy: 0.9794\n",
      "Epoch 377/1000\n",
      "244/244 [==============================] - 49s 202ms/step - loss: 0.0800 - accuracy: 0.9728 - val_loss: 0.0653 - val_accuracy: 0.9806\n",
      "Epoch 378/1000\n",
      "244/244 [==============================] - 50s 205ms/step - loss: 0.0791 - accuracy: 0.9739 - val_loss: 0.0668 - val_accuracy: 0.9797\n",
      "Epoch 379/1000\n",
      "244/244 [==============================] - 49s 199ms/step - loss: 0.0783 - accuracy: 0.9742 - val_loss: 0.0649 - val_accuracy: 0.9801\n",
      "Epoch 380/1000\n",
      "244/244 [==============================] - 49s 202ms/step - loss: 0.0770 - accuracy: 0.9746 - val_loss: 0.0644 - val_accuracy: 0.9802\n",
      "Epoch 381/1000\n",
      "244/244 [==============================] - 49s 203ms/step - loss: 0.0782 - accuracy: 0.9742 - val_loss: 0.0637 - val_accuracy: 0.9810\n",
      "Epoch 382/1000\n",
      "244/244 [==============================] - 49s 202ms/step - loss: 0.0767 - accuracy: 0.9752 - val_loss: 0.0644 - val_accuracy: 0.9811\n",
      "Epoch 383/1000\n",
      "244/244 [==============================] - 50s 204ms/step - loss: 0.0760 - accuracy: 0.9755 - val_loss: 0.0639 - val_accuracy: 0.9814\n",
      "Epoch 384/1000\n",
      "244/244 [==============================] - 49s 202ms/step - loss: 0.0746 - accuracy: 0.9752 - val_loss: 0.0634 - val_accuracy: 0.9814\n",
      "Epoch 385/1000\n",
      "244/244 [==============================] - 50s 207ms/step - loss: 0.0776 - accuracy: 0.9733 - val_loss: 0.0637 - val_accuracy: 0.9813\n",
      "Epoch 386/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 49s 202ms/step - loss: 0.0760 - accuracy: 0.9756 - val_loss: 0.0624 - val_accuracy: 0.9815\n",
      "Epoch 387/1000\n",
      "244/244 [==============================] - 48s 195ms/step - loss: 0.0713 - accuracy: 0.9772 - val_loss: 0.0618 - val_accuracy: 0.9816\n",
      "Epoch 388/1000\n",
      "244/244 [==============================] - 46s 188ms/step - loss: 0.0738 - accuracy: 0.9763 - val_loss: 0.0624 - val_accuracy: 0.9813\n",
      "Epoch 389/1000\n",
      "244/244 [==============================] - 47s 192ms/step - loss: 0.0707 - accuracy: 0.9774 - val_loss: 0.0627 - val_accuracy: 0.9813\n",
      "Epoch 390/1000\n",
      "244/244 [==============================] - 48s 195ms/step - loss: 0.0744 - accuracy: 0.9756 - val_loss: 0.0634 - val_accuracy: 0.9811\n",
      "Epoch 391/1000\n",
      "244/244 [==============================] - 50s 205ms/step - loss: 0.0724 - accuracy: 0.9756 - val_loss: 0.0626 - val_accuracy: 0.9812\n",
      "Epoch 392/1000\n",
      "244/244 [==============================] - 49s 201ms/step - loss: 0.0733 - accuracy: 0.9758 - val_loss: 0.0625 - val_accuracy: 0.9811\n"
     ]
    }
   ],
   "source": [
    "print('Training model 1')\n",
    "opt = Adam(learning_rate=0.00001)\n",
    "earlystopping = callbacks.EarlyStopping(monitor=\"val_loss\", patience = 5, restore_best_weights = True)\n",
    "# Compile the model with categorical crossentropy loss function and Adam optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "# model1.summary()\n",
    "\n",
    "history_const = model.fit(X_train, y_train,batch_size=100, epochs = 1000, validation_data=(X_test,y_test),\n",
    "                   callbacks= [earlystopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d5b72d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving\n",
      "saved\n"
     ]
    }
   ],
   "source": [
    "print('Saving')\n",
    "np.save(load_path+model_name1+'_history.npy',history_const.history)\n",
    "model.save(load_path+model_name1+'_model.h5') \n",
    "print(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f40f84c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "# #load saved history\n",
    "history_const=np.load(load_path+model_name1+'_history.npy',allow_pickle='TRUE').item()\n",
    "\n",
    "# #load saved model\n",
    "model1=load_model(load_path+model_name1+'_model.h5')\n",
    "\n",
    "print(\"loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "caf213f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Plots')\n",
    "plt.plot(history_const.history['loss'])\n",
    "plt.plot(history_const.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "# plt.savefig('F:/VA/onehandtwohand/26words_DSLR_results/'+model_name1+'_loss.png')\n",
    "plt.savefig(load_path+model_name1+'_loss.png')\n",
    "plt.show()\n",
    "plt.plot(history_const.history['accuracy'])\n",
    "plt.plot(history_const.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig(load_path+model_name1+'_accuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4006fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion matrix')\n",
    "Y_pred = model1.predict(X_new)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_test1 = np.argmax(y_new, axis=1)\n",
    "\n",
    "cm=metrics.confusion_matrix(y_test1, y_pred)\n",
    "\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "a4_dims = (200, 100)\n",
    "fig,ax= plt.subplots(figsize=a4_dims)\n",
    "sns.heatmap(cm, annot=True, fmt=\".2f\", ax=ax,  linewidth=.5);  \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.set_xticklabels(CATEGORIES)\n",
    "ax.set_yticklabels(CATEGORIES)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.setp(ax.get_xticklabels(), rotation=90, horizontalalignment='right')\n",
    "plt.setp(ax.get_yticklabels(), rotation=0, horizontalalignment='right')\n",
    "plt.savefig(load_path+model_name1+'_cm.png',bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57902f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLot fractional incorrect misclassifications\n",
    "\n",
    "incorr_fraction = 1 - np.diag(cm) / np.sum(cm, axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plt.bar(np.arange(cat_len), incorr_fraction)\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Fraction of incorrect predictions')\n",
    "plt.xticks(np.arange(cat_len), CATEGORIES)\n",
    "plt.savefig(load_path+model_name1+'_incorrect_percentage.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c596ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK RANDOM IMAGES FROM TESTED DATA WHETHER RIGHT OR WRONG\n",
    "\n",
    "i = random.randint(1,cat_len)\n",
    "plt.imshow(X_new[i,:,:,2]) \n",
    "print(\"Predicted Label: \", CATEGORIES[int(y_pred[i])])\n",
    "print(\"True Label: \", CATEGORIES[int(y_test1[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fc757b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "794a50d2",
   "metadata": {},
   "source": [
    "# Colourful mediapipe testing with VA_create_3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f40106c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "    \n",
    "def draw_landmarks(image, results):   \n",
    "    #face\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        results.face_landmarks,\n",
    "        mp_holistic.FACEMESH_CONTOURS,\n",
    "        landmark_drawing_spec=None,\n",
    "        connection_drawing_spec=mp_drawing_styles\n",
    "        .get_default_face_mesh_contours_style())\n",
    "#     #pose\n",
    "#     mp_drawing.draw_landmarks(\n",
    "#         image,\n",
    "#         results.pose_landmarks,\n",
    "#         mp_holistic.POSE_CONNECTIONS,\n",
    "#         landmark_drawing_spec=mp_drawing_styles\n",
    "#         .get_default_pose_landmarks_style())\n",
    "    \n",
    "    #left hand\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        results.left_hand_landmarks,\n",
    "        mp_holistic.HAND_CONNECTIONS,\n",
    "#         landmark_drawing_spec=None,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())\n",
    "    # right hand\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        results.right_hand_landmarks,\n",
    "        mp_holistic.HAND_CONNECTIONS,\n",
    "#         landmark_drawing_spec=None,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a1bc8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For veryyyyyyyy beautiful webcam input:\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "org = (20, 20)  \n",
    "org1 = (310, 20) \n",
    "fontScale = 0.65  \n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "# Blue color in BGR\n",
    "color = (130, 0, 0)  \n",
    "# Line thickness of 2 px\n",
    "thickness = 1 \n",
    "thickness1 = -1\n",
    "start_point = (0,0)\n",
    "end_point = (480,30)\n",
    "color1 = (255, 255, 255)  \n",
    "cls='R'\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "      while cap.isOpened():\n",
    "        #image from feeder\n",
    "        r, img_array = cap.read()\n",
    "        img_array = cv2.flip(img_array, 1)\n",
    "        #webcam\n",
    "        img_array = img_array[:, 80:560, :]\n",
    "        #dslr\n",
    "#         img_array = cv2.resize(img_array[:, 224:800, :],(480,480))\n",
    "        \n",
    "        image, results = mediapipe_detection(img_array, holistic)\n",
    "        draw_landmarks(image, results)\n",
    "        if not (results.left_hand_landmarks or results.right_hand_landmarks):\n",
    "            continue\n",
    "\n",
    "        # white background\n",
    "        img = np.zeros([480,480,3],dtype=np.uint8)\n",
    "        img.fill(255) \n",
    "        draw_landmarks(img, results)\n",
    "\n",
    "        # for prediction\n",
    "        IMG_SIZE=128\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        X = np.array(img).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "        X = X.astype('float32')\n",
    "        X /= 255\n",
    "        X = np.array(X)\n",
    "        Y = model1.predict(X,verbose=0)\n",
    "\n",
    "        if np.max(Y)>0.2:\n",
    "            # for display\n",
    "            image = cv2.rectangle(image, start_point, end_point, color1, thickness1)\n",
    "            image = cv2.rectangle(image, (0,30), (480,30), color, 2)\n",
    "            image = cv2.putText(image,\"Prediction: \"+ CATEGORIES[np.argmax(Y)], org, font, \n",
    "                   fontScale, color, thickness, cv2.LINE_AA)\n",
    "            image = cv2.putText(image,\"Accuracy: \"+ \"%.2f\" % np.max(Y), org1, font, \n",
    "                   fontScale, color, thickness, cv2.LINE_AA)\n",
    "#             if CATEGORIES[np.argmax(Y)]==cls:\n",
    "            if np.max(Y)>0.8:\n",
    "                cv2.imwrite(load_path+'/99.79_misc_rajesh/mp_'+\n",
    "                            CATEGORIES[np.argmax(Y)]+'_'+str(np.max(Y))+'.jpg',image)\n",
    "                cv2.imwrite(load_path+'/99.79_misc_rajesh/ori_'+\n",
    "                            CATEGORIES[np.argmax(Y)]+'_'+str(np.max(Y))+'.jpg',img_array)\n",
    "\n",
    "\n",
    "        cv2.imshow('Realtime testing', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "# close the camera\n",
    "cap.release()\n",
    "\n",
    "# close all the opened windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c88845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8a99bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
