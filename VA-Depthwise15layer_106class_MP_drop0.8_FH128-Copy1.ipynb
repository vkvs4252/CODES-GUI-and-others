{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d962aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dropout, BatchNormalization, Dense, Flatten, LayerNormalization\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.applications as appl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from keras import callbacks  \n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13774f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path='E:/VA/onehandtwohand/128/106words_DSLR_FH/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edaddf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES=np.load(load_path+'cat_106.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "659cb729",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12d7e2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n"
     ]
    }
   ],
   "source": [
    "cat_len=len(CATEGORIES)\n",
    "print(cat_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc104aa6",
   "metadata": {},
   "source": [
    "# Save combined data npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4dd8029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "# model_name1 = 'InceptionResNetV2'\n",
    "# model_name1 = '4layer'\n",
    "model_name1 = 'depthwise15_106words_dslr128'\n",
    "#model_name2 = 'VGG16'\n",
    "# model_name1 = 'DenseNet121'\n",
    "# model_name1 = 'InceptionV3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa37bec1",
   "metadata": {},
   "source": [
    "Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0def0f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load(load_path+'X_dslr.npy', allow_pickle=True)\n",
    "Y=np.load(load_path+'Y_dslr.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bac9e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype('float32')\n",
    "X /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89586ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting\n",
      "pass\n"
     ]
    }
   ],
   "source": [
    "print('Splitting') \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = cat_len)\n",
    "X_train, X_new, y_train, y_new = train_test_split(X_train, y_train, test_size = 0.2, random_state = cat_len)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "X_new = np.array(X_new)\n",
    "y_new = np.array(y_new)\n",
    "\n",
    "print(\"pass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f26320e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f75aadef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Data Augmentation\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('Image Data Augmentation')\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "val_generator = ImageDataGenerator(rotation_range=0, zoom_range=0.2, width_shift_range=0.2,\n",
    "    height_shift_range=0.2, shear_range=0.2)\n",
    "#                                     , horizontal_flip=True, brightness_range=[0.6,1.3])\n",
    "val_generator.fit(X_train)\n",
    "val_generator.fit(X_new)\n",
    "val_generator.fit(X_test)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48682243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " depthwise_conv2d (Depthwise  (None, 128, 128, 3)      30        \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128, 128, 3)      12        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " depthwise_conv2d_1 (Depthwi  (None, 128, 128, 3)      30        \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " depthwise_conv2d_2 (Depthwi  (None, 128, 128, 3)      30        \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128, 128, 3)      12        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 64, 3)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " depthwise_conv2d_3 (Depthwi  (None, 64, 64, 3)        30        \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " depthwise_conv2d_4 (Depthwi  (None, 64, 64, 3)        30        \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64, 64, 3)        12        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " depthwise_conv2d_5 (Depthwi  (None, 64, 64, 3)        30        \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 3)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " depthwise_conv2d_6 (Depthwi  (None, 32, 32, 3)        30        \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 32, 32, 3)        12        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " depthwise_conv2d_7 (Depthwi  (None, 32, 32, 3)        30        \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " depthwise_conv2d_8 (Depthwi  (None, 32, 32, 3)        30        \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 32, 32, 3)        12        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 16, 3)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " depthwise_conv2d_9 (Depthwi  (None, 16, 16, 3)        30        \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " depthwise_conv2d_10 (Depthw  (None, 16, 16, 3)        30        \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " depthwise_conv2d_11 (Depthw  (None, 16, 16, 3)        30        \n",
      " iseConv2D)                                                      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 8, 8, 3)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 192)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2048)              395264    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 106)               108650    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,602,510\n",
      "Trainable params: 2,602,480\n",
      "Non-trainable params: 30\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    # First layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu', input_shape=(128, 128, 3)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Second layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Third layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Fourth layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Fifth layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Sixth layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Seventh layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Eighth layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Nineth layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # 10th layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # 11th layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # 12th layer: Depthwise Convolution\n",
    "    tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "   \n",
    "    # Flatten the output from convolutional layers\n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    # Add a dense layer to learn the final classification\n",
    "    tf.keras.layers.Dense(2048, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    # Output layer with softmax activation function for multi-class classification\n",
    "    tf.keras.layers.Dense(106, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a88ad52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1\n",
      "Epoch 1/1000\n",
      "487/487 [==============================] - 49s 92ms/step - loss: 4.6599 - accuracy: 0.0113 - val_loss: 4.6586 - val_accuracy: 0.0207\n",
      "Epoch 2/1000\n",
      "487/487 [==============================] - 43s 89ms/step - loss: 4.6439 - accuracy: 0.0131 - val_loss: 4.6337 - val_accuracy: 0.0501\n",
      "Epoch 3/1000\n",
      "487/487 [==============================] - 44s 90ms/step - loss: 4.6202 - accuracy: 0.0161 - val_loss: 4.6016 - val_accuracy: 0.0736\n",
      "Epoch 4/1000\n",
      "487/487 [==============================] - 44s 90ms/step - loss: 4.5879 - accuracy: 0.0196 - val_loss: 4.5538 - val_accuracy: 0.0929\n",
      "Epoch 5/1000\n",
      "487/487 [==============================] - 44s 90ms/step - loss: 4.5475 - accuracy: 0.0230 - val_loss: 4.4922 - val_accuracy: 0.1120\n",
      "Epoch 6/1000\n",
      "487/487 [==============================] - 44s 90ms/step - loss: 4.5003 - accuracy: 0.0318 - val_loss: 4.4200 - val_accuracy: 0.1343\n",
      "Epoch 7/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 4.4460 - accuracy: 0.0394 - val_loss: 4.3305 - val_accuracy: 0.1481\n",
      "Epoch 8/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 4.3839 - accuracy: 0.0486 - val_loss: 4.2227 - val_accuracy: 0.1531\n",
      "Epoch 9/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 4.3039 - accuracy: 0.0599 - val_loss: 4.0949 - val_accuracy: 0.1587\n",
      "Epoch 10/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 4.2108 - accuracy: 0.0698 - val_loss: 3.9560 - val_accuracy: 0.1646\n",
      "Epoch 11/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 4.1235 - accuracy: 0.0808 - val_loss: 3.8209 - val_accuracy: 0.1744\n",
      "Epoch 12/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 4.0337 - accuracy: 0.0928 - val_loss: 3.6933 - val_accuracy: 0.1842\n",
      "Epoch 13/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 3.9443 - accuracy: 0.1013 - val_loss: 3.5865 - val_accuracy: 0.1955\n",
      "Epoch 14/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 3.8747 - accuracy: 0.1067 - val_loss: 3.4844 - val_accuracy: 0.2060\n",
      "Epoch 15/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 3.8105 - accuracy: 0.1168 - val_loss: 3.3991 - val_accuracy: 0.2143\n",
      "Epoch 16/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 3.7466 - accuracy: 0.1203 - val_loss: 3.3263 - val_accuracy: 0.2244\n",
      "Epoch 17/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 3.6906 - accuracy: 0.1310 - val_loss: 3.2687 - val_accuracy: 0.2345\n",
      "Epoch 18/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 3.6410 - accuracy: 0.1340 - val_loss: 3.2048 - val_accuracy: 0.2420\n",
      "Epoch 19/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 3.5983 - accuracy: 0.1412 - val_loss: 3.1543 - val_accuracy: 0.2478\n",
      "Epoch 20/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 3.5547 - accuracy: 0.1432 - val_loss: 3.1101 - val_accuracy: 0.2548\n",
      "Epoch 21/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 3.4987 - accuracy: 0.1545 - val_loss: 3.0622 - val_accuracy: 0.2626\n",
      "Epoch 22/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 3.4658 - accuracy: 0.1564 - val_loss: 3.0175 - val_accuracy: 0.2696\n",
      "Epoch 23/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 3.4263 - accuracy: 0.1612 - val_loss: 2.9826 - val_accuracy: 0.2784\n",
      "Epoch 24/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 3.3912 - accuracy: 0.1679 - val_loss: 2.9463 - val_accuracy: 0.2853\n",
      "Epoch 25/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 3.3594 - accuracy: 0.1728 - val_loss: 2.9195 - val_accuracy: 0.2889\n",
      "Epoch 26/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 3.3409 - accuracy: 0.1704 - val_loss: 2.8870 - val_accuracy: 0.2941\n",
      "Epoch 27/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 3.2987 - accuracy: 0.1817 - val_loss: 2.8525 - val_accuracy: 0.3027\n",
      "Epoch 28/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 3.2670 - accuracy: 0.1859 - val_loss: 2.8208 - val_accuracy: 0.3096\n",
      "Epoch 29/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 3.2373 - accuracy: 0.1893 - val_loss: 2.7922 - val_accuracy: 0.3152\n",
      "Epoch 30/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 3.2022 - accuracy: 0.1945 - val_loss: 2.7640 - val_accuracy: 0.3234\n",
      "Epoch 31/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 3.1865 - accuracy: 0.1989 - val_loss: 2.7370 - val_accuracy: 0.3279\n",
      "Epoch 32/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 3.1587 - accuracy: 0.2041 - val_loss: 2.7153 - val_accuracy: 0.3334\n",
      "Epoch 33/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 3.1349 - accuracy: 0.2057 - val_loss: 2.6903 - val_accuracy: 0.3360\n",
      "Epoch 34/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 3.1063 - accuracy: 0.2133 - val_loss: 2.6603 - val_accuracy: 0.3430\n",
      "Epoch 35/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 3.0716 - accuracy: 0.2165 - val_loss: 2.6407 - val_accuracy: 0.3448\n",
      "Epoch 36/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 3.0448 - accuracy: 0.2231 - val_loss: 2.6086 - val_accuracy: 0.3532\n",
      "Epoch 37/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 3.0246 - accuracy: 0.2259 - val_loss: 2.5930 - val_accuracy: 0.3566\n",
      "Epoch 38/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 3.0000 - accuracy: 0.2318 - val_loss: 2.5597 - val_accuracy: 0.3630\n",
      "Epoch 39/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.9798 - accuracy: 0.2318 - val_loss: 2.5461 - val_accuracy: 0.3651\n",
      "Epoch 40/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.9539 - accuracy: 0.2386 - val_loss: 2.5207 - val_accuracy: 0.3701\n",
      "Epoch 41/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.9213 - accuracy: 0.2455 - val_loss: 2.4916 - val_accuracy: 0.3746\n",
      "Epoch 42/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.9123 - accuracy: 0.2471 - val_loss: 2.4671 - val_accuracy: 0.3847\n",
      "Epoch 43/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.8889 - accuracy: 0.2493 - val_loss: 2.4458 - val_accuracy: 0.3900\n",
      "Epoch 44/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.8666 - accuracy: 0.2552 - val_loss: 2.4310 - val_accuracy: 0.3927\n",
      "Epoch 45/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.8448 - accuracy: 0.2587 - val_loss: 2.4024 - val_accuracy: 0.3991\n",
      "Epoch 46/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.8213 - accuracy: 0.2630 - val_loss: 2.3883 - val_accuracy: 0.3997\n",
      "Epoch 47/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.8041 - accuracy: 0.2677 - val_loss: 2.3652 - val_accuracy: 0.4053\n",
      "Epoch 48/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.7653 - accuracy: 0.2765 - val_loss: 2.3338 - val_accuracy: 0.4129\n",
      "Epoch 49/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.7584 - accuracy: 0.2751 - val_loss: 2.3129 - val_accuracy: 0.4171\n",
      "Epoch 50/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.7483 - accuracy: 0.2803 - val_loss: 2.2941 - val_accuracy: 0.4212\n",
      "Epoch 51/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.7159 - accuracy: 0.2856 - val_loss: 2.2729 - val_accuracy: 0.4255\n",
      "Epoch 52/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.6998 - accuracy: 0.2864 - val_loss: 2.2541 - val_accuracy: 0.4290\n",
      "Epoch 53/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.6656 - accuracy: 0.2957 - val_loss: 2.2411 - val_accuracy: 0.4290\n",
      "Epoch 54/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.6608 - accuracy: 0.2948 - val_loss: 2.2113 - val_accuracy: 0.4350\n",
      "Epoch 55/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.6299 - accuracy: 0.3017 - val_loss: 2.1969 - val_accuracy: 0.4389\n",
      "Epoch 56/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.6128 - accuracy: 0.3035 - val_loss: 2.1678 - val_accuracy: 0.4450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.5888 - accuracy: 0.3080 - val_loss: 2.1466 - val_accuracy: 0.4500\n",
      "Epoch 58/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.5648 - accuracy: 0.3124 - val_loss: 2.1262 - val_accuracy: 0.4540\n",
      "Epoch 59/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.5643 - accuracy: 0.3180 - val_loss: 2.1116 - val_accuracy: 0.4579\n",
      "Epoch 60/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.5386 - accuracy: 0.3175 - val_loss: 2.0903 - val_accuracy: 0.4623\n",
      "Epoch 61/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.5163 - accuracy: 0.3247 - val_loss: 2.0719 - val_accuracy: 0.4657\n",
      "Epoch 62/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.4955 - accuracy: 0.3266 - val_loss: 2.0515 - val_accuracy: 0.4704\n",
      "Epoch 63/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.4818 - accuracy: 0.3309 - val_loss: 2.0350 - val_accuracy: 0.4745\n",
      "Epoch 64/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.4565 - accuracy: 0.3360 - val_loss: 2.0133 - val_accuracy: 0.4790\n",
      "Epoch 65/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.4343 - accuracy: 0.3393 - val_loss: 1.9956 - val_accuracy: 0.4827\n",
      "Epoch 66/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.4120 - accuracy: 0.3436 - val_loss: 1.9720 - val_accuracy: 0.4880\n",
      "Epoch 67/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.4120 - accuracy: 0.3459 - val_loss: 1.9543 - val_accuracy: 0.4909\n",
      "Epoch 68/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.3816 - accuracy: 0.3540 - val_loss: 1.9383 - val_accuracy: 0.4928\n",
      "Epoch 69/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.3610 - accuracy: 0.3542 - val_loss: 1.9238 - val_accuracy: 0.4961\n",
      "Epoch 70/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.3432 - accuracy: 0.3582 - val_loss: 1.9035 - val_accuracy: 0.4990\n",
      "Epoch 71/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.3276 - accuracy: 0.3637 - val_loss: 1.8837 - val_accuracy: 0.5019\n",
      "Epoch 72/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.3096 - accuracy: 0.3680 - val_loss: 1.8708 - val_accuracy: 0.5067\n",
      "Epoch 73/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.2874 - accuracy: 0.3740 - val_loss: 1.8523 - val_accuracy: 0.5106\n",
      "Epoch 74/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.2828 - accuracy: 0.3706 - val_loss: 1.8375 - val_accuracy: 0.5143\n",
      "Epoch 75/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.2582 - accuracy: 0.3766 - val_loss: 1.8173 - val_accuracy: 0.5182\n",
      "Epoch 76/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.2425 - accuracy: 0.3809 - val_loss: 1.7994 - val_accuracy: 0.5203\n",
      "Epoch 77/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.2219 - accuracy: 0.3847 - val_loss: 1.7874 - val_accuracy: 0.5240\n",
      "Epoch 78/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.2206 - accuracy: 0.3810 - val_loss: 1.7717 - val_accuracy: 0.5275\n",
      "Epoch 79/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.1992 - accuracy: 0.3898 - val_loss: 1.7567 - val_accuracy: 0.5304\n",
      "Epoch 80/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.1847 - accuracy: 0.3956 - val_loss: 1.7416 - val_accuracy: 0.5338\n",
      "Epoch 81/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.1590 - accuracy: 0.4013 - val_loss: 1.7264 - val_accuracy: 0.5375\n",
      "Epoch 82/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.1412 - accuracy: 0.4050 - val_loss: 1.7099 - val_accuracy: 0.5398\n",
      "Epoch 83/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.1332 - accuracy: 0.4059 - val_loss: 1.6945 - val_accuracy: 0.5444\n",
      "Epoch 84/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.1214 - accuracy: 0.4078 - val_loss: 1.6796 - val_accuracy: 0.5474\n",
      "Epoch 85/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.1054 - accuracy: 0.4087 - val_loss: 1.6650 - val_accuracy: 0.5504\n",
      "Epoch 86/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.1049 - accuracy: 0.4112 - val_loss: 1.6544 - val_accuracy: 0.5550\n",
      "Epoch 87/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.0795 - accuracy: 0.4191 - val_loss: 1.6401 - val_accuracy: 0.5577\n",
      "Epoch 88/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.0586 - accuracy: 0.4210 - val_loss: 1.6241 - val_accuracy: 0.5615\n",
      "Epoch 89/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.0388 - accuracy: 0.4241 - val_loss: 1.6111 - val_accuracy: 0.5641\n",
      "Epoch 90/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.0225 - accuracy: 0.4271 - val_loss: 1.5935 - val_accuracy: 0.5674\n",
      "Epoch 91/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.0123 - accuracy: 0.4330 - val_loss: 1.5810 - val_accuracy: 0.5700\n",
      "Epoch 92/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 2.0043 - accuracy: 0.4348 - val_loss: 1.5682 - val_accuracy: 0.5740\n",
      "Epoch 93/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.9933 - accuracy: 0.4378 - val_loss: 1.5576 - val_accuracy: 0.5776\n",
      "Epoch 94/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.9771 - accuracy: 0.4371 - val_loss: 1.5435 - val_accuracy: 0.5798\n",
      "Epoch 95/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.9557 - accuracy: 0.4450 - val_loss: 1.5300 - val_accuracy: 0.5817\n",
      "Epoch 96/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.9407 - accuracy: 0.4468 - val_loss: 1.5169 - val_accuracy: 0.5860\n",
      "Epoch 97/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.9281 - accuracy: 0.4493 - val_loss: 1.5038 - val_accuracy: 0.5889\n",
      "Epoch 98/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.9139 - accuracy: 0.4532 - val_loss: 1.4923 - val_accuracy: 0.5923\n",
      "Epoch 99/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.9209 - accuracy: 0.4544 - val_loss: 1.4840 - val_accuracy: 0.5951\n",
      "Epoch 100/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.8983 - accuracy: 0.4569 - val_loss: 1.4723 - val_accuracy: 0.5980\n",
      "Epoch 101/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.8791 - accuracy: 0.4613 - val_loss: 1.4597 - val_accuracy: 0.6003\n",
      "Epoch 102/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.8587 - accuracy: 0.4709 - val_loss: 1.4447 - val_accuracy: 0.6047\n",
      "Epoch 103/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.8641 - accuracy: 0.4626 - val_loss: 1.4355 - val_accuracy: 0.6073\n",
      "Epoch 104/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.8492 - accuracy: 0.4692 - val_loss: 1.4264 - val_accuracy: 0.6105\n",
      "Epoch 105/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.8324 - accuracy: 0.4736 - val_loss: 1.4118 - val_accuracy: 0.6128\n",
      "Epoch 106/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.8239 - accuracy: 0.4762 - val_loss: 1.4027 - val_accuracy: 0.6151\n",
      "Epoch 107/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.8215 - accuracy: 0.4757 - val_loss: 1.3915 - val_accuracy: 0.6180\n",
      "Epoch 108/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.8003 - accuracy: 0.4788 - val_loss: 1.3820 - val_accuracy: 0.6216\n",
      "Epoch 109/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.7953 - accuracy: 0.4818 - val_loss: 1.3724 - val_accuracy: 0.6232\n",
      "Epoch 110/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.7790 - accuracy: 0.4842 - val_loss: 1.3601 - val_accuracy: 0.6251\n",
      "Epoch 111/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.7550 - accuracy: 0.4886 - val_loss: 1.3490 - val_accuracy: 0.6260\n",
      "Epoch 112/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 44s 91ms/step - loss: 1.7578 - accuracy: 0.4926 - val_loss: 1.3403 - val_accuracy: 0.6305\n",
      "Epoch 113/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.7504 - accuracy: 0.4923 - val_loss: 1.3311 - val_accuracy: 0.6323\n",
      "Epoch 114/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.7352 - accuracy: 0.4976 - val_loss: 1.3215 - val_accuracy: 0.6348\n",
      "Epoch 115/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.7216 - accuracy: 0.5003 - val_loss: 1.3096 - val_accuracy: 0.6374\n",
      "Epoch 116/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.7148 - accuracy: 0.5018 - val_loss: 1.3013 - val_accuracy: 0.6402\n",
      "Epoch 117/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.7079 - accuracy: 0.4969 - val_loss: 1.2914 - val_accuracy: 0.6421\n",
      "Epoch 118/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.6992 - accuracy: 0.5047 - val_loss: 1.2831 - val_accuracy: 0.6450\n",
      "Epoch 119/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.6846 - accuracy: 0.5081 - val_loss: 1.2724 - val_accuracy: 0.6473\n",
      "Epoch 120/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.6805 - accuracy: 0.5104 - val_loss: 1.2631 - val_accuracy: 0.6498\n",
      "Epoch 121/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.6728 - accuracy: 0.5121 - val_loss: 1.2557 - val_accuracy: 0.6525\n",
      "Epoch 122/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.6536 - accuracy: 0.5186 - val_loss: 1.2460 - val_accuracy: 0.6534\n",
      "Epoch 123/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.6438 - accuracy: 0.5197 - val_loss: 1.2357 - val_accuracy: 0.6578\n",
      "Epoch 124/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.6306 - accuracy: 0.5229 - val_loss: 1.2276 - val_accuracy: 0.6588\n",
      "Epoch 125/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 1.6285 - accuracy: 0.5240 - val_loss: 1.2184 - val_accuracy: 0.6602\n",
      "Epoch 126/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.6200 - accuracy: 0.5230 - val_loss: 1.2105 - val_accuracy: 0.6616\n",
      "Epoch 127/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.6177 - accuracy: 0.5254 - val_loss: 1.2045 - val_accuracy: 0.6639\n",
      "Epoch 128/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.6091 - accuracy: 0.5283 - val_loss: 1.1967 - val_accuracy: 0.6655\n",
      "Epoch 129/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.5936 - accuracy: 0.5321 - val_loss: 1.1881 - val_accuracy: 0.6674\n",
      "Epoch 130/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.5925 - accuracy: 0.5321 - val_loss: 1.1794 - val_accuracy: 0.6711\n",
      "Epoch 131/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.5801 - accuracy: 0.5358 - val_loss: 1.1719 - val_accuracy: 0.6726\n",
      "Epoch 132/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.5761 - accuracy: 0.5369 - val_loss: 1.1667 - val_accuracy: 0.6750\n",
      "Epoch 133/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.5560 - accuracy: 0.5388 - val_loss: 1.1564 - val_accuracy: 0.6774\n",
      "Epoch 134/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.5476 - accuracy: 0.5364 - val_loss: 1.1455 - val_accuracy: 0.6789\n",
      "Epoch 135/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.5455 - accuracy: 0.5443 - val_loss: 1.1381 - val_accuracy: 0.6816\n",
      "Epoch 136/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.5241 - accuracy: 0.5515 - val_loss: 1.1292 - val_accuracy: 0.6837\n",
      "Epoch 137/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.5243 - accuracy: 0.5486 - val_loss: 1.1196 - val_accuracy: 0.6858\n",
      "Epoch 138/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.5140 - accuracy: 0.5513 - val_loss: 1.1146 - val_accuracy: 0.6886\n",
      "Epoch 139/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.5120 - accuracy: 0.5495 - val_loss: 1.1085 - val_accuracy: 0.6899\n",
      "Epoch 140/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 1.4944 - accuracy: 0.5547 - val_loss: 1.1002 - val_accuracy: 0.6920\n",
      "Epoch 141/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 1.4929 - accuracy: 0.5545 - val_loss: 1.0949 - val_accuracy: 0.6932\n",
      "Epoch 142/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 1.4810 - accuracy: 0.5604 - val_loss: 1.0849 - val_accuracy: 0.6953\n",
      "Epoch 143/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 1.4846 - accuracy: 0.5595 - val_loss: 1.0780 - val_accuracy: 0.6993\n",
      "Epoch 144/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 1.4727 - accuracy: 0.5630 - val_loss: 1.0707 - val_accuracy: 0.7019\n",
      "Epoch 145/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.4542 - accuracy: 0.5663 - val_loss: 1.0627 - val_accuracy: 0.7025\n",
      "Epoch 146/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.4541 - accuracy: 0.5639 - val_loss: 1.0587 - val_accuracy: 0.7035\n",
      "Epoch 147/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 1.4392 - accuracy: 0.5726 - val_loss: 1.0475 - val_accuracy: 0.7079\n",
      "Epoch 148/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.4451 - accuracy: 0.5682 - val_loss: 1.0423 - val_accuracy: 0.7107\n",
      "Epoch 149/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 1.4207 - accuracy: 0.5754 - val_loss: 1.0342 - val_accuracy: 0.7126\n",
      "Epoch 150/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.4187 - accuracy: 0.5782 - val_loss: 1.0279 - val_accuracy: 0.7137\n",
      "Epoch 151/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 1.4257 - accuracy: 0.5761 - val_loss: 1.0231 - val_accuracy: 0.7160\n",
      "Epoch 152/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 1.4110 - accuracy: 0.5749 - val_loss: 1.0171 - val_accuracy: 0.7177\n",
      "Epoch 153/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 1.3974 - accuracy: 0.5798 - val_loss: 1.0090 - val_accuracy: 0.7190\n",
      "Epoch 154/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.3902 - accuracy: 0.5816 - val_loss: 1.0005 - val_accuracy: 0.7230\n",
      "Epoch 155/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.3849 - accuracy: 0.5821 - val_loss: 0.9939 - val_accuracy: 0.7223\n",
      "Epoch 156/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 1.3710 - accuracy: 0.5874 - val_loss: 0.9867 - val_accuracy: 0.7240\n",
      "Epoch 157/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 1.3673 - accuracy: 0.5902 - val_loss: 0.9794 - val_accuracy: 0.7266\n",
      "Epoch 158/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.3625 - accuracy: 0.5944 - val_loss: 0.9760 - val_accuracy: 0.7290\n",
      "Epoch 159/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.3483 - accuracy: 0.5948 - val_loss: 0.9673 - val_accuracy: 0.7314\n",
      "Epoch 160/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.3507 - accuracy: 0.5941 - val_loss: 0.9644 - val_accuracy: 0.7322\n",
      "Epoch 161/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.3486 - accuracy: 0.5942 - val_loss: 0.9569 - val_accuracy: 0.7331\n",
      "Epoch 162/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.3378 - accuracy: 0.5937 - val_loss: 0.9513 - val_accuracy: 0.7360\n",
      "Epoch 163/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 1.3281 - accuracy: 0.5987 - val_loss: 0.9460 - val_accuracy: 0.7373\n",
      "Epoch 164/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.3272 - accuracy: 0.5952 - val_loss: 0.9362 - val_accuracy: 0.7411\n",
      "Epoch 165/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.3061 - accuracy: 0.6072 - val_loss: 0.9315 - val_accuracy: 0.7419\n",
      "Epoch 166/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.3099 - accuracy: 0.6031 - val_loss: 0.9261 - val_accuracy: 0.7433\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 45s 92ms/step - loss: 1.3091 - accuracy: 0.6034 - val_loss: 0.9202 - val_accuracy: 0.7448\n",
      "Epoch 168/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.2966 - accuracy: 0.6091 - val_loss: 0.9142 - val_accuracy: 0.7469\n",
      "Epoch 169/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.2956 - accuracy: 0.6061 - val_loss: 0.9105 - val_accuracy: 0.7479\n",
      "Epoch 170/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.2894 - accuracy: 0.6061 - val_loss: 0.9040 - val_accuracy: 0.7508\n",
      "Epoch 171/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.2797 - accuracy: 0.6110 - val_loss: 0.8954 - val_accuracy: 0.7520\n",
      "Epoch 172/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.2788 - accuracy: 0.6122 - val_loss: 0.8914 - val_accuracy: 0.7525\n",
      "Epoch 173/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.2641 - accuracy: 0.6186 - val_loss: 0.8819 - val_accuracy: 0.7553\n",
      "Epoch 174/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.2592 - accuracy: 0.6191 - val_loss: 0.8805 - val_accuracy: 0.7555\n",
      "Epoch 175/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.2607 - accuracy: 0.6196 - val_loss: 0.8739 - val_accuracy: 0.7572\n",
      "Epoch 176/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.2465 - accuracy: 0.6214 - val_loss: 0.8672 - val_accuracy: 0.7611\n",
      "Epoch 177/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.2429 - accuracy: 0.6236 - val_loss: 0.8619 - val_accuracy: 0.7607\n",
      "Epoch 178/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.2391 - accuracy: 0.6220 - val_loss: 0.8580 - val_accuracy: 0.7618\n",
      "Epoch 179/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.2340 - accuracy: 0.6250 - val_loss: 0.8517 - val_accuracy: 0.7640\n",
      "Epoch 180/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.2235 - accuracy: 0.6283 - val_loss: 0.8470 - val_accuracy: 0.7648\n",
      "Epoch 181/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.2038 - accuracy: 0.6338 - val_loss: 0.8379 - val_accuracy: 0.7672\n",
      "Epoch 182/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.2085 - accuracy: 0.6349 - val_loss: 0.8341 - val_accuracy: 0.7672\n",
      "Epoch 183/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.2056 - accuracy: 0.6334 - val_loss: 0.8277 - val_accuracy: 0.7706\n",
      "Epoch 184/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.2027 - accuracy: 0.6364 - val_loss: 0.8236 - val_accuracy: 0.7712\n",
      "Epoch 185/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.1976 - accuracy: 0.6312 - val_loss: 0.8190 - val_accuracy: 0.7718\n",
      "Epoch 186/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.1852 - accuracy: 0.6391 - val_loss: 0.8139 - val_accuracy: 0.7736\n",
      "Epoch 187/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.1796 - accuracy: 0.6416 - val_loss: 0.8107 - val_accuracy: 0.7745\n",
      "Epoch 188/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.1830 - accuracy: 0.6386 - val_loss: 0.8044 - val_accuracy: 0.7767\n",
      "Epoch 189/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.1774 - accuracy: 0.6419 - val_loss: 0.7983 - val_accuracy: 0.7783\n",
      "Epoch 190/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.1692 - accuracy: 0.6423 - val_loss: 0.7956 - val_accuracy: 0.7794\n",
      "Epoch 191/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.1637 - accuracy: 0.6404 - val_loss: 0.7906 - val_accuracy: 0.7796\n",
      "Epoch 192/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.1524 - accuracy: 0.6444 - val_loss: 0.7870 - val_accuracy: 0.7802\n",
      "Epoch 193/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.1455 - accuracy: 0.6501 - val_loss: 0.7801 - val_accuracy: 0.7830\n",
      "Epoch 194/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.1495 - accuracy: 0.6479 - val_loss: 0.7757 - val_accuracy: 0.7838\n",
      "Epoch 195/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 1.1400 - accuracy: 0.6525 - val_loss: 0.7695 - val_accuracy: 0.7841\n",
      "Epoch 196/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 1.1266 - accuracy: 0.6552 - val_loss: 0.7629 - val_accuracy: 0.7866\n",
      "Epoch 197/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.1294 - accuracy: 0.6516 - val_loss: 0.7608 - val_accuracy: 0.7881\n",
      "Epoch 198/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 1.1297 - accuracy: 0.6538 - val_loss: 0.7583 - val_accuracy: 0.7883\n",
      "Epoch 199/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.1176 - accuracy: 0.6585 - val_loss: 0.7531 - val_accuracy: 0.7906\n",
      "Epoch 200/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.0997 - accuracy: 0.6627 - val_loss: 0.7455 - val_accuracy: 0.7914\n",
      "Epoch 201/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.1047 - accuracy: 0.6613 - val_loss: 0.7435 - val_accuracy: 0.7921\n",
      "Epoch 202/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.0983 - accuracy: 0.6633 - val_loss: 0.7389 - val_accuracy: 0.7947\n",
      "Epoch 203/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.0928 - accuracy: 0.6639 - val_loss: 0.7308 - val_accuracy: 0.7956\n",
      "Epoch 204/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.0922 - accuracy: 0.6642 - val_loss: 0.7293 - val_accuracy: 0.7958\n",
      "Epoch 205/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.0883 - accuracy: 0.6648 - val_loss: 0.7225 - val_accuracy: 0.7966\n",
      "Epoch 206/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 1.0836 - accuracy: 0.6674 - val_loss: 0.7187 - val_accuracy: 0.7979\n",
      "Epoch 207/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.0760 - accuracy: 0.6702 - val_loss: 0.7146 - val_accuracy: 0.8009\n",
      "Epoch 208/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.0711 - accuracy: 0.6681 - val_loss: 0.7111 - val_accuracy: 0.8025\n",
      "Epoch 209/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.0578 - accuracy: 0.6711 - val_loss: 0.7050 - val_accuracy: 0.8026\n",
      "Epoch 210/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.0603 - accuracy: 0.6732 - val_loss: 0.7010 - val_accuracy: 0.8038\n",
      "Epoch 211/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.0599 - accuracy: 0.6715 - val_loss: 0.6987 - val_accuracy: 0.8042\n",
      "Epoch 212/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.0468 - accuracy: 0.6766 - val_loss: 0.6938 - val_accuracy: 0.8067\n",
      "Epoch 213/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.0460 - accuracy: 0.6796 - val_loss: 0.6871 - val_accuracy: 0.8090\n",
      "Epoch 214/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.0475 - accuracy: 0.6760 - val_loss: 0.6864 - val_accuracy: 0.8078\n",
      "Epoch 215/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.0330 - accuracy: 0.6801 - val_loss: 0.6800 - val_accuracy: 0.8093\n",
      "Epoch 216/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.0389 - accuracy: 0.6798 - val_loss: 0.6766 - val_accuracy: 0.8110\n",
      "Epoch 217/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.0246 - accuracy: 0.6841 - val_loss: 0.6725 - val_accuracy: 0.8129\n",
      "Epoch 218/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.0216 - accuracy: 0.6856 - val_loss: 0.6683 - val_accuracy: 0.8130\n",
      "Epoch 219/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 1.0165 - accuracy: 0.6861 - val_loss: 0.6652 - val_accuracy: 0.8146\n",
      "Epoch 220/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.0218 - accuracy: 0.6861 - val_loss: 0.6618 - val_accuracy: 0.8144\n",
      "Epoch 221/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.0126 - accuracy: 0.6880 - val_loss: 0.6602 - val_accuracy: 0.8160\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 45s 92ms/step - loss: 0.9983 - accuracy: 0.6898 - val_loss: 0.6530 - val_accuracy: 0.8158\n",
      "Epoch 223/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 1.0039 - accuracy: 0.6906 - val_loss: 0.6486 - val_accuracy: 0.8177\n",
      "Epoch 224/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.9916 - accuracy: 0.6899 - val_loss: 0.6447 - val_accuracy: 0.8202\n",
      "Epoch 225/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.9965 - accuracy: 0.6909 - val_loss: 0.6432 - val_accuracy: 0.8216\n",
      "Epoch 226/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.9896 - accuracy: 0.6950 - val_loss: 0.6379 - val_accuracy: 0.8220\n",
      "Epoch 227/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.9922 - accuracy: 0.6905 - val_loss: 0.6348 - val_accuracy: 0.8228\n",
      "Epoch 228/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.9758 - accuracy: 0.7021 - val_loss: 0.6295 - val_accuracy: 0.8239\n",
      "Epoch 229/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.9839 - accuracy: 0.6942 - val_loss: 0.6272 - val_accuracy: 0.8247\n",
      "Epoch 230/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.9788 - accuracy: 0.6937 - val_loss: 0.6251 - val_accuracy: 0.8253\n",
      "Epoch 231/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.9612 - accuracy: 0.7013 - val_loss: 0.6205 - val_accuracy: 0.8269\n",
      "Epoch 232/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.9671 - accuracy: 0.6997 - val_loss: 0.6161 - val_accuracy: 0.8295\n",
      "Epoch 233/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.9539 - accuracy: 0.7033 - val_loss: 0.6141 - val_accuracy: 0.8292\n",
      "Epoch 234/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.9546 - accuracy: 0.7019 - val_loss: 0.6092 - val_accuracy: 0.8319\n",
      "Epoch 235/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.9428 - accuracy: 0.7052 - val_loss: 0.6050 - val_accuracy: 0.8332\n",
      "Epoch 236/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.9465 - accuracy: 0.7066 - val_loss: 0.6019 - val_accuracy: 0.8332\n",
      "Epoch 237/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.9410 - accuracy: 0.7050 - val_loss: 0.5984 - val_accuracy: 0.8345\n",
      "Epoch 238/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.9415 - accuracy: 0.7078 - val_loss: 0.5944 - val_accuracy: 0.8353\n",
      "Epoch 239/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.9473 - accuracy: 0.7082 - val_loss: 0.5932 - val_accuracy: 0.8361\n",
      "Epoch 240/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.9337 - accuracy: 0.7062 - val_loss: 0.5893 - val_accuracy: 0.8358\n",
      "Epoch 241/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.9250 - accuracy: 0.7126 - val_loss: 0.5874 - val_accuracy: 0.8351\n",
      "Epoch 242/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.9185 - accuracy: 0.7122 - val_loss: 0.5822 - val_accuracy: 0.8377\n",
      "Epoch 243/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.9144 - accuracy: 0.7164 - val_loss: 0.5784 - val_accuracy: 0.8390\n",
      "Epoch 244/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.9217 - accuracy: 0.7102 - val_loss: 0.5761 - val_accuracy: 0.8407\n",
      "Epoch 245/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.9147 - accuracy: 0.7142 - val_loss: 0.5733 - val_accuracy: 0.8402\n",
      "Epoch 246/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.9095 - accuracy: 0.7184 - val_loss: 0.5690 - val_accuracy: 0.8420\n",
      "Epoch 247/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.9065 - accuracy: 0.7167 - val_loss: 0.5687 - val_accuracy: 0.8420\n",
      "Epoch 248/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.9036 - accuracy: 0.7153 - val_loss: 0.5636 - val_accuracy: 0.8447\n",
      "Epoch 249/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.8928 - accuracy: 0.7178 - val_loss: 0.5590 - val_accuracy: 0.8456\n",
      "Epoch 250/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.8961 - accuracy: 0.7173 - val_loss: 0.5584 - val_accuracy: 0.8443\n",
      "Epoch 251/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.8912 - accuracy: 0.7179 - val_loss: 0.5562 - val_accuracy: 0.8461\n",
      "Epoch 252/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.8943 - accuracy: 0.7209 - val_loss: 0.5506 - val_accuracy: 0.8475\n",
      "Epoch 253/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.8741 - accuracy: 0.7248 - val_loss: 0.5471 - val_accuracy: 0.8470\n",
      "Epoch 254/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.8774 - accuracy: 0.7205 - val_loss: 0.5483 - val_accuracy: 0.8467\n",
      "Epoch 255/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.8794 - accuracy: 0.7264 - val_loss: 0.5441 - val_accuracy: 0.8489\n",
      "Epoch 256/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.8633 - accuracy: 0.7287 - val_loss: 0.5390 - val_accuracy: 0.8507\n",
      "Epoch 257/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.8744 - accuracy: 0.7290 - val_loss: 0.5358 - val_accuracy: 0.8522\n",
      "Epoch 258/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.8625 - accuracy: 0.7311 - val_loss: 0.5324 - val_accuracy: 0.8523\n",
      "Epoch 259/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.8656 - accuracy: 0.7274 - val_loss: 0.5323 - val_accuracy: 0.8534\n",
      "Epoch 260/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.8494 - accuracy: 0.7344 - val_loss: 0.5265 - val_accuracy: 0.8556\n",
      "Epoch 261/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.8534 - accuracy: 0.7319 - val_loss: 0.5255 - val_accuracy: 0.8564\n",
      "Epoch 262/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.8478 - accuracy: 0.7360 - val_loss: 0.5213 - val_accuracy: 0.8564\n",
      "Epoch 263/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.8569 - accuracy: 0.7308 - val_loss: 0.5201 - val_accuracy: 0.8569\n",
      "Epoch 264/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.8430 - accuracy: 0.7343 - val_loss: 0.5160 - val_accuracy: 0.8563\n",
      "Epoch 265/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.8325 - accuracy: 0.7347 - val_loss: 0.5130 - val_accuracy: 0.8577\n",
      "Epoch 266/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.8353 - accuracy: 0.7344 - val_loss: 0.5102 - val_accuracy: 0.8592\n",
      "Epoch 267/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.8344 - accuracy: 0.7353 - val_loss: 0.5082 - val_accuracy: 0.8593\n",
      "Epoch 268/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.8321 - accuracy: 0.7369 - val_loss: 0.5043 - val_accuracy: 0.8605\n",
      "Epoch 269/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.8356 - accuracy: 0.7392 - val_loss: 0.5040 - val_accuracy: 0.8613\n",
      "Epoch 270/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.8268 - accuracy: 0.7393 - val_loss: 0.5010 - val_accuracy: 0.8611\n",
      "Epoch 271/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.8283 - accuracy: 0.7393 - val_loss: 0.4987 - val_accuracy: 0.8624\n",
      "Epoch 272/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.8087 - accuracy: 0.7446 - val_loss: 0.4932 - val_accuracy: 0.8627\n",
      "Epoch 273/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.8103 - accuracy: 0.7415 - val_loss: 0.4917 - val_accuracy: 0.8642\n",
      "Epoch 274/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.8233 - accuracy: 0.7401 - val_loss: 0.4878 - val_accuracy: 0.8658\n",
      "Epoch 275/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.8157 - accuracy: 0.7413 - val_loss: 0.4877 - val_accuracy: 0.8654\n",
      "Epoch 276/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.8104 - accuracy: 0.7459 - val_loss: 0.4868 - val_accuracy: 0.8655\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 45s 92ms/step - loss: 0.7963 - accuracy: 0.7471 - val_loss: 0.4817 - val_accuracy: 0.8663\n",
      "Epoch 278/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.8078 - accuracy: 0.7456 - val_loss: 0.4813 - val_accuracy: 0.8675\n",
      "Epoch 279/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.7967 - accuracy: 0.7490 - val_loss: 0.4798 - val_accuracy: 0.8675\n",
      "Epoch 280/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.7905 - accuracy: 0.7491 - val_loss: 0.4757 - val_accuracy: 0.8677\n",
      "Epoch 281/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.7968 - accuracy: 0.7497 - val_loss: 0.4738 - val_accuracy: 0.8683\n",
      "Epoch 282/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.7860 - accuracy: 0.7496 - val_loss: 0.4698 - val_accuracy: 0.8693\n",
      "Epoch 283/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.7937 - accuracy: 0.7485 - val_loss: 0.4688 - val_accuracy: 0.8698\n",
      "Epoch 284/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.7851 - accuracy: 0.7534 - val_loss: 0.4680 - val_accuracy: 0.8711\n",
      "Epoch 285/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.7712 - accuracy: 0.7573 - val_loss: 0.4616 - val_accuracy: 0.8720\n",
      "Epoch 286/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.7835 - accuracy: 0.7515 - val_loss: 0.4617 - val_accuracy: 0.8713\n",
      "Epoch 287/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.7750 - accuracy: 0.7551 - val_loss: 0.4587 - val_accuracy: 0.8730\n",
      "Epoch 288/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.7768 - accuracy: 0.7536 - val_loss: 0.4572 - val_accuracy: 0.8741\n",
      "Epoch 289/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.7675 - accuracy: 0.7588 - val_loss: 0.4526 - val_accuracy: 0.8746\n",
      "Epoch 290/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.7573 - accuracy: 0.7603 - val_loss: 0.4515 - val_accuracy: 0.8755\n",
      "Epoch 291/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.7635 - accuracy: 0.7593 - val_loss: 0.4507 - val_accuracy: 0.8749\n",
      "Epoch 292/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.7620 - accuracy: 0.7603 - val_loss: 0.4483 - val_accuracy: 0.8762\n",
      "Epoch 293/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.7584 - accuracy: 0.7597 - val_loss: 0.4467 - val_accuracy: 0.8772\n",
      "Epoch 294/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.7443 - accuracy: 0.7611 - val_loss: 0.4424 - val_accuracy: 0.8772\n",
      "Epoch 295/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.7510 - accuracy: 0.7623 - val_loss: 0.4408 - val_accuracy: 0.8780\n",
      "Epoch 296/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.7586 - accuracy: 0.7613 - val_loss: 0.4393 - val_accuracy: 0.8786\n",
      "Epoch 297/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.7510 - accuracy: 0.7623 - val_loss: 0.4385 - val_accuracy: 0.8784\n",
      "Epoch 298/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.7446 - accuracy: 0.7629 - val_loss: 0.4358 - val_accuracy: 0.8793\n",
      "Epoch 299/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.7370 - accuracy: 0.7676 - val_loss: 0.4336 - val_accuracy: 0.8799\n",
      "Epoch 300/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.7379 - accuracy: 0.7679 - val_loss: 0.4314 - val_accuracy: 0.8795\n",
      "Epoch 301/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.7297 - accuracy: 0.7680 - val_loss: 0.4293 - val_accuracy: 0.8808\n",
      "Epoch 302/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.7404 - accuracy: 0.7639 - val_loss: 0.4264 - val_accuracy: 0.8818\n",
      "Epoch 303/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.7194 - accuracy: 0.7729 - val_loss: 0.4232 - val_accuracy: 0.8830\n",
      "Epoch 304/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.7256 - accuracy: 0.7715 - val_loss: 0.4219 - val_accuracy: 0.8833\n",
      "Epoch 305/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.7197 - accuracy: 0.7731 - val_loss: 0.4184 - val_accuracy: 0.8838\n",
      "Epoch 306/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.7204 - accuracy: 0.7699 - val_loss: 0.4190 - val_accuracy: 0.8838\n",
      "Epoch 307/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.7158 - accuracy: 0.7743 - val_loss: 0.4166 - val_accuracy: 0.8830\n",
      "Epoch 308/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.7163 - accuracy: 0.7708 - val_loss: 0.4134 - val_accuracy: 0.8846\n",
      "Epoch 309/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.7114 - accuracy: 0.7734 - val_loss: 0.4141 - val_accuracy: 0.8848\n",
      "Epoch 310/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.7040 - accuracy: 0.7738 - val_loss: 0.4122 - val_accuracy: 0.8844\n",
      "Epoch 311/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.7155 - accuracy: 0.7713 - val_loss: 0.4085 - val_accuracy: 0.8864\n",
      "Epoch 312/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.7082 - accuracy: 0.7753 - val_loss: 0.4073 - val_accuracy: 0.8861\n",
      "Epoch 313/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.7024 - accuracy: 0.7788 - val_loss: 0.4055 - val_accuracy: 0.8877\n",
      "Epoch 314/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6965 - accuracy: 0.7780 - val_loss: 0.4033 - val_accuracy: 0.8880\n",
      "Epoch 315/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.7051 - accuracy: 0.7773 - val_loss: 0.4008 - val_accuracy: 0.8885\n",
      "Epoch 316/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.7064 - accuracy: 0.7780 - val_loss: 0.4000 - val_accuracy: 0.8897\n",
      "Epoch 317/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.7014 - accuracy: 0.7737 - val_loss: 0.3965 - val_accuracy: 0.8887\n",
      "Epoch 318/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6880 - accuracy: 0.7836 - val_loss: 0.3930 - val_accuracy: 0.8908\n",
      "Epoch 319/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6930 - accuracy: 0.7823 - val_loss: 0.3937 - val_accuracy: 0.8910\n",
      "Epoch 320/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6870 - accuracy: 0.7824 - val_loss: 0.3907 - val_accuracy: 0.8913\n",
      "Epoch 321/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.6926 - accuracy: 0.7810 - val_loss: 0.3896 - val_accuracy: 0.8910\n",
      "Epoch 322/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6889 - accuracy: 0.7817 - val_loss: 0.3881 - val_accuracy: 0.8920\n",
      "Epoch 323/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.6831 - accuracy: 0.7828 - val_loss: 0.3862 - val_accuracy: 0.8915\n",
      "Epoch 324/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6847 - accuracy: 0.7824 - val_loss: 0.3840 - val_accuracy: 0.8925\n",
      "Epoch 325/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6746 - accuracy: 0.7816 - val_loss: 0.3815 - val_accuracy: 0.8932\n",
      "Epoch 326/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6694 - accuracy: 0.7874 - val_loss: 0.3811 - val_accuracy: 0.8926\n",
      "Epoch 327/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6726 - accuracy: 0.7864 - val_loss: 0.3819 - val_accuracy: 0.8943\n",
      "Epoch 328/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6802 - accuracy: 0.7832 - val_loss: 0.3769 - val_accuracy: 0.8947\n",
      "Epoch 329/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6685 - accuracy: 0.7861 - val_loss: 0.3751 - val_accuracy: 0.8951\n",
      "Epoch 330/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6698 - accuracy: 0.7858 - val_loss: 0.3751 - val_accuracy: 0.8952\n",
      "Epoch 331/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6727 - accuracy: 0.7854 - val_loss: 0.3732 - val_accuracy: 0.8972\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6536 - accuracy: 0.7910 - val_loss: 0.3704 - val_accuracy: 0.8976\n",
      "Epoch 333/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6634 - accuracy: 0.7869 - val_loss: 0.3684 - val_accuracy: 0.8976\n",
      "Epoch 334/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6594 - accuracy: 0.7890 - val_loss: 0.3674 - val_accuracy: 0.8976\n",
      "Epoch 335/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6610 - accuracy: 0.7903 - val_loss: 0.3664 - val_accuracy: 0.8981\n",
      "Epoch 336/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6462 - accuracy: 0.7916 - val_loss: 0.3637 - val_accuracy: 0.8977\n",
      "Epoch 337/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6486 - accuracy: 0.7931 - val_loss: 0.3606 - val_accuracy: 0.8984\n",
      "Epoch 338/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6463 - accuracy: 0.7948 - val_loss: 0.3619 - val_accuracy: 0.8987\n",
      "Epoch 339/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6503 - accuracy: 0.7939 - val_loss: 0.3603 - val_accuracy: 0.8990\n",
      "Epoch 340/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6480 - accuracy: 0.7939 - val_loss: 0.3593 - val_accuracy: 0.8997\n",
      "Epoch 341/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.6454 - accuracy: 0.7943 - val_loss: 0.3566 - val_accuracy: 0.9010\n",
      "Epoch 342/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.6377 - accuracy: 0.7976 - val_loss: 0.3560 - val_accuracy: 0.9011\n",
      "Epoch 343/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6403 - accuracy: 0.7956 - val_loss: 0.3528 - val_accuracy: 0.9022\n",
      "Epoch 344/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6333 - accuracy: 0.7967 - val_loss: 0.3513 - val_accuracy: 0.9025\n",
      "Epoch 345/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6361 - accuracy: 0.8006 - val_loss: 0.3506 - val_accuracy: 0.9032\n",
      "Epoch 346/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6276 - accuracy: 0.7976 - val_loss: 0.3494 - val_accuracy: 0.9016\n",
      "Epoch 347/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6256 - accuracy: 0.7989 - val_loss: 0.3465 - val_accuracy: 0.9037\n",
      "Epoch 348/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6310 - accuracy: 0.7980 - val_loss: 0.3472 - val_accuracy: 0.9038\n",
      "Epoch 349/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6334 - accuracy: 0.8003 - val_loss: 0.3438 - val_accuracy: 0.9046\n",
      "Epoch 350/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.6243 - accuracy: 0.8026 - val_loss: 0.3433 - val_accuracy: 0.9058\n",
      "Epoch 351/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6272 - accuracy: 0.7994 - val_loss: 0.3413 - val_accuracy: 0.9058\n",
      "Epoch 352/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6205 - accuracy: 0.8003 - val_loss: 0.3410 - val_accuracy: 0.9057\n",
      "Epoch 353/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6208 - accuracy: 0.8010 - val_loss: 0.3384 - val_accuracy: 0.9060\n",
      "Epoch 354/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6213 - accuracy: 0.8001 - val_loss: 0.3366 - val_accuracy: 0.9067\n",
      "Epoch 355/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6228 - accuracy: 0.7993 - val_loss: 0.3365 - val_accuracy: 0.9068\n",
      "Epoch 356/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6175 - accuracy: 0.8011 - val_loss: 0.3345 - val_accuracy: 0.9079\n",
      "Epoch 357/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6079 - accuracy: 0.8057 - val_loss: 0.3328 - val_accuracy: 0.9081\n",
      "Epoch 358/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.6040 - accuracy: 0.8054 - val_loss: 0.3319 - val_accuracy: 0.9068\n",
      "Epoch 359/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6049 - accuracy: 0.8069 - val_loss: 0.3305 - val_accuracy: 0.9074\n",
      "Epoch 360/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.6029 - accuracy: 0.8070 - val_loss: 0.3284 - val_accuracy: 0.9096\n",
      "Epoch 361/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5999 - accuracy: 0.8078 - val_loss: 0.3263 - val_accuracy: 0.9093\n",
      "Epoch 362/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5954 - accuracy: 0.8087 - val_loss: 0.3265 - val_accuracy: 0.9089\n",
      "Epoch 363/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5982 - accuracy: 0.8085 - val_loss: 0.3236 - val_accuracy: 0.9102\n",
      "Epoch 364/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5847 - accuracy: 0.8142 - val_loss: 0.3222 - val_accuracy: 0.9104\n",
      "Epoch 365/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5882 - accuracy: 0.8102 - val_loss: 0.3194 - val_accuracy: 0.9104\n",
      "Epoch 366/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5929 - accuracy: 0.8096 - val_loss: 0.3185 - val_accuracy: 0.9109\n",
      "Epoch 367/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5806 - accuracy: 0.8149 - val_loss: 0.3172 - val_accuracy: 0.9110\n",
      "Epoch 368/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5881 - accuracy: 0.8121 - val_loss: 0.3172 - val_accuracy: 0.9109\n",
      "Epoch 369/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5922 - accuracy: 0.8076 - val_loss: 0.3169 - val_accuracy: 0.9117\n",
      "Epoch 370/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5909 - accuracy: 0.8118 - val_loss: 0.3141 - val_accuracy: 0.9120\n",
      "Epoch 371/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.5858 - accuracy: 0.8109 - val_loss: 0.3127 - val_accuracy: 0.9117\n",
      "Epoch 372/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5804 - accuracy: 0.8126 - val_loss: 0.3111 - val_accuracy: 0.9122\n",
      "Epoch 373/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5727 - accuracy: 0.8158 - val_loss: 0.3088 - val_accuracy: 0.9136\n",
      "Epoch 374/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5833 - accuracy: 0.8121 - val_loss: 0.3092 - val_accuracy: 0.9135\n",
      "Epoch 375/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5770 - accuracy: 0.8169 - val_loss: 0.3066 - val_accuracy: 0.9139\n",
      "Epoch 376/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5738 - accuracy: 0.8173 - val_loss: 0.3054 - val_accuracy: 0.9140\n",
      "Epoch 377/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5841 - accuracy: 0.8099 - val_loss: 0.3070 - val_accuracy: 0.9143\n",
      "Epoch 378/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5746 - accuracy: 0.8146 - val_loss: 0.3049 - val_accuracy: 0.9139\n",
      "Epoch 379/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.5634 - accuracy: 0.8198 - val_loss: 0.3029 - val_accuracy: 0.9150\n",
      "Epoch 380/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.5715 - accuracy: 0.8175 - val_loss: 0.3008 - val_accuracy: 0.9164\n",
      "Epoch 381/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5703 - accuracy: 0.8136 - val_loss: 0.3006 - val_accuracy: 0.9165\n",
      "Epoch 382/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5648 - accuracy: 0.8201 - val_loss: 0.2982 - val_accuracy: 0.9171\n",
      "Epoch 383/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5672 - accuracy: 0.8199 - val_loss: 0.2970 - val_accuracy: 0.9167\n",
      "Epoch 384/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5648 - accuracy: 0.8193 - val_loss: 0.2962 - val_accuracy: 0.9177\n",
      "Epoch 385/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.5619 - accuracy: 0.8198 - val_loss: 0.2952 - val_accuracy: 0.9178\n",
      "Epoch 386/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.5644 - accuracy: 0.8178 - val_loss: 0.2943 - val_accuracy: 0.9186\n",
      "Epoch 387/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5620 - accuracy: 0.8195 - val_loss: 0.2928 - val_accuracy: 0.9188\n",
      "Epoch 388/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5561 - accuracy: 0.8213 - val_loss: 0.2911 - val_accuracy: 0.9187\n",
      "Epoch 389/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5561 - accuracy: 0.8225 - val_loss: 0.2899 - val_accuracy: 0.9186\n",
      "Epoch 390/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.5447 - accuracy: 0.8228 - val_loss: 0.2895 - val_accuracy: 0.9183\n",
      "Epoch 391/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5403 - accuracy: 0.8245 - val_loss: 0.2860 - val_accuracy: 0.9198\n",
      "Epoch 392/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.5525 - accuracy: 0.8217 - val_loss: 0.2855 - val_accuracy: 0.9202\n",
      "Epoch 393/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.5435 - accuracy: 0.8227 - val_loss: 0.2859 - val_accuracy: 0.9211\n",
      "Epoch 394/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5513 - accuracy: 0.8202 - val_loss: 0.2838 - val_accuracy: 0.9209\n",
      "Epoch 395/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5433 - accuracy: 0.8237 - val_loss: 0.2831 - val_accuracy: 0.9215\n",
      "Epoch 396/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5455 - accuracy: 0.8270 - val_loss: 0.2833 - val_accuracy: 0.9216\n",
      "Epoch 397/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5497 - accuracy: 0.8234 - val_loss: 0.2824 - val_accuracy: 0.9222\n",
      "Epoch 398/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5399 - accuracy: 0.8255 - val_loss: 0.2796 - val_accuracy: 0.9222\n",
      "Epoch 399/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5379 - accuracy: 0.8266 - val_loss: 0.2790 - val_accuracy: 0.9222\n",
      "Epoch 400/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5334 - accuracy: 0.8257 - val_loss: 0.2782 - val_accuracy: 0.9232\n",
      "Epoch 401/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5348 - accuracy: 0.8262 - val_loss: 0.2762 - val_accuracy: 0.9229\n",
      "Epoch 402/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5354 - accuracy: 0.8265 - val_loss: 0.2761 - val_accuracy: 0.9227\n",
      "Epoch 403/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5293 - accuracy: 0.8302 - val_loss: 0.2739 - val_accuracy: 0.9237\n",
      "Epoch 404/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.5308 - accuracy: 0.8291 - val_loss: 0.2746 - val_accuracy: 0.9242\n",
      "Epoch 405/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5342 - accuracy: 0.8288 - val_loss: 0.2725 - val_accuracy: 0.9241\n",
      "Epoch 406/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5278 - accuracy: 0.8283 - val_loss: 0.2724 - val_accuracy: 0.9237\n",
      "Epoch 407/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5318 - accuracy: 0.8276 - val_loss: 0.2713 - val_accuracy: 0.9242\n",
      "Epoch 408/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5206 - accuracy: 0.8312 - val_loss: 0.2699 - val_accuracy: 0.9255\n",
      "Epoch 409/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5252 - accuracy: 0.8289 - val_loss: 0.2690 - val_accuracy: 0.9241\n",
      "Epoch 410/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.5281 - accuracy: 0.8314 - val_loss: 0.2676 - val_accuracy: 0.9249\n",
      "Epoch 411/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5241 - accuracy: 0.8314 - val_loss: 0.2672 - val_accuracy: 0.9249\n",
      "Epoch 412/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5220 - accuracy: 0.8303 - val_loss: 0.2653 - val_accuracy: 0.9252\n",
      "Epoch 413/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.5239 - accuracy: 0.8305 - val_loss: 0.2643 - val_accuracy: 0.9252\n",
      "Epoch 414/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.5126 - accuracy: 0.8348 - val_loss: 0.2635 - val_accuracy: 0.9265\n",
      "Epoch 415/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.5154 - accuracy: 0.8349 - val_loss: 0.2624 - val_accuracy: 0.9278\n",
      "Epoch 416/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5094 - accuracy: 0.8359 - val_loss: 0.2623 - val_accuracy: 0.9275\n",
      "Epoch 417/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.5104 - accuracy: 0.8342 - val_loss: 0.2605 - val_accuracy: 0.9272\n",
      "Epoch 418/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.5064 - accuracy: 0.8370 - val_loss: 0.2591 - val_accuracy: 0.9275\n",
      "Epoch 419/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.5128 - accuracy: 0.8352 - val_loss: 0.2584 - val_accuracy: 0.9273\n",
      "Epoch 420/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.4973 - accuracy: 0.8412 - val_loss: 0.2568 - val_accuracy: 0.9271\n",
      "Epoch 421/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.5067 - accuracy: 0.8368 - val_loss: 0.2574 - val_accuracy: 0.9272\n",
      "Epoch 422/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4998 - accuracy: 0.8427 - val_loss: 0.2549 - val_accuracy: 0.9282\n",
      "Epoch 423/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.5047 - accuracy: 0.8356 - val_loss: 0.2536 - val_accuracy: 0.9291\n",
      "Epoch 424/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.5049 - accuracy: 0.8373 - val_loss: 0.2538 - val_accuracy: 0.9293\n",
      "Epoch 425/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.5074 - accuracy: 0.8367 - val_loss: 0.2530 - val_accuracy: 0.9288\n",
      "Epoch 426/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4959 - accuracy: 0.8403 - val_loss: 0.2527 - val_accuracy: 0.9293\n",
      "Epoch 427/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4943 - accuracy: 0.8393 - val_loss: 0.2513 - val_accuracy: 0.9301\n",
      "Epoch 428/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.5004 - accuracy: 0.8377 - val_loss: 0.2502 - val_accuracy: 0.9312\n",
      "Epoch 429/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.5031 - accuracy: 0.8365 - val_loss: 0.2498 - val_accuracy: 0.9311\n",
      "Epoch 430/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4945 - accuracy: 0.8401 - val_loss: 0.2475 - val_accuracy: 0.9308\n",
      "Epoch 431/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4917 - accuracy: 0.8441 - val_loss: 0.2466 - val_accuracy: 0.9312\n",
      "Epoch 432/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.4929 - accuracy: 0.8415 - val_loss: 0.2468 - val_accuracy: 0.9318\n",
      "Epoch 433/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4925 - accuracy: 0.8403 - val_loss: 0.2479 - val_accuracy: 0.9321\n",
      "Epoch 434/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4951 - accuracy: 0.8428 - val_loss: 0.2466 - val_accuracy: 0.9325\n",
      "Epoch 435/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.4857 - accuracy: 0.8405 - val_loss: 0.2455 - val_accuracy: 0.9324\n",
      "Epoch 436/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4906 - accuracy: 0.8413 - val_loss: 0.2425 - val_accuracy: 0.9325\n",
      "Epoch 437/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4832 - accuracy: 0.8421 - val_loss: 0.2418 - val_accuracy: 0.9334\n",
      "Epoch 438/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4878 - accuracy: 0.8411 - val_loss: 0.2416 - val_accuracy: 0.9341\n",
      "Epoch 439/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4764 - accuracy: 0.8471 - val_loss: 0.2404 - val_accuracy: 0.9337\n",
      "Epoch 440/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4836 - accuracy: 0.8447 - val_loss: 0.2400 - val_accuracy: 0.9345\n",
      "Epoch 441/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4789 - accuracy: 0.8452 - val_loss: 0.2384 - val_accuracy: 0.9342\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4853 - accuracy: 0.8425 - val_loss: 0.2391 - val_accuracy: 0.9342\n",
      "Epoch 443/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4763 - accuracy: 0.8452 - val_loss: 0.2359 - val_accuracy: 0.9347\n",
      "Epoch 444/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4802 - accuracy: 0.8439 - val_loss: 0.2355 - val_accuracy: 0.9348\n",
      "Epoch 445/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4809 - accuracy: 0.8458 - val_loss: 0.2353 - val_accuracy: 0.9356\n",
      "Epoch 446/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4797 - accuracy: 0.8460 - val_loss: 0.2332 - val_accuracy: 0.9358\n",
      "Epoch 447/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.4747 - accuracy: 0.8473 - val_loss: 0.2325 - val_accuracy: 0.9353\n",
      "Epoch 448/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4686 - accuracy: 0.8496 - val_loss: 0.2318 - val_accuracy: 0.9368\n",
      "Epoch 449/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4723 - accuracy: 0.8468 - val_loss: 0.2306 - val_accuracy: 0.9373\n",
      "Epoch 450/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.4748 - accuracy: 0.8474 - val_loss: 0.2308 - val_accuracy: 0.9370\n",
      "Epoch 451/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4628 - accuracy: 0.8508 - val_loss: 0.2290 - val_accuracy: 0.9370\n",
      "Epoch 452/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4646 - accuracy: 0.8482 - val_loss: 0.2288 - val_accuracy: 0.9363\n",
      "Epoch 453/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.4669 - accuracy: 0.8471 - val_loss: 0.2305 - val_accuracy: 0.9357\n",
      "Epoch 454/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4644 - accuracy: 0.8491 - val_loss: 0.2290 - val_accuracy: 0.9360\n",
      "Epoch 455/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4614 - accuracy: 0.8517 - val_loss: 0.2271 - val_accuracy: 0.9370\n",
      "Epoch 456/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4660 - accuracy: 0.8493 - val_loss: 0.2257 - val_accuracy: 0.9376\n",
      "Epoch 457/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4626 - accuracy: 0.8509 - val_loss: 0.2252 - val_accuracy: 0.9375\n",
      "Epoch 458/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4630 - accuracy: 0.8505 - val_loss: 0.2242 - val_accuracy: 0.9383\n",
      "Epoch 459/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4578 - accuracy: 0.8537 - val_loss: 0.2239 - val_accuracy: 0.9390\n",
      "Epoch 460/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4533 - accuracy: 0.8547 - val_loss: 0.2225 - val_accuracy: 0.9387\n",
      "Epoch 461/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4681 - accuracy: 0.8496 - val_loss: 0.2237 - val_accuracy: 0.9383\n",
      "Epoch 462/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4560 - accuracy: 0.8519 - val_loss: 0.2219 - val_accuracy: 0.9383\n",
      "Epoch 463/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4463 - accuracy: 0.8565 - val_loss: 0.2202 - val_accuracy: 0.9386\n",
      "Epoch 464/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4393 - accuracy: 0.8612 - val_loss: 0.2188 - val_accuracy: 0.9387\n",
      "Epoch 465/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4542 - accuracy: 0.8530 - val_loss: 0.2182 - val_accuracy: 0.9390\n",
      "Epoch 466/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4421 - accuracy: 0.8532 - val_loss: 0.2181 - val_accuracy: 0.9397\n",
      "Epoch 467/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4524 - accuracy: 0.8529 - val_loss: 0.2180 - val_accuracy: 0.9393\n",
      "Epoch 468/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4407 - accuracy: 0.8577 - val_loss: 0.2169 - val_accuracy: 0.9402\n",
      "Epoch 469/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4491 - accuracy: 0.8544 - val_loss: 0.2166 - val_accuracy: 0.9403\n",
      "Epoch 470/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4503 - accuracy: 0.8535 - val_loss: 0.2155 - val_accuracy: 0.9400\n",
      "Epoch 471/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4471 - accuracy: 0.8556 - val_loss: 0.2141 - val_accuracy: 0.9415\n",
      "Epoch 472/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4421 - accuracy: 0.8565 - val_loss: 0.2129 - val_accuracy: 0.9403\n",
      "Epoch 473/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4451 - accuracy: 0.8571 - val_loss: 0.2138 - val_accuracy: 0.9404\n",
      "Epoch 474/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4345 - accuracy: 0.8591 - val_loss: 0.2113 - val_accuracy: 0.9418\n",
      "Epoch 475/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4432 - accuracy: 0.8578 - val_loss: 0.2118 - val_accuracy: 0.9415\n",
      "Epoch 476/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4360 - accuracy: 0.8588 - val_loss: 0.2103 - val_accuracy: 0.9416\n",
      "Epoch 477/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4385 - accuracy: 0.8600 - val_loss: 0.2111 - val_accuracy: 0.9410\n",
      "Epoch 478/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4360 - accuracy: 0.8600 - val_loss: 0.2089 - val_accuracy: 0.9417\n",
      "Epoch 479/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.4365 - accuracy: 0.8600 - val_loss: 0.2085 - val_accuracy: 0.9421\n",
      "Epoch 480/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4284 - accuracy: 0.8630 - val_loss: 0.2071 - val_accuracy: 0.9424\n",
      "Epoch 481/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4331 - accuracy: 0.8622 - val_loss: 0.2064 - val_accuracy: 0.9424\n",
      "Epoch 482/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4369 - accuracy: 0.8586 - val_loss: 0.2048 - val_accuracy: 0.9430\n",
      "Epoch 483/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4294 - accuracy: 0.8615 - val_loss: 0.2048 - val_accuracy: 0.9422\n",
      "Epoch 484/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4244 - accuracy: 0.8598 - val_loss: 0.2047 - val_accuracy: 0.9427\n",
      "Epoch 485/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4315 - accuracy: 0.8626 - val_loss: 0.2046 - val_accuracy: 0.9437\n",
      "Epoch 486/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4299 - accuracy: 0.8624 - val_loss: 0.2046 - val_accuracy: 0.9433\n",
      "Epoch 487/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4340 - accuracy: 0.8583 - val_loss: 0.2029 - val_accuracy: 0.9440\n",
      "Epoch 488/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4291 - accuracy: 0.8615 - val_loss: 0.2014 - val_accuracy: 0.9441\n",
      "Epoch 489/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4282 - accuracy: 0.8623 - val_loss: 0.2019 - val_accuracy: 0.9443\n",
      "Epoch 490/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4237 - accuracy: 0.8653 - val_loss: 0.2015 - val_accuracy: 0.9434\n",
      "Epoch 491/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4282 - accuracy: 0.8599 - val_loss: 0.2015 - val_accuracy: 0.9437\n",
      "Epoch 492/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4205 - accuracy: 0.8628 - val_loss: 0.2007 - val_accuracy: 0.9449\n",
      "Epoch 493/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4192 - accuracy: 0.8637 - val_loss: 0.1994 - val_accuracy: 0.9453\n",
      "Epoch 494/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4156 - accuracy: 0.8645 - val_loss: 0.1983 - val_accuracy: 0.9451\n",
      "Epoch 495/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4183 - accuracy: 0.8635 - val_loss: 0.1973 - val_accuracy: 0.9456\n",
      "Epoch 496/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4147 - accuracy: 0.8651 - val_loss: 0.1978 - val_accuracy: 0.9439\n",
      "Epoch 497/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4170 - accuracy: 0.8652 - val_loss: 0.1975 - val_accuracy: 0.9456\n",
      "Epoch 498/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4151 - accuracy: 0.8670 - val_loss: 0.1974 - val_accuracy: 0.9449\n",
      "Epoch 499/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4161 - accuracy: 0.8646 - val_loss: 0.1961 - val_accuracy: 0.9452\n",
      "Epoch 500/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4082 - accuracy: 0.8678 - val_loss: 0.1949 - val_accuracy: 0.9452\n",
      "Epoch 501/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4162 - accuracy: 0.8646 - val_loss: 0.1940 - val_accuracy: 0.9459\n",
      "Epoch 502/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4099 - accuracy: 0.8672 - val_loss: 0.1942 - val_accuracy: 0.9465\n",
      "Epoch 503/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4171 - accuracy: 0.8652 - val_loss: 0.1931 - val_accuracy: 0.9459\n",
      "Epoch 504/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4164 - accuracy: 0.8654 - val_loss: 0.1919 - val_accuracy: 0.9469\n",
      "Epoch 505/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4054 - accuracy: 0.8690 - val_loss: 0.1921 - val_accuracy: 0.9470\n",
      "Epoch 506/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4154 - accuracy: 0.8651 - val_loss: 0.1915 - val_accuracy: 0.9469\n",
      "Epoch 507/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4068 - accuracy: 0.8679 - val_loss: 0.1904 - val_accuracy: 0.9464\n",
      "Epoch 508/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4049 - accuracy: 0.8679 - val_loss: 0.1915 - val_accuracy: 0.9467\n",
      "Epoch 509/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.4071 - accuracy: 0.8678 - val_loss: 0.1893 - val_accuracy: 0.9479\n",
      "Epoch 510/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.3976 - accuracy: 0.8691 - val_loss: 0.1889 - val_accuracy: 0.9476\n",
      "Epoch 511/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4055 - accuracy: 0.8689 - val_loss: 0.1886 - val_accuracy: 0.9465\n",
      "Epoch 512/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3976 - accuracy: 0.8706 - val_loss: 0.1874 - val_accuracy: 0.9472\n",
      "Epoch 513/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4100 - accuracy: 0.8668 - val_loss: 0.1872 - val_accuracy: 0.9477\n",
      "Epoch 514/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3953 - accuracy: 0.8690 - val_loss: 0.1860 - val_accuracy: 0.9476\n",
      "Epoch 515/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3957 - accuracy: 0.8715 - val_loss: 0.1856 - val_accuracy: 0.9478\n",
      "Epoch 516/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4028 - accuracy: 0.8687 - val_loss: 0.1869 - val_accuracy: 0.9484\n",
      "Epoch 517/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3964 - accuracy: 0.8694 - val_loss: 0.1857 - val_accuracy: 0.9482\n",
      "Epoch 518/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3987 - accuracy: 0.8694 - val_loss: 0.1839 - val_accuracy: 0.9485\n",
      "Epoch 519/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.4015 - accuracy: 0.8683 - val_loss: 0.1844 - val_accuracy: 0.9493\n",
      "Epoch 520/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3975 - accuracy: 0.8731 - val_loss: 0.1831 - val_accuracy: 0.9488\n",
      "Epoch 521/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3956 - accuracy: 0.8708 - val_loss: 0.1829 - val_accuracy: 0.9492\n",
      "Epoch 522/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3904 - accuracy: 0.8715 - val_loss: 0.1822 - val_accuracy: 0.9485\n",
      "Epoch 523/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.3948 - accuracy: 0.8719 - val_loss: 0.1827 - val_accuracy: 0.9486\n",
      "Epoch 524/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3903 - accuracy: 0.8742 - val_loss: 0.1813 - val_accuracy: 0.9489\n",
      "Epoch 525/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3900 - accuracy: 0.8729 - val_loss: 0.1801 - val_accuracy: 0.9492\n",
      "Epoch 526/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3894 - accuracy: 0.8729 - val_loss: 0.1806 - val_accuracy: 0.9501\n",
      "Epoch 527/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3879 - accuracy: 0.8738 - val_loss: 0.1797 - val_accuracy: 0.9501\n",
      "Epoch 528/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3840 - accuracy: 0.8756 - val_loss: 0.1789 - val_accuracy: 0.9495\n",
      "Epoch 529/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3875 - accuracy: 0.8736 - val_loss: 0.1770 - val_accuracy: 0.9499\n",
      "Epoch 530/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3847 - accuracy: 0.8765 - val_loss: 0.1772 - val_accuracy: 0.9503\n",
      "Epoch 531/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.3890 - accuracy: 0.8736 - val_loss: 0.1772 - val_accuracy: 0.9503\n",
      "Epoch 532/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3824 - accuracy: 0.8749 - val_loss: 0.1764 - val_accuracy: 0.9499\n",
      "Epoch 533/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3857 - accuracy: 0.8734 - val_loss: 0.1756 - val_accuracy: 0.9504\n",
      "Epoch 534/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3872 - accuracy: 0.8765 - val_loss: 0.1754 - val_accuracy: 0.9503\n",
      "Epoch 535/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.3905 - accuracy: 0.8735 - val_loss: 0.1755 - val_accuracy: 0.9506\n",
      "Epoch 536/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3800 - accuracy: 0.8779 - val_loss: 0.1742 - val_accuracy: 0.9505\n",
      "Epoch 537/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3836 - accuracy: 0.8766 - val_loss: 0.1744 - val_accuracy: 0.9505\n",
      "Epoch 538/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3776 - accuracy: 0.8767 - val_loss: 0.1746 - val_accuracy: 0.9504\n",
      "Epoch 539/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3802 - accuracy: 0.8755 - val_loss: 0.1727 - val_accuracy: 0.9516\n",
      "Epoch 540/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3807 - accuracy: 0.8767 - val_loss: 0.1732 - val_accuracy: 0.9509\n",
      "Epoch 541/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3794 - accuracy: 0.8762 - val_loss: 0.1717 - val_accuracy: 0.9512\n",
      "Epoch 542/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3760 - accuracy: 0.8789 - val_loss: 0.1709 - val_accuracy: 0.9518\n",
      "Epoch 543/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3744 - accuracy: 0.8777 - val_loss: 0.1704 - val_accuracy: 0.9521\n",
      "Epoch 544/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3711 - accuracy: 0.8789 - val_loss: 0.1703 - val_accuracy: 0.9517\n",
      "Epoch 545/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3817 - accuracy: 0.8766 - val_loss: 0.1701 - val_accuracy: 0.9515\n",
      "Epoch 546/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3712 - accuracy: 0.8819 - val_loss: 0.1699 - val_accuracy: 0.9515\n",
      "Epoch 547/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3797 - accuracy: 0.8791 - val_loss: 0.1706 - val_accuracy: 0.9515\n",
      "Epoch 548/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3681 - accuracy: 0.8799 - val_loss: 0.1696 - val_accuracy: 0.9522\n",
      "Epoch 549/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3749 - accuracy: 0.8796 - val_loss: 0.1696 - val_accuracy: 0.9513\n",
      "Epoch 550/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3680 - accuracy: 0.8824 - val_loss: 0.1683 - val_accuracy: 0.9522\n",
      "Epoch 551/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3691 - accuracy: 0.8814 - val_loss: 0.1663 - val_accuracy: 0.9530\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3749 - accuracy: 0.8776 - val_loss: 0.1670 - val_accuracy: 0.9531\n",
      "Epoch 553/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3656 - accuracy: 0.8808 - val_loss: 0.1663 - val_accuracy: 0.9530\n",
      "Epoch 554/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3677 - accuracy: 0.8807 - val_loss: 0.1657 - val_accuracy: 0.9530\n",
      "Epoch 555/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3686 - accuracy: 0.8784 - val_loss: 0.1667 - val_accuracy: 0.9524\n",
      "Epoch 556/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3716 - accuracy: 0.8765 - val_loss: 0.1659 - val_accuracy: 0.9531\n",
      "Epoch 557/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3648 - accuracy: 0.8843 - val_loss: 0.1655 - val_accuracy: 0.9533\n",
      "Epoch 558/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3649 - accuracy: 0.8834 - val_loss: 0.1647 - val_accuracy: 0.9531\n",
      "Epoch 559/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.3618 - accuracy: 0.8839 - val_loss: 0.1630 - val_accuracy: 0.9538\n",
      "Epoch 560/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3658 - accuracy: 0.8792 - val_loss: 0.1630 - val_accuracy: 0.9537\n",
      "Epoch 561/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3624 - accuracy: 0.8819 - val_loss: 0.1636 - val_accuracy: 0.9538\n",
      "Epoch 562/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3717 - accuracy: 0.8801 - val_loss: 0.1630 - val_accuracy: 0.9543\n",
      "Epoch 563/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3705 - accuracy: 0.8798 - val_loss: 0.1635 - val_accuracy: 0.9538\n",
      "Epoch 564/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.3614 - accuracy: 0.8823 - val_loss: 0.1619 - val_accuracy: 0.9541\n",
      "Epoch 565/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3573 - accuracy: 0.8837 - val_loss: 0.1611 - val_accuracy: 0.9538\n",
      "Epoch 566/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.3621 - accuracy: 0.8807 - val_loss: 0.1610 - val_accuracy: 0.9528\n",
      "Epoch 567/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3537 - accuracy: 0.8834 - val_loss: 0.1606 - val_accuracy: 0.9538\n",
      "Epoch 568/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.3583 - accuracy: 0.8816 - val_loss: 0.1599 - val_accuracy: 0.9545\n",
      "Epoch 569/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3589 - accuracy: 0.8828 - val_loss: 0.1591 - val_accuracy: 0.9547\n",
      "Epoch 570/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3566 - accuracy: 0.8847 - val_loss: 0.1594 - val_accuracy: 0.9538\n",
      "Epoch 571/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.3517 - accuracy: 0.8847 - val_loss: 0.1588 - val_accuracy: 0.9547\n",
      "Epoch 572/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3543 - accuracy: 0.8839 - val_loss: 0.1572 - val_accuracy: 0.9554\n",
      "Epoch 573/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3525 - accuracy: 0.8858 - val_loss: 0.1571 - val_accuracy: 0.9550\n",
      "Epoch 574/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3520 - accuracy: 0.8852 - val_loss: 0.1575 - val_accuracy: 0.9549\n",
      "Epoch 575/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3524 - accuracy: 0.8866 - val_loss: 0.1565 - val_accuracy: 0.9561\n",
      "Epoch 576/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3414 - accuracy: 0.8887 - val_loss: 0.1559 - val_accuracy: 0.9554\n",
      "Epoch 577/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.3473 - accuracy: 0.8849 - val_loss: 0.1554 - val_accuracy: 0.9559\n",
      "Epoch 578/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3536 - accuracy: 0.8842 - val_loss: 0.1543 - val_accuracy: 0.9558\n",
      "Epoch 579/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3428 - accuracy: 0.8891 - val_loss: 0.1540 - val_accuracy: 0.9559\n",
      "Epoch 580/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3431 - accuracy: 0.8881 - val_loss: 0.1551 - val_accuracy: 0.9559\n",
      "Epoch 581/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3441 - accuracy: 0.8882 - val_loss: 0.1535 - val_accuracy: 0.9565\n",
      "Epoch 582/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.3459 - accuracy: 0.8853 - val_loss: 0.1537 - val_accuracy: 0.9560\n",
      "Epoch 583/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.3429 - accuracy: 0.8889 - val_loss: 0.1534 - val_accuracy: 0.9562\n",
      "Epoch 584/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.3528 - accuracy: 0.8867 - val_loss: 0.1534 - val_accuracy: 0.9562\n",
      "Epoch 585/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.3455 - accuracy: 0.8878 - val_loss: 0.1528 - val_accuracy: 0.9559\n",
      "Epoch 586/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3367 - accuracy: 0.8899 - val_loss: 0.1511 - val_accuracy: 0.9569\n",
      "Epoch 587/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3400 - accuracy: 0.8908 - val_loss: 0.1507 - val_accuracy: 0.9573\n",
      "Epoch 588/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.3400 - accuracy: 0.8915 - val_loss: 0.1512 - val_accuracy: 0.9569\n",
      "Epoch 589/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3418 - accuracy: 0.8874 - val_loss: 0.1514 - val_accuracy: 0.9567\n",
      "Epoch 590/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3422 - accuracy: 0.8895 - val_loss: 0.1504 - val_accuracy: 0.9567\n",
      "Epoch 591/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3389 - accuracy: 0.8891 - val_loss: 0.1491 - val_accuracy: 0.9574\n",
      "Epoch 592/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3378 - accuracy: 0.8890 - val_loss: 0.1499 - val_accuracy: 0.9571\n",
      "Epoch 593/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.3419 - accuracy: 0.8874 - val_loss: 0.1484 - val_accuracy: 0.9580\n",
      "Epoch 594/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.3314 - accuracy: 0.8910 - val_loss: 0.1483 - val_accuracy: 0.9568\n",
      "Epoch 595/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.3315 - accuracy: 0.8912 - val_loss: 0.1483 - val_accuracy: 0.9574\n",
      "Epoch 596/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.3404 - accuracy: 0.8889 - val_loss: 0.1479 - val_accuracy: 0.9574\n",
      "Epoch 597/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.3318 - accuracy: 0.8925 - val_loss: 0.1471 - val_accuracy: 0.9579\n",
      "Epoch 598/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3429 - accuracy: 0.8877 - val_loss: 0.1479 - val_accuracy: 0.9579\n",
      "Epoch 599/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.3333 - accuracy: 0.8901 - val_loss: 0.1471 - val_accuracy: 0.9581\n",
      "Epoch 600/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3270 - accuracy: 0.8929 - val_loss: 0.1460 - val_accuracy: 0.9579\n",
      "Epoch 601/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3396 - accuracy: 0.8886 - val_loss: 0.1469 - val_accuracy: 0.9573\n",
      "Epoch 602/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3251 - accuracy: 0.8914 - val_loss: 0.1459 - val_accuracy: 0.9577\n",
      "Epoch 603/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3270 - accuracy: 0.8927 - val_loss: 0.1461 - val_accuracy: 0.9574\n",
      "Epoch 604/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3332 - accuracy: 0.8908 - val_loss: 0.1458 - val_accuracy: 0.9583\n",
      "Epoch 605/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3260 - accuracy: 0.8942 - val_loss: 0.1441 - val_accuracy: 0.9589\n",
      "Epoch 606/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.3294 - accuracy: 0.8911 - val_loss: 0.1447 - val_accuracy: 0.9581\n",
      "Epoch 607/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3341 - accuracy: 0.8916 - val_loss: 0.1439 - val_accuracy: 0.9587\n",
      "Epoch 608/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3239 - accuracy: 0.8918 - val_loss: 0.1442 - val_accuracy: 0.9594\n",
      "Epoch 609/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3307 - accuracy: 0.8938 - val_loss: 0.1436 - val_accuracy: 0.9586\n",
      "Epoch 610/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.3289 - accuracy: 0.8936 - val_loss: 0.1437 - val_accuracy: 0.9583\n",
      "Epoch 611/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3257 - accuracy: 0.8945 - val_loss: 0.1431 - val_accuracy: 0.9584\n",
      "Epoch 612/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3269 - accuracy: 0.8927 - val_loss: 0.1428 - val_accuracy: 0.9588\n",
      "Epoch 613/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3307 - accuracy: 0.8934 - val_loss: 0.1417 - val_accuracy: 0.9587\n",
      "Epoch 614/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3322 - accuracy: 0.8901 - val_loss: 0.1427 - val_accuracy: 0.9583\n",
      "Epoch 615/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.3310 - accuracy: 0.8921 - val_loss: 0.1412 - val_accuracy: 0.9581\n",
      "Epoch 616/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3301 - accuracy: 0.8913 - val_loss: 0.1413 - val_accuracy: 0.9590\n",
      "Epoch 617/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3211 - accuracy: 0.8954 - val_loss: 0.1408 - val_accuracy: 0.9591\n",
      "Epoch 618/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3231 - accuracy: 0.8939 - val_loss: 0.1411 - val_accuracy: 0.9594\n",
      "Epoch 619/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3192 - accuracy: 0.8975 - val_loss: 0.1395 - val_accuracy: 0.9594\n",
      "Epoch 620/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3265 - accuracy: 0.8941 - val_loss: 0.1395 - val_accuracy: 0.9599\n",
      "Epoch 621/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3287 - accuracy: 0.8927 - val_loss: 0.1393 - val_accuracy: 0.9600\n",
      "Epoch 622/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3144 - accuracy: 0.8969 - val_loss: 0.1391 - val_accuracy: 0.9598\n",
      "Epoch 623/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3297 - accuracy: 0.8928 - val_loss: 0.1396 - val_accuracy: 0.9595\n",
      "Epoch 624/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3134 - accuracy: 0.8939 - val_loss: 0.1389 - val_accuracy: 0.9601\n",
      "Epoch 625/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3144 - accuracy: 0.8975 - val_loss: 0.1380 - val_accuracy: 0.9605\n",
      "Epoch 626/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3222 - accuracy: 0.8965 - val_loss: 0.1379 - val_accuracy: 0.9610\n",
      "Epoch 627/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3090 - accuracy: 0.9005 - val_loss: 0.1372 - val_accuracy: 0.9609\n",
      "Epoch 628/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.3240 - accuracy: 0.8958 - val_loss: 0.1365 - val_accuracy: 0.9601\n",
      "Epoch 629/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3181 - accuracy: 0.8963 - val_loss: 0.1368 - val_accuracy: 0.9605\n",
      "Epoch 630/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3140 - accuracy: 0.8971 - val_loss: 0.1354 - val_accuracy: 0.9610\n",
      "Epoch 631/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3175 - accuracy: 0.8959 - val_loss: 0.1349 - val_accuracy: 0.9607\n",
      "Epoch 632/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3135 - accuracy: 0.8958 - val_loss: 0.1352 - val_accuracy: 0.9609\n",
      "Epoch 633/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3162 - accuracy: 0.8937 - val_loss: 0.1360 - val_accuracy: 0.9610\n",
      "Epoch 634/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3176 - accuracy: 0.8986 - val_loss: 0.1352 - val_accuracy: 0.9618\n",
      "Epoch 635/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3093 - accuracy: 0.9000 - val_loss: 0.1354 - val_accuracy: 0.9608\n",
      "Epoch 636/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3111 - accuracy: 0.8993 - val_loss: 0.1353 - val_accuracy: 0.9610\n",
      "Epoch 637/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3067 - accuracy: 0.8988 - val_loss: 0.1333 - val_accuracy: 0.9626\n",
      "Epoch 638/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.3141 - accuracy: 0.8984 - val_loss: 0.1341 - val_accuracy: 0.9625\n",
      "Epoch 639/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3097 - accuracy: 0.8996 - val_loss: 0.1331 - val_accuracy: 0.9613\n",
      "Epoch 640/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3086 - accuracy: 0.8990 - val_loss: 0.1326 - val_accuracy: 0.9624\n",
      "Epoch 641/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.3053 - accuracy: 0.8996 - val_loss: 0.1328 - val_accuracy: 0.9618\n",
      "Epoch 642/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3094 - accuracy: 0.8987 - val_loss: 0.1322 - val_accuracy: 0.9622\n",
      "Epoch 643/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3063 - accuracy: 0.8992 - val_loss: 0.1315 - val_accuracy: 0.9627\n",
      "Epoch 644/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3131 - accuracy: 0.8983 - val_loss: 0.1319 - val_accuracy: 0.9630\n",
      "Epoch 645/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3020 - accuracy: 0.8995 - val_loss: 0.1321 - val_accuracy: 0.9625\n",
      "Epoch 646/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3134 - accuracy: 0.8964 - val_loss: 0.1307 - val_accuracy: 0.9632\n",
      "Epoch 647/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2977 - accuracy: 0.9034 - val_loss: 0.1302 - val_accuracy: 0.9628\n",
      "Epoch 648/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3092 - accuracy: 0.8983 - val_loss: 0.1304 - val_accuracy: 0.9629\n",
      "Epoch 649/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.3031 - accuracy: 0.9006 - val_loss: 0.1303 - val_accuracy: 0.9630\n",
      "Epoch 650/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.3001 - accuracy: 0.9008 - val_loss: 0.1292 - val_accuracy: 0.9625\n",
      "Epoch 651/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.3014 - accuracy: 0.9005 - val_loss: 0.1289 - val_accuracy: 0.9628\n",
      "Epoch 652/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2956 - accuracy: 0.9033 - val_loss: 0.1294 - val_accuracy: 0.9633\n",
      "Epoch 653/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2963 - accuracy: 0.9043 - val_loss: 0.1293 - val_accuracy: 0.9630\n",
      "Epoch 654/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3091 - accuracy: 0.8996 - val_loss: 0.1286 - val_accuracy: 0.9638\n",
      "Epoch 655/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3000 - accuracy: 0.9017 - val_loss: 0.1296 - val_accuracy: 0.9630\n",
      "Epoch 656/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.3007 - accuracy: 0.9016 - val_loss: 0.1292 - val_accuracy: 0.9638\n",
      "Epoch 657/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2963 - accuracy: 0.9041 - val_loss: 0.1290 - val_accuracy: 0.9637\n",
      "Epoch 658/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2882 - accuracy: 0.9055 - val_loss: 0.1280 - val_accuracy: 0.9634\n",
      "Epoch 659/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3009 - accuracy: 0.9021 - val_loss: 0.1271 - val_accuracy: 0.9637\n",
      "Epoch 660/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2946 - accuracy: 0.9026 - val_loss: 0.1271 - val_accuracy: 0.9643\n",
      "Epoch 661/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2995 - accuracy: 0.9028 - val_loss: 0.1269 - val_accuracy: 0.9640\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2919 - accuracy: 0.9052 - val_loss: 0.1263 - val_accuracy: 0.9643\n",
      "Epoch 663/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2980 - accuracy: 0.9005 - val_loss: 0.1267 - val_accuracy: 0.9637\n",
      "Epoch 664/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2998 - accuracy: 0.9040 - val_loss: 0.1258 - val_accuracy: 0.9640\n",
      "Epoch 665/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2967 - accuracy: 0.9050 - val_loss: 0.1255 - val_accuracy: 0.9649\n",
      "Epoch 666/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2889 - accuracy: 0.9041 - val_loss: 0.1244 - val_accuracy: 0.9641\n",
      "Epoch 667/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2933 - accuracy: 0.9040 - val_loss: 0.1252 - val_accuracy: 0.9646\n",
      "Epoch 668/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.3060 - accuracy: 0.9008 - val_loss: 0.1254 - val_accuracy: 0.9644\n",
      "Epoch 669/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2949 - accuracy: 0.9032 - val_loss: 0.1250 - val_accuracy: 0.9660\n",
      "Epoch 670/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2946 - accuracy: 0.9047 - val_loss: 0.1250 - val_accuracy: 0.9649\n",
      "Epoch 671/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2901 - accuracy: 0.9057 - val_loss: 0.1238 - val_accuracy: 0.9653\n",
      "Epoch 672/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2900 - accuracy: 0.9042 - val_loss: 0.1239 - val_accuracy: 0.9653\n",
      "Epoch 673/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2889 - accuracy: 0.9071 - val_loss: 0.1232 - val_accuracy: 0.9647\n",
      "Epoch 674/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2917 - accuracy: 0.9050 - val_loss: 0.1226 - val_accuracy: 0.9653\n",
      "Epoch 675/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2915 - accuracy: 0.9029 - val_loss: 0.1214 - val_accuracy: 0.9653\n",
      "Epoch 676/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2880 - accuracy: 0.9082 - val_loss: 0.1220 - val_accuracy: 0.9656\n",
      "Epoch 677/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2876 - accuracy: 0.9036 - val_loss: 0.1214 - val_accuracy: 0.9656\n",
      "Epoch 678/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2965 - accuracy: 0.9033 - val_loss: 0.1208 - val_accuracy: 0.9663\n",
      "Epoch 679/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2887 - accuracy: 0.9078 - val_loss: 0.1220 - val_accuracy: 0.9656\n",
      "Epoch 680/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2927 - accuracy: 0.9042 - val_loss: 0.1217 - val_accuracy: 0.9661\n",
      "Epoch 681/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2835 - accuracy: 0.9084 - val_loss: 0.1218 - val_accuracy: 0.9661\n",
      "Epoch 682/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2806 - accuracy: 0.9079 - val_loss: 0.1207 - val_accuracy: 0.9659\n",
      "Epoch 683/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2864 - accuracy: 0.9074 - val_loss: 0.1208 - val_accuracy: 0.9660\n",
      "Epoch 684/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2923 - accuracy: 0.9049 - val_loss: 0.1208 - val_accuracy: 0.9660\n",
      "Epoch 685/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2848 - accuracy: 0.9067 - val_loss: 0.1211 - val_accuracy: 0.9661\n",
      "Epoch 686/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2892 - accuracy: 0.9058 - val_loss: 0.1199 - val_accuracy: 0.9663\n",
      "Epoch 687/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2914 - accuracy: 0.9046 - val_loss: 0.1205 - val_accuracy: 0.9666\n",
      "Epoch 688/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2827 - accuracy: 0.9078 - val_loss: 0.1194 - val_accuracy: 0.9664\n",
      "Epoch 689/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2834 - accuracy: 0.9086 - val_loss: 0.1201 - val_accuracy: 0.9663\n",
      "Epoch 690/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2849 - accuracy: 0.9070 - val_loss: 0.1186 - val_accuracy: 0.9662\n",
      "Epoch 691/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2794 - accuracy: 0.9090 - val_loss: 0.1187 - val_accuracy: 0.9660\n",
      "Epoch 692/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2839 - accuracy: 0.9068 - val_loss: 0.1184 - val_accuracy: 0.9662\n",
      "Epoch 693/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2843 - accuracy: 0.9084 - val_loss: 0.1188 - val_accuracy: 0.9663\n",
      "Epoch 694/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2832 - accuracy: 0.9061 - val_loss: 0.1190 - val_accuracy: 0.9666\n",
      "Epoch 695/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2822 - accuracy: 0.9067 - val_loss: 0.1184 - val_accuracy: 0.9670\n",
      "Epoch 696/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2788 - accuracy: 0.9078 - val_loss: 0.1179 - val_accuracy: 0.9666\n",
      "Epoch 697/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2779 - accuracy: 0.9076 - val_loss: 0.1167 - val_accuracy: 0.9676\n",
      "Epoch 698/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2752 - accuracy: 0.9105 - val_loss: 0.1167 - val_accuracy: 0.9681\n",
      "Epoch 699/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2713 - accuracy: 0.9103 - val_loss: 0.1167 - val_accuracy: 0.9680\n",
      "Epoch 700/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2774 - accuracy: 0.9086 - val_loss: 0.1164 - val_accuracy: 0.9676\n",
      "Epoch 701/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2789 - accuracy: 0.9099 - val_loss: 0.1162 - val_accuracy: 0.9675\n",
      "Epoch 702/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2727 - accuracy: 0.9094 - val_loss: 0.1159 - val_accuracy: 0.9671\n",
      "Epoch 703/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2766 - accuracy: 0.9078 - val_loss: 0.1168 - val_accuracy: 0.9666\n",
      "Epoch 704/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2786 - accuracy: 0.9109 - val_loss: 0.1160 - val_accuracy: 0.9676\n",
      "Epoch 705/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2703 - accuracy: 0.9120 - val_loss: 0.1146 - val_accuracy: 0.9687\n",
      "Epoch 706/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2719 - accuracy: 0.9106 - val_loss: 0.1148 - val_accuracy: 0.9670\n",
      "Epoch 707/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2718 - accuracy: 0.9101 - val_loss: 0.1146 - val_accuracy: 0.9677\n",
      "Epoch 708/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2699 - accuracy: 0.9118 - val_loss: 0.1147 - val_accuracy: 0.9673\n",
      "Epoch 709/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2696 - accuracy: 0.9123 - val_loss: 0.1141 - val_accuracy: 0.9680\n",
      "Epoch 710/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2697 - accuracy: 0.9124 - val_loss: 0.1145 - val_accuracy: 0.9679\n",
      "Epoch 711/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2757 - accuracy: 0.9090 - val_loss: 0.1148 - val_accuracy: 0.9670\n",
      "Epoch 712/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2681 - accuracy: 0.9130 - val_loss: 0.1133 - val_accuracy: 0.9674\n",
      "Epoch 713/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2775 - accuracy: 0.9093 - val_loss: 0.1131 - val_accuracy: 0.9677\n",
      "Epoch 714/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2701 - accuracy: 0.9116 - val_loss: 0.1134 - val_accuracy: 0.9678\n",
      "Epoch 715/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2690 - accuracy: 0.9127 - val_loss: 0.1120 - val_accuracy: 0.9679\n",
      "Epoch 716/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2660 - accuracy: 0.9140 - val_loss: 0.1128 - val_accuracy: 0.9682\n",
      "Epoch 717/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2686 - accuracy: 0.9120 - val_loss: 0.1130 - val_accuracy: 0.9683\n",
      "Epoch 718/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2720 - accuracy: 0.9105 - val_loss: 0.1127 - val_accuracy: 0.9676\n",
      "Epoch 719/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2648 - accuracy: 0.9129 - val_loss: 0.1121 - val_accuracy: 0.9680\n",
      "Epoch 720/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2719 - accuracy: 0.9111 - val_loss: 0.1123 - val_accuracy: 0.9679\n",
      "Epoch 721/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2686 - accuracy: 0.9109 - val_loss: 0.1118 - val_accuracy: 0.9685\n",
      "Epoch 722/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2675 - accuracy: 0.9127 - val_loss: 0.1122 - val_accuracy: 0.9688\n",
      "Epoch 723/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2626 - accuracy: 0.9153 - val_loss: 0.1125 - val_accuracy: 0.9682\n",
      "Epoch 724/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2690 - accuracy: 0.9126 - val_loss: 0.1118 - val_accuracy: 0.9679\n",
      "Epoch 725/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2680 - accuracy: 0.9143 - val_loss: 0.1109 - val_accuracy: 0.9683\n",
      "Epoch 726/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2631 - accuracy: 0.9135 - val_loss: 0.1113 - val_accuracy: 0.9683\n",
      "Epoch 727/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2650 - accuracy: 0.9115 - val_loss: 0.1104 - val_accuracy: 0.9686\n",
      "Epoch 728/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2659 - accuracy: 0.9139 - val_loss: 0.1094 - val_accuracy: 0.9685\n",
      "Epoch 729/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2686 - accuracy: 0.9125 - val_loss: 0.1099 - val_accuracy: 0.9687\n",
      "Epoch 730/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2591 - accuracy: 0.9152 - val_loss: 0.1093 - val_accuracy: 0.9688\n",
      "Epoch 731/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2654 - accuracy: 0.9134 - val_loss: 0.1101 - val_accuracy: 0.9683\n",
      "Epoch 732/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2609 - accuracy: 0.9130 - val_loss: 0.1094 - val_accuracy: 0.9684\n",
      "Epoch 733/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2598 - accuracy: 0.9160 - val_loss: 0.1088 - val_accuracy: 0.9694\n",
      "Epoch 734/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2653 - accuracy: 0.9136 - val_loss: 0.1084 - val_accuracy: 0.9691\n",
      "Epoch 735/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2693 - accuracy: 0.9126 - val_loss: 0.1086 - val_accuracy: 0.9692\n",
      "Epoch 736/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2536 - accuracy: 0.9172 - val_loss: 0.1075 - val_accuracy: 0.9690\n",
      "Epoch 737/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2653 - accuracy: 0.9160 - val_loss: 0.1080 - val_accuracy: 0.9689\n",
      "Epoch 738/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2588 - accuracy: 0.9146 - val_loss: 0.1091 - val_accuracy: 0.9689\n",
      "Epoch 739/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2648 - accuracy: 0.9138 - val_loss: 0.1083 - val_accuracy: 0.9696\n",
      "Epoch 740/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2601 - accuracy: 0.9136 - val_loss: 0.1075 - val_accuracy: 0.9693\n",
      "Epoch 741/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2615 - accuracy: 0.9140 - val_loss: 0.1085 - val_accuracy: 0.9691\n",
      "Epoch 742/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2583 - accuracy: 0.9160 - val_loss: 0.1077 - val_accuracy: 0.9690\n",
      "Epoch 743/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2632 - accuracy: 0.9135 - val_loss: 0.1071 - val_accuracy: 0.9696\n",
      "Epoch 744/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2613 - accuracy: 0.9135 - val_loss: 0.1061 - val_accuracy: 0.9698\n",
      "Epoch 745/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2552 - accuracy: 0.9175 - val_loss: 0.1062 - val_accuracy: 0.9699\n",
      "Epoch 746/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2596 - accuracy: 0.9155 - val_loss: 0.1068 - val_accuracy: 0.9696\n",
      "Epoch 747/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2542 - accuracy: 0.9164 - val_loss: 0.1065 - val_accuracy: 0.9699\n",
      "Epoch 748/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2608 - accuracy: 0.9126 - val_loss: 0.1071 - val_accuracy: 0.9699\n",
      "Epoch 749/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2579 - accuracy: 0.9171 - val_loss: 0.1055 - val_accuracy: 0.9703\n",
      "Epoch 750/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2538 - accuracy: 0.9182 - val_loss: 0.1051 - val_accuracy: 0.9706\n",
      "Epoch 751/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2532 - accuracy: 0.9175 - val_loss: 0.1058 - val_accuracy: 0.9702\n",
      "Epoch 752/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2569 - accuracy: 0.9161 - val_loss: 0.1050 - val_accuracy: 0.9705\n",
      "Epoch 753/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2584 - accuracy: 0.9159 - val_loss: 0.1055 - val_accuracy: 0.9706\n",
      "Epoch 754/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2556 - accuracy: 0.9162 - val_loss: 0.1049 - val_accuracy: 0.9702\n",
      "Epoch 755/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2618 - accuracy: 0.9154 - val_loss: 0.1053 - val_accuracy: 0.9699\n",
      "Epoch 756/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2445 - accuracy: 0.9206 - val_loss: 0.1043 - val_accuracy: 0.9696\n",
      "Epoch 757/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2533 - accuracy: 0.9170 - val_loss: 0.1049 - val_accuracy: 0.9695\n",
      "Epoch 758/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2471 - accuracy: 0.9180 - val_loss: 0.1035 - val_accuracy: 0.9698\n",
      "Epoch 759/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2523 - accuracy: 0.9166 - val_loss: 0.1030 - val_accuracy: 0.9701\n",
      "Epoch 760/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2603 - accuracy: 0.9159 - val_loss: 0.1034 - val_accuracy: 0.9698\n",
      "Epoch 761/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2520 - accuracy: 0.9187 - val_loss: 0.1033 - val_accuracy: 0.9707\n",
      "Epoch 762/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2507 - accuracy: 0.9173 - val_loss: 0.1025 - val_accuracy: 0.9708\n",
      "Epoch 763/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.2542 - accuracy: 0.9173 - val_loss: 0.1026 - val_accuracy: 0.9703\n",
      "Epoch 764/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2444 - accuracy: 0.9195 - val_loss: 0.1025 - val_accuracy: 0.9705\n",
      "Epoch 765/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2455 - accuracy: 0.9189 - val_loss: 0.1030 - val_accuracy: 0.9707\n",
      "Epoch 766/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2511 - accuracy: 0.9164 - val_loss: 0.1031 - val_accuracy: 0.9704\n",
      "Epoch 767/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2524 - accuracy: 0.9180 - val_loss: 0.1015 - val_accuracy: 0.9712\n",
      "Epoch 768/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2525 - accuracy: 0.9181 - val_loss: 0.1025 - val_accuracy: 0.9704\n",
      "Epoch 769/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2498 - accuracy: 0.9183 - val_loss: 0.1024 - val_accuracy: 0.9708\n",
      "Epoch 770/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2515 - accuracy: 0.9194 - val_loss: 0.1018 - val_accuracy: 0.9708\n",
      "Epoch 771/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2433 - accuracy: 0.9222 - val_loss: 0.1020 - val_accuracy: 0.9710\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2425 - accuracy: 0.9225 - val_loss: 0.1016 - val_accuracy: 0.9714\n",
      "Epoch 773/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2496 - accuracy: 0.9213 - val_loss: 0.1020 - val_accuracy: 0.9709\n",
      "Epoch 774/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2448 - accuracy: 0.9187 - val_loss: 0.1009 - val_accuracy: 0.9714\n",
      "Epoch 775/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2474 - accuracy: 0.9185 - val_loss: 0.1012 - val_accuracy: 0.9712\n",
      "Epoch 776/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2406 - accuracy: 0.9208 - val_loss: 0.0996 - val_accuracy: 0.9717\n",
      "Epoch 777/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2404 - accuracy: 0.9206 - val_loss: 0.0995 - val_accuracy: 0.9713\n",
      "Epoch 778/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2421 - accuracy: 0.9203 - val_loss: 0.0998 - val_accuracy: 0.9714\n",
      "Epoch 779/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2482 - accuracy: 0.9194 - val_loss: 0.0996 - val_accuracy: 0.9716\n",
      "Epoch 780/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2439 - accuracy: 0.9208 - val_loss: 0.0994 - val_accuracy: 0.9709\n",
      "Epoch 781/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2417 - accuracy: 0.9211 - val_loss: 0.1001 - val_accuracy: 0.9712\n",
      "Epoch 782/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2429 - accuracy: 0.9199 - val_loss: 0.0996 - val_accuracy: 0.9715\n",
      "Epoch 783/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2427 - accuracy: 0.9192 - val_loss: 0.0996 - val_accuracy: 0.9716\n",
      "Epoch 784/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2368 - accuracy: 0.9246 - val_loss: 0.1001 - val_accuracy: 0.9712\n",
      "Epoch 785/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2476 - accuracy: 0.9188 - val_loss: 0.0995 - val_accuracy: 0.9712\n",
      "Epoch 786/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2407 - accuracy: 0.9231 - val_loss: 0.0991 - val_accuracy: 0.9715\n",
      "Epoch 787/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2419 - accuracy: 0.9208 - val_loss: 0.0989 - val_accuracy: 0.9724\n",
      "Epoch 788/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2448 - accuracy: 0.9185 - val_loss: 0.0988 - val_accuracy: 0.9723\n",
      "Epoch 789/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2443 - accuracy: 0.9216 - val_loss: 0.0991 - val_accuracy: 0.9718\n",
      "Epoch 790/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2349 - accuracy: 0.9228 - val_loss: 0.0981 - val_accuracy: 0.9720\n",
      "Epoch 791/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2351 - accuracy: 0.9214 - val_loss: 0.0979 - val_accuracy: 0.9722\n",
      "Epoch 792/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2351 - accuracy: 0.9245 - val_loss: 0.0976 - val_accuracy: 0.9725\n",
      "Epoch 793/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2333 - accuracy: 0.9235 - val_loss: 0.0974 - val_accuracy: 0.9727\n",
      "Epoch 794/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2460 - accuracy: 0.9180 - val_loss: 0.0975 - val_accuracy: 0.9722\n",
      "Epoch 795/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2385 - accuracy: 0.9217 - val_loss: 0.0981 - val_accuracy: 0.9725\n",
      "Epoch 796/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2373 - accuracy: 0.9202 - val_loss: 0.0969 - val_accuracy: 0.9729\n",
      "Epoch 797/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2331 - accuracy: 0.9246 - val_loss: 0.0971 - val_accuracy: 0.9718\n",
      "Epoch 798/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2365 - accuracy: 0.9245 - val_loss: 0.0968 - val_accuracy: 0.9718\n",
      "Epoch 799/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2356 - accuracy: 0.9237 - val_loss: 0.0956 - val_accuracy: 0.9728\n",
      "Epoch 800/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2291 - accuracy: 0.9245 - val_loss: 0.0957 - val_accuracy: 0.9722\n",
      "Epoch 801/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2408 - accuracy: 0.9206 - val_loss: 0.0962 - val_accuracy: 0.9728\n",
      "Epoch 802/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2351 - accuracy: 0.9239 - val_loss: 0.0958 - val_accuracy: 0.9729\n",
      "Epoch 803/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2329 - accuracy: 0.9245 - val_loss: 0.0952 - val_accuracy: 0.9720\n",
      "Epoch 804/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2369 - accuracy: 0.9216 - val_loss: 0.0954 - val_accuracy: 0.9722\n",
      "Epoch 805/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2383 - accuracy: 0.9230 - val_loss: 0.0960 - val_accuracy: 0.9730\n",
      "Epoch 806/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2309 - accuracy: 0.9245 - val_loss: 0.0955 - val_accuracy: 0.9722\n",
      "Epoch 807/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2365 - accuracy: 0.9225 - val_loss: 0.0960 - val_accuracy: 0.9724\n",
      "Epoch 808/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2329 - accuracy: 0.9243 - val_loss: 0.0952 - val_accuracy: 0.9737\n",
      "Epoch 809/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2312 - accuracy: 0.9245 - val_loss: 0.0948 - val_accuracy: 0.9732\n",
      "Epoch 810/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2324 - accuracy: 0.9224 - val_loss: 0.0948 - val_accuracy: 0.9738\n",
      "Epoch 811/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2280 - accuracy: 0.9229 - val_loss: 0.0949 - val_accuracy: 0.9732\n",
      "Epoch 812/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2358 - accuracy: 0.9219 - val_loss: 0.0947 - val_accuracy: 0.9738\n",
      "Epoch 813/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2269 - accuracy: 0.9235 - val_loss: 0.0939 - val_accuracy: 0.9737\n",
      "Epoch 814/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2270 - accuracy: 0.9259 - val_loss: 0.0942 - val_accuracy: 0.9730\n",
      "Epoch 815/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2258 - accuracy: 0.9243 - val_loss: 0.0939 - val_accuracy: 0.9740\n",
      "Epoch 816/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2299 - accuracy: 0.9249 - val_loss: 0.0940 - val_accuracy: 0.9741\n",
      "Epoch 817/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2259 - accuracy: 0.9251 - val_loss: 0.0930 - val_accuracy: 0.9741\n",
      "Epoch 818/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2278 - accuracy: 0.9239 - val_loss: 0.0933 - val_accuracy: 0.9742\n",
      "Epoch 819/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.2363 - accuracy: 0.9217 - val_loss: 0.0940 - val_accuracy: 0.9739\n",
      "Epoch 820/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2295 - accuracy: 0.9249 - val_loss: 0.0932 - val_accuracy: 0.9743\n",
      "Epoch 821/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.2264 - accuracy: 0.9278 - val_loss: 0.0924 - val_accuracy: 0.9745\n",
      "Epoch 822/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2224 - accuracy: 0.9256 - val_loss: 0.0919 - val_accuracy: 0.9744\n",
      "Epoch 823/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2320 - accuracy: 0.9235 - val_loss: 0.0916 - val_accuracy: 0.9741\n",
      "Epoch 824/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2243 - accuracy: 0.9266 - val_loss: 0.0914 - val_accuracy: 0.9745\n",
      "Epoch 825/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2259 - accuracy: 0.9254 - val_loss: 0.0924 - val_accuracy: 0.9738\n",
      "Epoch 826/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2196 - accuracy: 0.9268 - val_loss: 0.0912 - val_accuracy: 0.9745\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2272 - accuracy: 0.9271 - val_loss: 0.0914 - val_accuracy: 0.9740\n",
      "Epoch 828/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2316 - accuracy: 0.9235 - val_loss: 0.0916 - val_accuracy: 0.9745\n",
      "Epoch 829/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2294 - accuracy: 0.9245 - val_loss: 0.0917 - val_accuracy: 0.9755\n",
      "Epoch 830/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2257 - accuracy: 0.9278 - val_loss: 0.0914 - val_accuracy: 0.9743\n",
      "Epoch 831/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2237 - accuracy: 0.9262 - val_loss: 0.0914 - val_accuracy: 0.9746\n",
      "Epoch 832/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2199 - accuracy: 0.9275 - val_loss: 0.0906 - val_accuracy: 0.9742\n",
      "Epoch 833/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2259 - accuracy: 0.9251 - val_loss: 0.0912 - val_accuracy: 0.9748\n",
      "Epoch 834/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2173 - accuracy: 0.9278 - val_loss: 0.0904 - val_accuracy: 0.9748\n",
      "Epoch 835/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2255 - accuracy: 0.9258 - val_loss: 0.0906 - val_accuracy: 0.9740\n",
      "Epoch 836/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2247 - accuracy: 0.9263 - val_loss: 0.0903 - val_accuracy: 0.9741\n",
      "Epoch 837/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2265 - accuracy: 0.9249 - val_loss: 0.0900 - val_accuracy: 0.9743\n",
      "Epoch 838/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2220 - accuracy: 0.9283 - val_loss: 0.0901 - val_accuracy: 0.9752\n",
      "Epoch 839/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2186 - accuracy: 0.9281 - val_loss: 0.0901 - val_accuracy: 0.9748\n",
      "Epoch 840/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2172 - accuracy: 0.9280 - val_loss: 0.0891 - val_accuracy: 0.9747\n",
      "Epoch 841/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2182 - accuracy: 0.9288 - val_loss: 0.0887 - val_accuracy: 0.9760\n",
      "Epoch 842/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2160 - accuracy: 0.9282 - val_loss: 0.0886 - val_accuracy: 0.9762\n",
      "Epoch 843/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2263 - accuracy: 0.9261 - val_loss: 0.0889 - val_accuracy: 0.9755\n",
      "Epoch 844/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2187 - accuracy: 0.9275 - val_loss: 0.0889 - val_accuracy: 0.9758\n",
      "Epoch 845/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2200 - accuracy: 0.9277 - val_loss: 0.0877 - val_accuracy: 0.9761\n",
      "Epoch 846/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2184 - accuracy: 0.9288 - val_loss: 0.0882 - val_accuracy: 0.9758\n",
      "Epoch 847/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2249 - accuracy: 0.9263 - val_loss: 0.0883 - val_accuracy: 0.9760\n",
      "Epoch 848/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2147 - accuracy: 0.9304 - val_loss: 0.0884 - val_accuracy: 0.9757\n",
      "Epoch 849/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2207 - accuracy: 0.9283 - val_loss: 0.0884 - val_accuracy: 0.9756\n",
      "Epoch 850/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2154 - accuracy: 0.9302 - val_loss: 0.0876 - val_accuracy: 0.9755\n",
      "Epoch 851/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2178 - accuracy: 0.9271 - val_loss: 0.0879 - val_accuracy: 0.9759\n",
      "Epoch 852/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2133 - accuracy: 0.9301 - val_loss: 0.0870 - val_accuracy: 0.9757\n",
      "Epoch 853/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2187 - accuracy: 0.9283 - val_loss: 0.0869 - val_accuracy: 0.9762\n",
      "Epoch 854/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2185 - accuracy: 0.9277 - val_loss: 0.0864 - val_accuracy: 0.9759\n",
      "Epoch 855/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2140 - accuracy: 0.9304 - val_loss: 0.0870 - val_accuracy: 0.9760\n",
      "Epoch 856/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2137 - accuracy: 0.9296 - val_loss: 0.0866 - val_accuracy: 0.9756\n",
      "Epoch 857/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2140 - accuracy: 0.9304 - val_loss: 0.0858 - val_accuracy: 0.9765\n",
      "Epoch 858/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2180 - accuracy: 0.9269 - val_loss: 0.0870 - val_accuracy: 0.9758\n",
      "Epoch 859/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2165 - accuracy: 0.9292 - val_loss: 0.0863 - val_accuracy: 0.9762\n",
      "Epoch 860/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2153 - accuracy: 0.9297 - val_loss: 0.0862 - val_accuracy: 0.9758\n",
      "Epoch 861/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2202 - accuracy: 0.9293 - val_loss: 0.0861 - val_accuracy: 0.9762\n",
      "Epoch 862/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2118 - accuracy: 0.9308 - val_loss: 0.0859 - val_accuracy: 0.9765\n",
      "Epoch 863/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2191 - accuracy: 0.9287 - val_loss: 0.0863 - val_accuracy: 0.9764\n",
      "Epoch 864/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2122 - accuracy: 0.9304 - val_loss: 0.0864 - val_accuracy: 0.9763\n",
      "Epoch 865/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2208 - accuracy: 0.9279 - val_loss: 0.0872 - val_accuracy: 0.9761\n",
      "Epoch 866/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2112 - accuracy: 0.9291 - val_loss: 0.0854 - val_accuracy: 0.9763\n",
      "Epoch 867/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2127 - accuracy: 0.9298 - val_loss: 0.0853 - val_accuracy: 0.9765\n",
      "Epoch 868/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2176 - accuracy: 0.9290 - val_loss: 0.0858 - val_accuracy: 0.9763\n",
      "Epoch 869/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2096 - accuracy: 0.9323 - val_loss: 0.0851 - val_accuracy: 0.9768\n",
      "Epoch 870/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2129 - accuracy: 0.9315 - val_loss: 0.0853 - val_accuracy: 0.9763\n",
      "Epoch 871/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2044 - accuracy: 0.9323 - val_loss: 0.0846 - val_accuracy: 0.9762\n",
      "Epoch 872/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2062 - accuracy: 0.9324 - val_loss: 0.0842 - val_accuracy: 0.9766\n",
      "Epoch 873/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2177 - accuracy: 0.9301 - val_loss: 0.0846 - val_accuracy: 0.9761\n",
      "Epoch 874/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2119 - accuracy: 0.9310 - val_loss: 0.0847 - val_accuracy: 0.9762\n",
      "Epoch 875/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2136 - accuracy: 0.9306 - val_loss: 0.0843 - val_accuracy: 0.9760\n",
      "Epoch 876/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.2092 - accuracy: 0.9312 - val_loss: 0.0847 - val_accuracy: 0.9768\n",
      "Epoch 877/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.2084 - accuracy: 0.9311 - val_loss: 0.0839 - val_accuracy: 0.9769\n",
      "Epoch 878/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2088 - accuracy: 0.9310 - val_loss: 0.0840 - val_accuracy: 0.9771\n",
      "Epoch 879/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2105 - accuracy: 0.9313 - val_loss: 0.0834 - val_accuracy: 0.9775\n",
      "Epoch 880/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2129 - accuracy: 0.9298 - val_loss: 0.0840 - val_accuracy: 0.9774\n",
      "Epoch 881/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2082 - accuracy: 0.9309 - val_loss: 0.0838 - val_accuracy: 0.9772\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2095 - accuracy: 0.9316 - val_loss: 0.0836 - val_accuracy: 0.9771\n",
      "Epoch 883/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2050 - accuracy: 0.9335 - val_loss: 0.0836 - val_accuracy: 0.9771\n",
      "Epoch 884/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2107 - accuracy: 0.9330 - val_loss: 0.0831 - val_accuracy: 0.9777\n",
      "Epoch 885/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2041 - accuracy: 0.9336 - val_loss: 0.0829 - val_accuracy: 0.9775\n",
      "Epoch 886/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2079 - accuracy: 0.9296 - val_loss: 0.0830 - val_accuracy: 0.9765\n",
      "Epoch 887/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2024 - accuracy: 0.9343 - val_loss: 0.0831 - val_accuracy: 0.9765\n",
      "Epoch 888/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2134 - accuracy: 0.9288 - val_loss: 0.0830 - val_accuracy: 0.9771\n",
      "Epoch 889/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2108 - accuracy: 0.9311 - val_loss: 0.0834 - val_accuracy: 0.9774\n",
      "Epoch 890/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2066 - accuracy: 0.9329 - val_loss: 0.0827 - val_accuracy: 0.9771\n",
      "Epoch 891/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2062 - accuracy: 0.9315 - val_loss: 0.0830 - val_accuracy: 0.9770\n",
      "Epoch 892/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2089 - accuracy: 0.9312 - val_loss: 0.0825 - val_accuracy: 0.9771\n",
      "Epoch 893/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2087 - accuracy: 0.9325 - val_loss: 0.0825 - val_accuracy: 0.9769\n",
      "Epoch 894/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2094 - accuracy: 0.9327 - val_loss: 0.0819 - val_accuracy: 0.9770\n",
      "Epoch 895/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2023 - accuracy: 0.9333 - val_loss: 0.0820 - val_accuracy: 0.9771\n",
      "Epoch 896/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2032 - accuracy: 0.9316 - val_loss: 0.0818 - val_accuracy: 0.9778\n",
      "Epoch 897/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2078 - accuracy: 0.9318 - val_loss: 0.0819 - val_accuracy: 0.9775\n",
      "Epoch 898/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2036 - accuracy: 0.9327 - val_loss: 0.0808 - val_accuracy: 0.9777\n",
      "Epoch 899/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1985 - accuracy: 0.9346 - val_loss: 0.0810 - val_accuracy: 0.9779\n",
      "Epoch 900/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2007 - accuracy: 0.9344 - val_loss: 0.0818 - val_accuracy: 0.9774\n",
      "Epoch 901/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2030 - accuracy: 0.9333 - val_loss: 0.0814 - val_accuracy: 0.9781\n",
      "Epoch 902/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2041 - accuracy: 0.9335 - val_loss: 0.0814 - val_accuracy: 0.9785\n",
      "Epoch 903/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2015 - accuracy: 0.9329 - val_loss: 0.0820 - val_accuracy: 0.9776\n",
      "Epoch 904/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2018 - accuracy: 0.9351 - val_loss: 0.0816 - val_accuracy: 0.9781\n",
      "Epoch 905/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2010 - accuracy: 0.9352 - val_loss: 0.0804 - val_accuracy: 0.9776\n",
      "Epoch 906/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2043 - accuracy: 0.9323 - val_loss: 0.0805 - val_accuracy: 0.9787\n",
      "Epoch 907/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1918 - accuracy: 0.9363 - val_loss: 0.0805 - val_accuracy: 0.9778\n",
      "Epoch 908/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2094 - accuracy: 0.9314 - val_loss: 0.0813 - val_accuracy: 0.9771\n",
      "Epoch 909/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2044 - accuracy: 0.9318 - val_loss: 0.0808 - val_accuracy: 0.9777\n",
      "Epoch 910/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.2054 - accuracy: 0.9316 - val_loss: 0.0798 - val_accuracy: 0.9785\n",
      "Epoch 911/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2091 - accuracy: 0.9322 - val_loss: 0.0804 - val_accuracy: 0.9778\n",
      "Epoch 912/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2030 - accuracy: 0.9332 - val_loss: 0.0800 - val_accuracy: 0.9782\n",
      "Epoch 913/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2055 - accuracy: 0.9309 - val_loss: 0.0804 - val_accuracy: 0.9781\n",
      "Epoch 914/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1960 - accuracy: 0.9353 - val_loss: 0.0792 - val_accuracy: 0.9785\n",
      "Epoch 915/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2042 - accuracy: 0.9340 - val_loss: 0.0796 - val_accuracy: 0.9785\n",
      "Epoch 916/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.2001 - accuracy: 0.9339 - val_loss: 0.0797 - val_accuracy: 0.9780\n",
      "Epoch 917/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1922 - accuracy: 0.9367 - val_loss: 0.0789 - val_accuracy: 0.9788\n",
      "Epoch 918/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1974 - accuracy: 0.9355 - val_loss: 0.0791 - val_accuracy: 0.9787\n",
      "Epoch 919/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1995 - accuracy: 0.9336 - val_loss: 0.0788 - val_accuracy: 0.9777\n",
      "Epoch 920/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.1974 - accuracy: 0.9346 - val_loss: 0.0788 - val_accuracy: 0.9780\n",
      "Epoch 921/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.1913 - accuracy: 0.9368 - val_loss: 0.0787 - val_accuracy: 0.9781\n",
      "Epoch 922/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.1995 - accuracy: 0.9358 - val_loss: 0.0782 - val_accuracy: 0.9780\n",
      "Epoch 923/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.2007 - accuracy: 0.9342 - val_loss: 0.0782 - val_accuracy: 0.9782\n",
      "Epoch 924/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.1968 - accuracy: 0.9359 - val_loss: 0.0783 - val_accuracy: 0.9787\n",
      "Epoch 925/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.1989 - accuracy: 0.9351 - val_loss: 0.0794 - val_accuracy: 0.9782\n",
      "Epoch 926/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.1949 - accuracy: 0.9364 - val_loss: 0.0790 - val_accuracy: 0.9778\n",
      "Epoch 927/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.1993 - accuracy: 0.9332 - val_loss: 0.0787 - val_accuracy: 0.9786\n",
      "Epoch 928/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1924 - accuracy: 0.9374 - val_loss: 0.0777 - val_accuracy: 0.9783\n",
      "Epoch 929/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1990 - accuracy: 0.9345 - val_loss: 0.0783 - val_accuracy: 0.9782\n",
      "Epoch 930/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.1925 - accuracy: 0.9380 - val_loss: 0.0772 - val_accuracy: 0.9785\n",
      "Epoch 931/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1940 - accuracy: 0.9359 - val_loss: 0.0776 - val_accuracy: 0.9788\n",
      "Epoch 932/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1838 - accuracy: 0.9389 - val_loss: 0.0774 - val_accuracy: 0.9785\n",
      "Epoch 933/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.1988 - accuracy: 0.9356 - val_loss: 0.0766 - val_accuracy: 0.9793\n",
      "Epoch 934/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.1898 - accuracy: 0.9377 - val_loss: 0.0775 - val_accuracy: 0.9791\n",
      "Epoch 935/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1948 - accuracy: 0.9362 - val_loss: 0.0775 - val_accuracy: 0.9791\n",
      "Epoch 936/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1930 - accuracy: 0.9364 - val_loss: 0.0773 - val_accuracy: 0.9788\n",
      "Epoch 937/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1936 - accuracy: 0.9378 - val_loss: 0.0771 - val_accuracy: 0.9781\n",
      "Epoch 938/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1929 - accuracy: 0.9383 - val_loss: 0.0775 - val_accuracy: 0.9786\n",
      "Epoch 939/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1929 - accuracy: 0.9368 - val_loss: 0.0765 - val_accuracy: 0.9788\n",
      "Epoch 940/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1960 - accuracy: 0.9355 - val_loss: 0.0765 - val_accuracy: 0.9788\n",
      "Epoch 941/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1966 - accuracy: 0.9348 - val_loss: 0.0770 - val_accuracy: 0.9788\n",
      "Epoch 942/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1899 - accuracy: 0.9376 - val_loss: 0.0767 - val_accuracy: 0.9780\n",
      "Epoch 943/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1965 - accuracy: 0.9365 - val_loss: 0.0764 - val_accuracy: 0.9791\n",
      "Epoch 944/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1882 - accuracy: 0.9383 - val_loss: 0.0760 - val_accuracy: 0.9787\n",
      "Epoch 945/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1883 - accuracy: 0.9377 - val_loss: 0.0760 - val_accuracy: 0.9788\n",
      "Epoch 946/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1961 - accuracy: 0.9362 - val_loss: 0.0766 - val_accuracy: 0.9785\n",
      "Epoch 947/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1864 - accuracy: 0.9391 - val_loss: 0.0754 - val_accuracy: 0.9781\n",
      "Epoch 948/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1953 - accuracy: 0.9369 - val_loss: 0.0764 - val_accuracy: 0.9785\n",
      "Epoch 949/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1945 - accuracy: 0.9367 - val_loss: 0.0758 - val_accuracy: 0.9792\n",
      "Epoch 950/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1911 - accuracy: 0.9383 - val_loss: 0.0757 - val_accuracy: 0.9790\n",
      "Epoch 951/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1942 - accuracy: 0.9358 - val_loss: 0.0754 - val_accuracy: 0.9791\n",
      "Epoch 952/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1907 - accuracy: 0.9371 - val_loss: 0.0752 - val_accuracy: 0.9792\n",
      "Epoch 953/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1912 - accuracy: 0.9367 - val_loss: 0.0757 - val_accuracy: 0.9796\n",
      "Epoch 954/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1921 - accuracy: 0.9367 - val_loss: 0.0755 - val_accuracy: 0.9794\n",
      "Epoch 955/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1880 - accuracy: 0.9372 - val_loss: 0.0748 - val_accuracy: 0.9798\n",
      "Epoch 956/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1917 - accuracy: 0.9374 - val_loss: 0.0756 - val_accuracy: 0.9791\n",
      "Epoch 957/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1837 - accuracy: 0.9394 - val_loss: 0.0756 - val_accuracy: 0.9794\n",
      "Epoch 958/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1821 - accuracy: 0.9393 - val_loss: 0.0750 - val_accuracy: 0.9790\n",
      "Epoch 959/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.1915 - accuracy: 0.9372 - val_loss: 0.0755 - val_accuracy: 0.9793\n",
      "Epoch 960/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.1912 - accuracy: 0.9374 - val_loss: 0.0746 - val_accuracy: 0.9794\n",
      "Epoch 961/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.1898 - accuracy: 0.9388 - val_loss: 0.0745 - val_accuracy: 0.9800\n",
      "Epoch 962/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.1897 - accuracy: 0.9388 - val_loss: 0.0744 - val_accuracy: 0.9794\n",
      "Epoch 963/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1846 - accuracy: 0.9398 - val_loss: 0.0743 - val_accuracy: 0.9792\n",
      "Epoch 964/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1895 - accuracy: 0.9404 - val_loss: 0.0747 - val_accuracy: 0.9789\n",
      "Epoch 965/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.1886 - accuracy: 0.9392 - val_loss: 0.0744 - val_accuracy: 0.9795\n",
      "Epoch 966/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1831 - accuracy: 0.9386 - val_loss: 0.0741 - val_accuracy: 0.9796\n",
      "Epoch 967/1000\n",
      "487/487 [==============================] - 45s 93ms/step - loss: 0.1914 - accuracy: 0.9372 - val_loss: 0.0743 - val_accuracy: 0.9795\n",
      "Epoch 968/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.1864 - accuracy: 0.9390 - val_loss: 0.0741 - val_accuracy: 0.9796\n",
      "Epoch 969/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1897 - accuracy: 0.9378 - val_loss: 0.0748 - val_accuracy: 0.9794\n",
      "Epoch 970/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1827 - accuracy: 0.9392 - val_loss: 0.0739 - val_accuracy: 0.9800\n",
      "Epoch 971/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.1813 - accuracy: 0.9390 - val_loss: 0.0733 - val_accuracy: 0.9807\n",
      "Epoch 972/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1883 - accuracy: 0.9386 - val_loss: 0.0730 - val_accuracy: 0.9798\n",
      "Epoch 973/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.1858 - accuracy: 0.9383 - val_loss: 0.0736 - val_accuracy: 0.9793\n",
      "Epoch 974/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1855 - accuracy: 0.9377 - val_loss: 0.0728 - val_accuracy: 0.9797\n",
      "Epoch 975/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1807 - accuracy: 0.9401 - val_loss: 0.0733 - val_accuracy: 0.9801\n",
      "Epoch 976/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1845 - accuracy: 0.9385 - val_loss: 0.0733 - val_accuracy: 0.9800\n",
      "Epoch 977/1000\n",
      "487/487 [==============================] - 45s 93ms/step - loss: 0.1823 - accuracy: 0.9404 - val_loss: 0.0729 - val_accuracy: 0.9804\n",
      "Epoch 978/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.1799 - accuracy: 0.9403 - val_loss: 0.0728 - val_accuracy: 0.9801\n",
      "Epoch 979/1000\n",
      "487/487 [==============================] - 45s 93ms/step - loss: 0.1833 - accuracy: 0.9401 - val_loss: 0.0724 - val_accuracy: 0.9805\n",
      "Epoch 980/1000\n",
      "487/487 [==============================] - 45s 93ms/step - loss: 0.1819 - accuracy: 0.9414 - val_loss: 0.0721 - val_accuracy: 0.9806\n",
      "Epoch 981/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1912 - accuracy: 0.9372 - val_loss: 0.0718 - val_accuracy: 0.9803\n",
      "Epoch 982/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1848 - accuracy: 0.9377 - val_loss: 0.0733 - val_accuracy: 0.9795\n",
      "Epoch 983/1000\n",
      "487/487 [==============================] - 45s 93ms/step - loss: 0.1777 - accuracy: 0.9417 - val_loss: 0.0721 - val_accuracy: 0.9804\n",
      "Epoch 984/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1810 - accuracy: 0.9405 - val_loss: 0.0717 - val_accuracy: 0.9805\n",
      "Epoch 985/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.1771 - accuracy: 0.9420 - val_loss: 0.0720 - val_accuracy: 0.9795\n",
      "Epoch 986/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1787 - accuracy: 0.9406 - val_loss: 0.0722 - val_accuracy: 0.9801\n",
      "Epoch 987/1000\n",
      "487/487 [==============================] - 45s 93ms/step - loss: 0.1797 - accuracy: 0.9406 - val_loss: 0.0718 - val_accuracy: 0.9805\n",
      "Epoch 988/1000\n",
      "487/487 [==============================] - 45s 93ms/step - loss: 0.1786 - accuracy: 0.9417 - val_loss: 0.0728 - val_accuracy: 0.9808\n",
      "Epoch 989/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1827 - accuracy: 0.9387 - val_loss: 0.0720 - val_accuracy: 0.9800\n",
      "Epoch 990/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1862 - accuracy: 0.9380 - val_loss: 0.0721 - val_accuracy: 0.9805\n",
      "Epoch 991/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.1861 - accuracy: 0.9391 - val_loss: 0.0720 - val_accuracy: 0.9804\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1822 - accuracy: 0.9417 - val_loss: 0.0718 - val_accuracy: 0.9804\n",
      "Epoch 993/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1787 - accuracy: 0.9431 - val_loss: 0.0714 - val_accuracy: 0.9803\n",
      "Epoch 994/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1818 - accuracy: 0.9421 - val_loss: 0.0712 - val_accuracy: 0.9801\n",
      "Epoch 995/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1778 - accuracy: 0.9406 - val_loss: 0.0710 - val_accuracy: 0.9805\n",
      "Epoch 996/1000\n",
      "487/487 [==============================] - 44s 91ms/step - loss: 0.1809 - accuracy: 0.9406 - val_loss: 0.0705 - val_accuracy: 0.9810\n",
      "Epoch 997/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1801 - accuracy: 0.9404 - val_loss: 0.0716 - val_accuracy: 0.9806\n",
      "Epoch 998/1000\n",
      "487/487 [==============================] - 46s 94ms/step - loss: 0.1824 - accuracy: 0.9397 - val_loss: 0.0710 - val_accuracy: 0.9801\n",
      "Epoch 999/1000\n",
      "487/487 [==============================] - 45s 91ms/step - loss: 0.1818 - accuracy: 0.9407 - val_loss: 0.0712 - val_accuracy: 0.9801\n",
      "Epoch 1000/1000\n",
      "487/487 [==============================] - 45s 92ms/step - loss: 0.1811 - accuracy: 0.9416 - val_loss: 0.0707 - val_accuracy: 0.9803\n"
     ]
    }
   ],
   "source": [
    "print('Training model 1')\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "earlystopping = callbacks.EarlyStopping(monitor=\"val_loss\", patience = 5, restore_best_weights = True)\n",
    "# Compile the model with categorical crossentropy loss function and Adam optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "# model1.summary()\n",
    "\n",
    "history_const = model.fit(X_train, y_train,batch_size=100, epochs = 1000, validation_data=(X_test,y_test),\n",
    "                   callbacks= [earlystopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d5b72d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving\n",
      "saved\n"
     ]
    }
   ],
   "source": [
    "print('Saving')\n",
    "np.save(load_path+model_name1+'_history.npy',history_const.history)\n",
    "model.save(load_path+model_name1+'_model.h5') \n",
    "print(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f40f84c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "# #load saved history\n",
    "history_const=np.load(load_path+model_name1+'_history.npy',allow_pickle='TRUE').item()\n",
    "\n",
    "# #load saved model\n",
    "model1=load_model(load_path+model_name1+'_model.h5')\n",
    "\n",
    "print(\"loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "caf213f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Plots')\n",
    "plt.plot(history_const.history['loss'])\n",
    "plt.plot(history_const.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "# plt.savefig('F:/VA/onehandtwohand/26words_DSLR_results/'+model_name1+'_loss.png')\n",
    "plt.savefig(load_path+model_name1+'_loss.png')\n",
    "plt.show()\n",
    "plt.plot(history_const.history['accuracy'])\n",
    "plt.plot(history_const.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig(load_path+model_name1+'_accuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4006fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion matrix')\n",
    "Y_pred = model1.predict(X_new)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_test1 = np.argmax(y_new, axis=1)\n",
    "\n",
    "cm=metrics.confusion_matrix(y_test1, y_pred)\n",
    "\n",
    "\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "a4_dims = (200, 100)\n",
    "fig,ax= plt.subplots(figsize=a4_dims)\n",
    "sns.heatmap(cm, annot=True, fmt=\".2f\", ax=ax,  linewidth=.5);  \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.set_xticklabels(CATEGORIES)\n",
    "ax.set_yticklabels(CATEGORIES)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.setp(ax.get_xticklabels(), rotation=90, horizontalalignment='right')\n",
    "plt.setp(ax.get_yticklabels(), rotation=0, horizontalalignment='right')\n",
    "plt.savefig(load_path+model_name1+'_cm.png',bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57902f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLot fractional incorrect misclassifications\n",
    "\n",
    "incorr_fraction = 1 - np.diag(cm) / np.sum(cm, axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plt.bar(np.arange(cat_len), incorr_fraction)\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Fraction of incorrect predictions')\n",
    "plt.xticks(np.arange(cat_len), CATEGORIES)\n",
    "plt.savefig(load_path+model_name1+'_incorrect_percentage.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c596ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK RANDOM IMAGES FROM TESTED DATA WHETHER RIGHT OR WRONG\n",
    "\n",
    "i = random.randint(1,cat_len)\n",
    "plt.imshow(X_new[i,:,:,2]) \n",
    "print(\"Predicted Label: \", CATEGORIES[int(y_pred[i])])\n",
    "print(\"True Label: \", CATEGORIES[int(y_test1[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fc757b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "794a50d2",
   "metadata": {},
   "source": [
    "# Colourful mediapipe testing with VA_create_3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f40106c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "    \n",
    "def draw_landmarks(image, results):   \n",
    "    #face\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        results.face_landmarks,\n",
    "        mp_holistic.FACEMESH_CONTOURS,\n",
    "        landmark_drawing_spec=None,\n",
    "        connection_drawing_spec=mp_drawing_styles\n",
    "        .get_default_face_mesh_contours_style())\n",
    "#     #pose\n",
    "#     mp_drawing.draw_landmarks(\n",
    "#         image,\n",
    "#         results.pose_landmarks,\n",
    "#         mp_holistic.POSE_CONNECTIONS,\n",
    "#         landmark_drawing_spec=mp_drawing_styles\n",
    "#         .get_default_pose_landmarks_style())\n",
    "    \n",
    "    #left hand\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        results.left_hand_landmarks,\n",
    "        mp_holistic.HAND_CONNECTIONS,\n",
    "#         landmark_drawing_spec=None,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())\n",
    "    # right hand\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        results.right_hand_landmarks,\n",
    "        mp_holistic.HAND_CONNECTIONS,\n",
    "#         landmark_drawing_spec=None,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a1bc8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For veryyyyyyyy beautiful webcam input:\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "org = (20, 20)  \n",
    "org1 = (310, 20) \n",
    "fontScale = 0.65  \n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "# Blue color in BGR\n",
    "color = (130, 0, 0)  \n",
    "# Line thickness of 2 px\n",
    "thickness = 1 \n",
    "thickness1 = -1\n",
    "start_point = (0,0)\n",
    "end_point = (480,30)\n",
    "color1 = (255, 255, 255)  \n",
    "cls='R'\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "      while cap.isOpened():\n",
    "        #image from feeder\n",
    "        r, img_array = cap.read()\n",
    "        img_array = cv2.flip(img_array, 1)\n",
    "        #webcam\n",
    "        img_array = img_array[:, 80:560, :]\n",
    "        #dslr\n",
    "#         img_array = cv2.resize(img_array[:, 224:800, :],(480,480))\n",
    "        \n",
    "        image, results = mediapipe_detection(img_array, holistic)\n",
    "        draw_landmarks(image, results)\n",
    "        if not (results.left_hand_landmarks or results.right_hand_landmarks):\n",
    "            continue\n",
    "\n",
    "        # white background\n",
    "        img = np.zeros([480,480,3],dtype=np.uint8)\n",
    "        img.fill(255) \n",
    "        draw_landmarks(img, results)\n",
    "\n",
    "        # for prediction\n",
    "        IMG_SIZE=128\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        X = np.array(img).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "        X = X.astype('float32')\n",
    "        X /= 255\n",
    "        X = np.array(X)\n",
    "        Y = model1.predict(X,verbose=0)\n",
    "\n",
    "        if np.max(Y)>0.2:\n",
    "            # for display\n",
    "            image = cv2.rectangle(image, start_point, end_point, color1, thickness1)\n",
    "            image = cv2.rectangle(image, (0,30), (480,30), color, 2)\n",
    "            image = cv2.putText(image,\"Prediction: \"+ CATEGORIES[np.argmax(Y)], org, font, \n",
    "                   fontScale, color, thickness, cv2.LINE_AA)\n",
    "            image = cv2.putText(image,\"Accuracy: \"+ \"%.2f\" % np.max(Y), org1, font, \n",
    "                   fontScale, color, thickness, cv2.LINE_AA)\n",
    "#             if CATEGORIES[np.argmax(Y)]==cls:\n",
    "            if np.max(Y)>0.8:\n",
    "                cv2.imwrite(load_path+'/99.79_misc_rajesh/mp_'+\n",
    "                            CATEGORIES[np.argmax(Y)]+'_'+str(np.max(Y))+'.jpg',image)\n",
    "                cv2.imwrite(load_path+'/99.79_misc_rajesh/ori_'+\n",
    "                            CATEGORIES[np.argmax(Y)]+'_'+str(np.max(Y))+'.jpg',img_array)\n",
    "\n",
    "\n",
    "        cv2.imshow('Realtime testing', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "# close the camera\n",
    "cap.release()\n",
    "\n",
    "# close all the opened windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c88845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8a99bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
