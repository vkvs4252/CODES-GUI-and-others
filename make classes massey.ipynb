{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ffe905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import keras\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from keras.utils import np_utils\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d64c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = 'E:/VA/standard dataset/Massey dataset ASL/'\n",
    "save_path= 'E:/VA/standard dataset/Massey categories/'\n",
    "# CATEGORIES = ['0' ,'1' ,'2' ,'3' ,'4' ,'5' ,'6', '7' ,'8', '9', 'A', 'B', 'C' ,'D' ,'E' ,'F' ,'G', 'H' ,'I', \n",
    "#  'J' ,'K', 'L' ,'M', 'N', 'O', 'P' ,'Q', 'R',\n",
    "#  'S', 'T', 'U' ,'V', 'W' ,'X', 'Y', 'Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5122793",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad image using cv2\n",
    "def pad(img):\n",
    "    old_image_height, old_image_width, channels = img.shape\n",
    "\n",
    "    # create new image of desired size and color (blue) for padding\n",
    "    SIZE = 672\n",
    "    color = (0,0,0)\n",
    "    result = np.full((SIZE,SIZE, channels), color, dtype=np.uint8)\n",
    "\n",
    "    # compute center offset\n",
    "    x_center = (SIZE - old_image_width) // 2\n",
    "    y_center = (SIZE - old_image_height) // 2\n",
    "\n",
    "    # copy img image into center of result image\n",
    "    result[y_center:y_center+old_image_height, \n",
    "           x_center:x_center+old_image_width] = img\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a3ec519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 857/857 [00:21<00:00, 39.62it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 895/895 [00:21<00:00, 42.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 180/180 [00:04<00:00, 40.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 180/180 [00:04<00:00, 38.19it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 360/360 [00:05<00:00, 60.97it/s]\n"
     ]
    }
   ],
   "source": [
    "CATEGORIES = []\n",
    "for data_folder in (os.listdir(load_path)):  # to see data_folder\n",
    "    TRAIN_DIR=load_path+data_folder+'/'\n",
    "\n",
    "    for img_cat in tqdm(os.listdir(TRAIN_DIR)): #to see categories in data_folder\n",
    "        \n",
    "        cat = img_cat[6]\n",
    "        save_path1= save_path+'/'+cat\n",
    "        try: \n",
    "            os.makedirs(os.path.join(save_path1))\n",
    "            CATEGORIES.append(cat)\n",
    "        except:\n",
    "            pass\n",
    "        img_array = cv2.imread((TRAIN_DIR+img_cat))\n",
    "        pad_img = pad(img_array)\n",
    "        cv2.imwrite((save_path1+\"/\"+img_cat),pad_img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "653b02a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    }
   ],
   "source": [
    "one_hand=['X.npy','Y.npy']\n",
    "\n",
    "all_categories = list((Counter(all_categories)-Counter(one_hand)).elements())\n",
    "np.save(save_path+'/105words_DSLR_results_gray/'+'cat_105.npy', all_categories)\n",
    "cat_len=len(all_categories)\n",
    "print(cat_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a80174d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "672"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "224*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95433a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'bull', 'camel', 'cat', 'cow', 'crocodile', 'deer', 'dog', 'elephant', 'goat', 'horse', 'lion', 'tiger', 'antelope', 'bag', 'book', 'bottle', 'colour', 'dolphin', 'dupatta', 'fast', 'fish', 'frog', 'gun', 'hair', 'help', 'idea', 'internet', 'jeans', 'location', 'owl', 'pen', 'photo', 'rain', 'saree', 'school', 'shoot', 'sun', 'technology', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'accept', 'age', 'assistant', 'black', 'boot', 'card', 'cash', 'chicken', 'dance', 'earpods', 'handkerchief', 'home', 'human', 'keep', 'laptop', 'meet', 'mobile', 'monkey', 'namastey', 'person', 'proof', 'signature', 'sleep', 'spider', 'stand', 'star', 'tv', 'umbrella', 'white', 'wolf', 'yellow']\n"
     ]
    }
   ],
   "source": [
    "print(all_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565b46fe",
   "metadata": {},
   "source": [
    "# create n word dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cb66768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FH hands 10 words\n",
    "\n",
    "Xn=np.load('E:/VA/onehandtwohand/224_gray/10words_dataset_FH/X.npy', allow_pickle=True)\n",
    "Yn=np.load('E:/VA/onehandtwohand/224_gray/10words_dataset_FH/Y.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ca11de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FH hands 12 words\n",
    "\n",
    "Xa=np.load('E:/VA/onehandtwohand/224_gray/12words_dataset_FH/X.npy', allow_pickle=True)\n",
    "Ya=np.load('E:/VA/onehandtwohand/224_gray/12words_dataset_FH/Y.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ca720a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FH hands 25 words\n",
    "\n",
    "Xh=np.load('E:/VA/onehandtwohand/224_gray/25words_DSLR_FH/X.npy', allow_pickle=True)\n",
    "Yh=np.load('E:/VA/onehandtwohand/224_gray/25words_DSLR_FH/Y.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "659f5dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FH hands 26 words\n",
    "\n",
    "Xfh=np.load('E:/VA/onehandtwohand/224_gray/26words_DSLR_FH/X.npy', allow_pickle=True)\n",
    "Yfh=np.load('E:/VA/onehandtwohand/224_gray/26words_DSLR_FH/Y.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5538552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FH hands 31 words\n",
    "\n",
    "\n",
    "Xpfh=np.load('E:/VA/onehandtwohand/224_gray/31words_DSLR_FH/X.npy', allow_pickle=True)\n",
    "Ypfh=np.load('E:/VA/onehandtwohand/224_gray/31words_DSLR_FH/Y.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538bb710",
   "metadata": {},
   "source": [
    "# for x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e22a4b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43450, 224, 224, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "####### along X\n",
    "Xn1=np.append(Xn,Xa,axis=0)\n",
    "Xn2=np.append(Xn1,Xh,axis=0)\n",
    "Xn3=np.append(Xn2,Xfh,axis=0)\n",
    "X=np.append(Xn3,Xpfh,axis=0)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "510e6b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7593, 105)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### for numbers Y\n",
    "Y_a = np.zeros((Yn.shape[0],cat_len-10)) # to add ahead of 10 classes\n",
    "Yaa=np.append(Yn,Y_a,axis=1) # 105 classes number matrix   with Yn number of rows              \n",
    "####### for animals Y\n",
    "Y_b1 = np.zeros((Ya.shape[0],10))  # to add before of 12 classes\n",
    "Y_b2 = np.zeros((Ya.shape[0],cat_len-(10+12))) # to add ahead of 12 classes\n",
    "Ybb=np.append(Y_b1,Ya,axis=1)\n",
    "Ycc=np.append(Ybb,Y_b2,axis=1) # 105 classes animal matrix with Ya number of rows\n",
    "# final animal with number Y\n",
    "Ydd=np.append(Yaa,Ycc,axis=0)\n",
    "Ydd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dfa20e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19547, 105)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### for merging 25 words\n",
    "Y_c1 = np.zeros((Yh.shape[0],(10+12)))  # to add before of 25 classes\n",
    "Y_c2 = np.zeros((Yh.shape[0],cat_len-(10+12+26)))    # # to add ahead of 25 classes\n",
    "Yee=np.append(Y_c1,Yh,axis=1) # column merge\n",
    "Yff=np.append(Yee,Y_c2,axis=1)# column merge\n",
    "\n",
    "# # final animal, number, 25 classes along Y\n",
    "Ygg=np.append(Ydd,Yff,axis=0) # row\n",
    "Ygg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dffa70fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### for merging 26 words\n",
    "Y_d1 = np.zeros((Yfh.shape[0],(10+12+26)))  # to add before of 26 classes\n",
    "Y_d2 = np.zeros((Yfh.shape[0],cat_len-(10+12+26+26)))    # # to add ahead of 26 classes\n",
    "Yhh=np.append(Y_d1,Yfh,axis=1) # column merge\n",
    "Yii=np.append(Yhh,Y_d2,axis=1) # column merge\n",
    "# final animal, number, 25,26 classes along Y\n",
    "Yjj=np.append(Ygg,Yii,axis=0) # row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78268907",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### for merging 31 words\n",
    "Y_e1 = np.zeros((Ypfh.shape[0],(10+12+26+26)))  # to add before of 26 classes\n",
    "Y_e2 = np.zeros((Ypfh.shape[0],cat_len-(10+12+26+26+31)))    # # to add ahead of 26 classes\n",
    "Ykk=np.append(Y_e1,Ypfh,axis=1) # column merge\n",
    "Yll=np.append(Ykk,Y_e2,axis=1) # column merge\n",
    "# final animal, number, 25,26 classes along Y\n",
    "Ymm=np.append(Yjj,Yll,axis=0) # row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c72baf",
   "metadata": {},
   "source": [
    "for Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9f9346d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43450, 105)\n"
     ]
    }
   ],
   "source": [
    "#final 105 words \n",
    "Y=Ymm\n",
    "\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7a5ad0",
   "metadata": {},
   "source": [
    "saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01b64377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43450, 224, 224, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save(save_path+'/105words_DSLR_results_gray/'+'X.npy', X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b552fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(save_path+'/105words_DSLR_results_gray/'+'Y.npy', Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd16f4ba",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
